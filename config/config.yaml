# RAG LLM Configuration

# Embedding Configuration
embedding:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  dimension: 384

# Vector Store Configuration
vector_store:
  storage_path: "data/vector_store"
  use_faiss: true

# Document Processing Configuration
document_processing:
  chunk_size: 1000
  chunk_overlap: 200
  supported_formats:
    - .txt
    - .pdf
    - .docx
    - .md
    - .html

# LLM Configuration
llm:
  provider: "openai"  # openai, anthropic, huggingface
  model_name: "gpt-3.5-turbo"
  temperature: 0.7
  max_tokens: 1000

# Retrieval Configuration
retrieval:
  k: 5  # Number of documents to retrieve
  score_threshold: null  # Optional minimum similarity score

# System Messages
system_messages:
  default: |
    You are a helpful AI assistant. Use the provided context to answer the user's question.
    If the context doesn't contain relevant information, say so clearly.
    Always cite which document you're referring to when answering.

# Logging Configuration
logging:
  level: "INFO"
  log_file: "logs/rag_llm.log"
