{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ee78cf",
   "metadata": {},
   "source": [
    "# GitHub Repository Documentation Generator with OpenAI SDK\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "This notebook uses the OpenAI SDK with the open-source `gpt-oss-120b` model to generate repository documentation.\n",
    "\n",
    "1. **Get OpenAI API Key** from https://platform.openai.com/api-keys\n",
    "2. **Set environment variable**: `OPENAI_API_KEY=your_token_here` (already in .env file)\n",
    "3. **Run the cells below** to generate documentation\n",
    "\n",
    "The default model is `openai/gpt-oss-120b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbca8225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import base64\n",
    "import pathlib\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dcf76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_USERNAME = os.getenv(\"GITHUB_USERNAME\", \"\").strip()\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\", \"\").strip() \n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\").strip()  # required\n",
    "MODEL_NAME = \"gpt-4.1-nano\"\n",
    "OUT_DIR = pathlib.Path(\"../data/raw/repo_summaries\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff5ac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MAX_TREE_ITEMS = 800\n",
    "MAX_FILE_CHARS = 12000\n",
    "MAX_SOURCE_FILES = 12\n",
    "WORKERS=10\n",
    "\n",
    "IMPORTANT_FILES = [\n",
    "    \"README.md\", \"README.MD\", \"README.rst\",\n",
    "    \"pyproject.toml\", \"requirements.txt\", \"Pipfile\", \"setup.py\",\n",
    "    \"package.json\", \"pnpm-lock.yaml\", \"yarn.lock\", \"package-lock.json\",\n",
    "    \"Cargo.toml\", \"go.mod\", \"pom.xml\", \"build.gradle\", \"build.gradle.kts\",\n",
    "    \"Dockerfile\", \"docker-compose.yml\",\n",
    "    \".env.example\", \".github/workflows\",\n",
    "    \"Makefile\", \"compose.yaml\",\n",
    "]\n",
    "\n",
    "SOURCE_EXTS = {\n",
    "    \".py\", \".js\", \".ts\", \".tsx\", \".java\", \".kt\", \".go\", \".rs\", \".cpp\", \".c\", \".h\", \".hpp\",\n",
    "    \".cs\", \".php\", \".rb\", \".swift\", \".scala\", \".lua\", \".sql\", \".sh\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ec2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gh_headers():\n",
    "    h = {\"Accept\": \"application/vnd.github+json\"}\n",
    "    if GITHUB_TOKEN:\n",
    "        h[\"Authorization\"] = f\"Bearer {GITHUB_TOKEN}\"\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bed39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gh_get(url, params=None):\n",
    "    r = requests.get(url, headers=gh_headers(), params=params, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32554a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_repos(username):\n",
    "    \"\"\"Fetch all repos using pagination (100 per page).\"\"\"\n",
    "    repos = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        batch = gh_get(\n",
    "            f\"https://api.github.com/users/{username}/repos\",\n",
    "            params={\"per_page\": 100, \"page\": page, \"sort\": \"updated\"}\n",
    "        )\n",
    "        if not batch:\n",
    "            break\n",
    "        repos.extend(batch)\n",
    "        page += 1\n",
    "    return repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "457e10ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_branch(repo_full_name, fallback=\"main\"):\n",
    "    repo = gh_get(f\"https://api.github.com/repos/{repo_full_name}\")\n",
    "    return repo.get(\"default_branch\") or fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a2e62d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_tree(repo_full_name, branch):\n",
    "    \"\"\"\n",
    "    Two-step process: get commit SHA from branch ref, then fetch full recursive tree.\n",
    "    \"\"\"\n",
    "    ref = gh_get(f\"https://api.github.com/repos/{repo_full_name}/git/refs/heads/{branch}\")\n",
    "    sha = ref[\"object\"][\"sha\"]\n",
    "    \n",
    "    tree = gh_get(\n",
    "        f\"https://api.github.com/repos/{repo_full_name}/git/trees/{sha}\",\n",
    "        params={\"recursive\": 1}\n",
    "    )\n",
    "    return tree.get(\"tree\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9884705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_probably_binary(path):\n",
    "    \"\"\"Check file extension against known binary formats.\"\"\"\n",
    "    return any(path.lower().endswith(ext) for ext in [\n",
    "        \".png\", \".jpg\", \".jpeg\", \".gif\", \".webp\",\n",
    "        \".pdf\", \".zip\", \".gz\", \".7z\",\n",
    "        \".mp4\", \".mov\", \".avi\",\n",
    "        \".exe\", \".dll\", \".so\", \".dylib\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3c00542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_file_text(repo_full_name, path, branch):\n",
    "    \"\"\"\n",
    "    GitHub API returns file content base64-encoded.\n",
    "    Decode and handle both UTF-8 and Latin-1 encodings.\n",
    "    \"\"\"\n",
    "    data = gh_get(\n",
    "        f\"https://api.github.com/repos/{repo_full_name}/contents/{path}\",\n",
    "        params={\"ref\": branch}\n",
    "    )\n",
    "    \n",
    "    if isinstance(data, dict) and data.get(\"type\") == \"file\":\n",
    "        content = data.get(\"content\", \"\")\n",
    "        if data.get(\"encoding\") == \"base64\" and content:\n",
    "            raw = base64.b64decode(content.encode(\"utf-8\", errors=\"ignore\"))\n",
    "            try:\n",
    "                txt = raw.decode(\"utf-8\", errors=\"replace\")\n",
    "            except Exception:\n",
    "                txt = raw.decode(\"latin-1\", errors=\"replace\")\n",
    "            return txt[:MAX_FILE_CHARS]\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05d24758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_key_files(tree_paths):\n",
    "    \"\"\"\n",
    "    Multi-stage file selection:\n",
    "    1. Important files (README, config, CI/CD)\n",
    "    2. Source code files sorted by depth\n",
    "    3. Deduplicate while preserving order\n",
    "    \"\"\"\n",
    "    picked = []\n",
    "    \n",
    "    for imp in tqdm(IMPORTANT_FILES, desc=\"Finding important files\"):\n",
    "        for p in tree_paths:\n",
    "            if p == imp or p.endswith(\"/\" + imp) or (imp.endswith(\"/\") and p.startswith(imp)):\n",
    "                picked.append(p)\n",
    "\n",
    "    src = [p for p in tree_paths if pathlib.Path(p).suffix in SOURCE_EXTS and not is_probably_binary(p)]\n",
    "    src.sort(key=lambda x: (x.count(\"/\"), len(x)))\n",
    "    picked.extend(src[:MAX_SOURCE_FILES])\n",
    "\n",
    "    seen, out = set(), []\n",
    "    for p in tqdm(picked, desc=\"Deduplicating files\"):\n",
    "        if p not in seen:\n",
    "            seen.add(p)\n",
    "            out.append(p)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "940adac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_repo_context(repo, tree):\n",
    "    repo_full = repo[\"full_name\"]\n",
    "    branch = get_default_branch(repo_full)\n",
    "\n",
    "    tree_items = [t for t in tree if t.get(\"type\") in (\"blob\", \"tree\")]\n",
    "    tree_items = tree_items[:MAX_TREE_ITEMS]\n",
    "\n",
    "    paths = [t[\"path\"] for t in tree_items if \"path\" in t]\n",
    "    files = [p for p in paths if not is_probably_binary(p)]\n",
    "\n",
    "    chosen = pick_key_files(files)\n",
    "\n",
    "    file_blobs = []\n",
    "    for p in chosen:\n",
    "        try:\n",
    "            txt = fetch_file_text(repo_full, p, branch)\n",
    "            if txt.strip():\n",
    "                file_blobs.append({\"path\": p, \"text\": txt})\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    meta = {\n",
    "        \"name\": repo.get(\"name\"),\n",
    "        \"full_name\": repo_full,\n",
    "        \"description\": repo.get(\"description\"),\n",
    "        \"topics\": repo.get(\"topics\", []),\n",
    "        \"default_branch\": branch,\n",
    "        \"language\": repo.get(\"language\"),\n",
    "        \"updated_at\": repo.get(\"updated_at\"),\n",
    "        \"stargazers\": repo.get(\"stargazers_count\"),\n",
    "        \"forks\": repo.get(\"forks_count\"),\n",
    "        \"open_issues\": repo.get(\"open_issues_count\"),\n",
    "        \"license\": (repo.get(\"license\") or {}).get(\"spdx_id\"),\n",
    "        \"html_url\": repo.get(\"html_url\"),\n",
    "    }\n",
    "    return meta, paths, file_blobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5452f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(meta, paths, file_blobs):\n",
    "    tree_preview = \"\\n\".join(paths[:600])\n",
    "\n",
    "    def fence(path, text):\n",
    "        ext = pathlib.Path(path).suffix.lstrip(\".\")\n",
    "        lang = ext if ext else \"\"\n",
    "        text = text[:MAX_FILE_CHARS]\n",
    "        return f\"### {path}\\n```{lang}\\n{text}\\n```\\n\"\n",
    "\n",
    "    snippets = \"\\n\".join(fence(f[\"path\"], f[\"text\"]) for f in file_blobs[:20])\n",
    "\n",
    "    return f\"\"\"\n",
    "You are a senior engineer writing documentation.\n",
    "\n",
    "Generate a SINGLE markdown document that explains this GitHub repository clearly.\n",
    "Use proper headings and subheadings and keep it accurate based only on provided data.\n",
    "If something is unclear, say so.\n",
    "\n",
    "# Required structure\n",
    "- Title with repo name\n",
    "- Overview (what it is, who it's for)\n",
    "- Key Features (bullets)\n",
    "- Architecture / How it works (based on files/config)\n",
    "- Notable folders/files (explain why they matter)\n",
    "- Setup & Run (infer from configs; include commands if obvious)\n",
    "- How to use (examples if you can infer)\n",
    "- Testing / CI (if present)\n",
    "- Deployment (if present)\n",
    "- Contribution notes (if present)\n",
    "- Limitations / TODOs you infer (clearly labeled as inference)\n",
    "\n",
    "# Repo metadata (JSON)\n",
    "{json.dumps(meta, indent=2)}\n",
    "\n",
    "# File tree (preview)\n",
    "{tree_preview}\n",
    "\n",
    "# File excerpts\n",
    "{snippets}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70deceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_filename(name: str) -> str:\n",
    "    \"\"\"Replace invalid filename characters with underscores.\"\"\"\n",
    "    name = re.sub(r\"[^a-zA-Z0-9._-]+\", \"_\", name).strip(\"_\")\n",
    "    return name or \"repo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e92c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_markdown_with_openai(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate markdown documentation using OpenAI SDK with OSS model.\n",
    "    \"\"\"\n",
    "    if not OPENAI_API_KEY:\n",
    "        raise RuntimeError(\"OPENAI_API_KEY is missing. Set it in your environment.\")\n",
    "\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You write high-quality repo documentation in Markdown.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=4096,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f109cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_repo(repo):\n",
    "    \"\"\"\n",
    "    Worker function executed in a separate process.\n",
    "    Must be top-level (picklable) for Windows/macOS spawn.\n",
    "    \"\"\"\n",
    "    repo_full = repo[\"full_name\"]\n",
    "    try:\n",
    "        branch = get_default_branch(repo_full)\n",
    "        tree = get_repo_tree(repo_full, branch)\n",
    "        meta, paths, file_blobs = build_repo_context(repo, tree)\n",
    "        prompt = make_prompt(meta, paths, file_blobs)\n",
    "        md = generate_markdown_with_openai(prompt)\n",
    "\n",
    "        out_path = OUT_DIR / f\"{safe_filename(repo['name'])}.md\"\n",
    "        header = f\"<!-- Generated: {datetime.utcnow().isoformat()}Z | Model: {MODEL_NAME} -->\\n\\n\"\n",
    "        out_path.write_text(header + md.strip() + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "        return {\"repo\": repo_full, \"ok\": True, \"path\": str(out_path)}\n",
    "    except Exception as e:\n",
    "        return {\"repo\": repo_full, \"ok\": False, \"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ebe2c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41 repos for @upratham\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Processing repositories:   2%|▏         | 1/41 [00:06<04:22,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/LLM-RAG-private-knowldge-worker -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\LLM-RAG-private-knowldge-worker.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "Processing repositories:   5%|▍         | 2/41 [00:13<04:20,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/AI-in-Production-Healthcare-App -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\AI-in-Production-Healthcare-App.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<00:00, 41791.07it/s]\n",
      "Deduplicating files: 100%|██████████| 8/8 [00:00<?, ?it/s]\n",
      "Processing repositories:   7%|▋         | 3/41 [00:23<05:16,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/production -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\production.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Processing repositories:  10%|▉         | 4/41 [00:30<04:47,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/Breast-Cancer-Segmentation -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\Breast-Cancer-Segmentation.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "Processing repositories:  12%|█▏        | 5/41 [00:38<04:36,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/LLM-Meeting-Minutes-Generation -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\LLM-Meeting-Minutes-Generation.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "Processing repositories:  15%|█▍        | 6/41 [00:47<04:55,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/LLM-Code-Explainer -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\LLM-Code-Explainer.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "Processing repositories:  17%|█▋        | 7/41 [01:02<05:53, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/Desktop-Chat-App -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\Desktop-Chat-App.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<00:00, 22176.08it/s]\n",
      "Deduplicating files: 100%|██████████| 54/54 [00:00<?, ?it/s]\n",
      "Processing repositories:  20%|█▉        | 8/41 [01:17<06:32, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/llm_engineering -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\llm_engineering.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "Processing repositories:  22%|██▏       | 9/41 [01:26<05:54, 11.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/LLM-AI-Company-Brochure-Generator -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\LLM-AI-Company-Brochure-Generator.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Processing repositories:  24%|██▍       | 10/41 [01:32<04:54,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/upratham -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\upratham.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Processing repositories:  27%|██▋       | 11/41 [01:38<04:13,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/DS-Sleep-Disorder-analysis -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\DS-Sleep-Disorder-analysis.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "Processing repositories:  29%|██▉       | 12/41 [01:47<04:04,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/LLM-AI-Website-Summarizer -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\LLM-AI-Website-Summarizer.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "Processing repositories:  32%|███▏      | 13/41 [01:53<03:38,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/MLOps-CD-Docker -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\MLOps-CD-Docker.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "Processing repositories:  34%|███▍      | 14/41 [02:00<03:20,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/MLOps-CI -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\MLOps-CI.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 17/17 [00:00<?, ?it/s]\n",
      "Processing repositories:  37%|███▋      | 15/41 [02:10<03:36,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/MLOps-Insurance-Project -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\MLOps-Insurance-Project.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "Processing repositories:  39%|███▉      | 16/41 [02:20<03:37,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/LLM-Debate-Competition -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\LLM-Debate-Competition.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Processing repositories:  41%|████▏     | 17/41 [02:26<03:12,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/Brain-Tumor-Classification -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\Brain-Tumor-Classification.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "Processing repositories:  44%|████▍     | 18/41 [02:35<03:11,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/UMA_dropout_prediction_for_students -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\UMA_dropout_prediction_for_students.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 5/5 [00:00<?, ?it/s]\n",
      "Processing repositories:  46%|████▋     | 19/41 [02:43<03:00,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/DL-CNN-Transfer-Learning -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\DL-CNN-Transfer-Learning.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Processing repositories:  49%|████▉     | 20/41 [02:50<02:44,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/ML-Ensemble -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\ML-Ensemble.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Processing repositories:  51%|█████     | 21/41 [02:56<02:28,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/NN-Backpropagation -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\NN-Backpropagation.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Processing repositories:  54%|█████▎    | 22/41 [03:03<02:14,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/Linear-regressing--Ridge-Lasso -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\Linear-regressing--Ridge-Lasso.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Processing repositories:  56%|█████▌    | 23/41 [03:12<02:17,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/OpenCV-Basics -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\OpenCV-Basics.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<00:00, 4906.40it/s]\n",
      "Deduplicating files: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Processing repositories:  59%|█████▊    | 24/41 [03:22<02:22,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/ML-flow-exp -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\ML-flow-exp.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 6/6 [00:00<00:00, 4997.19it/s]\n",
      "Processing repositories:  61%|██████    | 25/41 [03:33<02:29,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/MLops-Complete-Pipeline -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\MLops-Complete-Pipeline.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 6/6 [00:00<?, ?it/s]\n",
      "Processing repositories:  63%|██████▎   | 26/41 [03:41<02:12,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/Feature-Selection-and-Dimensionality-Reduction -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\Feature-Selection-and-Dimensionality-Reduction.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Processing repositories:  66%|██████▌   | 27/41 [03:47<01:53,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/Non-linear-dimensionality-reduction -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\Non-linear-dimensionality-reduction.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Processing repositories:  68%|██████▊   | 28/41 [03:55<01:43,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/iris-softmax-vs-svm -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\iris-softmax-vs-svm.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Processing repositories:  71%|███████   | 29/41 [04:02<01:30,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/Dataset -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\Dataset.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Processing repositories:  73%|███████▎  | 30/41 [04:10<01:25,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/MLOps-DVC-Data-Versioning -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\MLOps-DVC-Data-Versioning.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Processing repositories:  76%|███████▌  | 31/41 [04:19<01:20,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/Clustering-KMeans-AHC -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\Clustering-KMeans-AHC.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 6/6 [00:00<?, ?it/s]\n",
      "Processing repositories:  78%|███████▊  | 32/41 [04:26<01:11,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/OOPS-Python-MLOps -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\OOPS-Python-MLOps.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Processing repositories:  80%|████████  | 33/41 [04:33<01:00,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/supervised-ml-feature-experiments -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\supervised-ml-feature-experiments.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 14/14 [00:00<?, ?it/s]\n",
      "Processing repositories:  83%|████████▎ | 34/41 [04:44<00:59,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/prathamesh-portfolio-static -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\prathamesh-portfolio-static.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Processing repositories:  85%|████████▌ | 35/41 [04:52<00:49,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/compare-knn-dt-randomforest -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\compare-knn-dt-randomforest.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Processing repositories:  88%|████████▊ | 36/41 [05:02<00:44,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/chem_sim -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\chem_sim.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 0it [00:00, ?it/s]\n",
      "Processing repositories:  90%|█████████ | 37/41 [05:07<00:31,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/gaussian-mle -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\gaussian-mle.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 17/17 [00:00<?, ?it/s]\n",
      "Processing repositories:  93%|█████████▎| 38/41 [05:20<00:28,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/UMA-V-2 -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\UMA-V-2.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing repositories:  95%|█████████▌| 39/41 [05:21<00:13,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ upratham/UMA_Facial_attentiveness_System failed: 409 Client Error: Conflict for url: https://api.github.com/repos/upratham/UMA_Facial_attentiveness_System/git/refs/heads/main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Processing repositories:  98%|█████████▊| 40/41 [05:27<00:06,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/Predicting-House-price-in-Bangalore-city- -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\Predicting-House-price-in-Bangalore-city-.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding important files: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "Deduplicating files: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Processing repositories: 100%|██████████| 41/41 [05:34<00:00,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upratham/Face-Differentiator -> D:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\data\\raw\\repo_summaries\\Face-Differentiator.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Fetch all repos and process in parallel with progress tracking.\"\"\"\n",
    "    if not GITHUB_USERNAME:\n",
    "        raise RuntimeError(\"Set GITHUB_USERNAME in env.\")\n",
    "\n",
    "    repos = list_repos(GITHUB_USERNAME)\n",
    "    print(f\"Found {len(repos)} repos for @{GITHUB_USERNAME}\")\n",
    "\n",
    "    for res in tqdm(repos, desc=\"Processing repositories\"):\n",
    "        res = process_one_repo(res)\n",
    "        if res[\"ok\"]:\n",
    "            print(f\"✅ {res['repo']} -> {res['path']}\")\n",
    "        else:\n",
    "            print(f\"⚠️ {res['repo']} failed: {res['error']}\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a5728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad7d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-rag-private-knowledge-worker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
