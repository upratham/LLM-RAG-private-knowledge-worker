{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f68d5a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT =Path(Path.cwd()).parent  # adjust if notebook isn't at repo root\n",
    "# If your notebook is in e.g. notebooks/, use: Path.cwd().parent\n",
    "\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c7bcca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from src.data_ingestion import fetch_documents, chunking\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "823ec61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(str(PROJECT_ROOT)+\"/data/processed/pdf_markdown/*/*\")\n",
    "filenames +=glob.glob(str(PROJECT_ROOT)+\"/data/processed/repo_summaries/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c72136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 80 documents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'type': 'resume',\n",
       "  'source': 'd:\\\\LLM\\\\Projects\\\\LLM-RAG-private-knowldge-worker/data/processed/pdf_markdown\\\\Resume\\\\AI_ML Resume 5 Prathamesh Uravane.md',\n",
       "  'text': \"Prathamesh Uravane\\nWashington DC, Baltimore Area | +1 (732) 318-9234 | upratham2002@gmail.com\\nlinkedin.com/in/upratham/ | https://github.com/upratham|Google Scholar Profile\\nEDUCATION\\nUniversity of Maryland, College Park Expected: May 2027\\nMaster of Science in Applied Machine Learning ; GPA: 4.0/ 4.0 College Park, Maryland\\nVishwakarma University May 2024\\nB.Tech in Artificial Intelligence and Data Science ; GPA: 3.75 / 4 Pune, India\\n● Featured in Times of India for Developing real time fall detection system\\n● AI/ML Core Team Member, Google Developer Student Club\\nTECHNICAL SKILLS\\nMachine Learning: Sci-kit Learn, Keras, Tensorflow, PyTorch.HuggingFace,LLMs\\nDevOps Tools: Git, Azure, AWS, Flask, Docker.\\nData Science and Visualization: Numpy, Pandas, Matplotlib, Seaborn.\\nProgramming Languages: Python, MySQL, HTML, PHP.\\nOther: Deep Learning, Medical Imaging, Image Processing, OpenCV, NLP, Gen AI, Big Data Analytics\\nPROFESSIONAL EXPERIENCE\\nAI Engineer Apr 2024 – Jun 2025\\nUniversidad María Auxiliadora Lima, Peru.\\n● Developed an AI-powered virtual lab simulator integrated with a student feedback system to give insights by analyzing student responses.\\nIncreasing student involvement by 34%.\\n● Built a student’s attentiveness Monitoring system for online classes using computer vision technology. It includes face detection, face\\nrecognition, and facial landmark analysis. Helped to improve student assessment.\\nStudent Researcher Intern Jan 2024 – Mar 2024\\nEnergy Research Institute @ NTU Singapore.\\n● Implemented GAN model to generate realistic road scenarios to enhance robustness of the perception system of autonomous vehicles.\\nAI Engineer Intern Jul 2023 – Dec 2023\\nYodda Elder Care Technologies Pvt Limited. Pune, India.\\n● Developed a OpenCV based fall-detection system with 95% accuracy for elderly people using pose estimation and pose-classification\\nclassification. Integrated features like alarm triggering and snapshot delivery, enhancing the system's effectiveness during emergencies.\\nStudent Researcher Jun 2022 – Aug 2022\\nVU Research Centre of Excellence for Health Informatics Pune, India.\\n● Developed a CNN model for classifying brain tumors MRI images, achieving 96% accuracy with minimal computational power.\\nPROJECTS\\n1. Multi-Model Classification System for Dyslexia Detection Using Handwritten Digit Data.\\n● Built CNN classifiers to detect dyslexia with 90.52% accuracy using handwritten digit image data with a multi-model approach. This\\napproach helped to boost accuracy. Results are saved for further analysis, enabling robust and reliable detection. This approach supports\\nearly diagnosis, for the betterment of affected people. (TensorFlow / Keras / Machine Learning / Ensemble Learning / Data Preprocessing)\\n2. LLM-Meeting-Minutes-Generation. (Github Link)\\n• Implemented an end-to-end LLM pipeline using Google Gemini for transcription and a Llama model via Hugging Face Router to\\ngenerate clean, shareable meeting minutes automatically. (Python / HuggingFace / Gradio / ML / Genai / LLM)\\n3. LLM-AI-Website-Summarizer. (Github Link)\\n• Built an AI website summarizer that extracts webpage text from a URL and generates concise summaries using an LLM, with support\\nfor both OpenAI and local Ollama models. Packaged as an easy-to-run notebook workflow with simple setup and environment-based\\nkey management.\\nPUBLICATIONS\\n1. IIETA: Efficient Segmentation Approach for the Traceability of Breast Cancer Tissues to Improve Diagnostic Accuracy in Ultrasound Images.\\n● Advanced preprocessing with multiple segmentation models analyzes breast CT images, enhancing quality and tumor delineation. Dice\\nand IoU evaluations show strong accuracy of 96.73%, enabling early diagnosis and informed treatment planning. (link)\\n2. IEEE ICCCIT’ 2025: Collating Random Forest Classifier and Artificial Neural Networks for the Risk Detection of Maternal Health. (Link)\\n● Compared ANN and Random Forests models for maternal health risk classification using clinical features; addressed class imbalance\\nvia class weights/dropout; Random Forest achieved 85.71% accuracy.\\n3. IEEE IC3I ’2022: An Efficient Deep Learning based Approach for the Detection of Brain Tumors (Link)\\n• Developed CNN model for classifying brain tumors MRI images, achieving 96% accuracy with minimal computational power.\"},\n",
       " {'type': 'resume',\n",
       "  'source': 'd:\\\\LLM\\\\Projects\\\\LLM-RAG-private-knowldge-worker/data/processed/pdf_markdown\\\\Resume\\\\Resume 6 Prathamesh Uravane.md',\n",
       "  'text': \"Prathamesh Uravane\\nWashington DC, Baltimore Area | +1 (732) 318-9234 | upratham2002@gmail.com\\nlinkedin.com/in/upratham/ | https://github.com/upratham|Google Scholar Profile\\nEDUCATION\\nUniversity of Maryland, College Park Anticipated Graduation: May 2027\\nMaster of Science in Applied Machine Learning; GPA: 4.0/ 4.0 College Park, Maryland\\nVishwakarma University May 2024\\nB.Tech in Artificial Intelligence and Data Science ; GPA: 3.75 / 4 Pune, India\\n● Featured in Times of India for Developing real time fall detection system\\n● AI/ML Core Team Member, Google Developer Student Club\\nTECHNICAL SKILLS\\nMachine Learning: Sci-kit Learn, Keras, Tensorflow, PyTorch.HuggingFace,LLMs\\nDevOps Tools: Git, Azure, AWS, Flask, Docker.\\nData Science and Visualization: Numpy, Pandas, Matplotlib, Seaborn.\\nProgramming Languages: Python, MySQL, HTML, PHP.\\nOther: Deep Learning, Medical Imaging, Image Processing, OpenCV, NLP, Gen AI, Big Data Analytics\\nPROFESSIONAL EXPERIENCE\\nAI Engineer | Universidad María Auxiliadora | Lima, Peru. April 2024 – June 2025\\n● Developed an AI-powered virtual lab simulator integrated with a student feedback system to give insights by analyzing student responses.\\nIncreasing student involvement by 34%.\\n● Built a student’s attentiveness Monitoring system for online classes using computer vision technology. It includes face detection, face\\nrecognition, and facial landmark analysis. Helped to improve student assessment.\\nStudent Researcher Intern | Energy Research Institute @ NTU | Singapore. January 2024 – March 2024\\n● Implemented GAN model to generate realistic road scenarios to enhance robustness of the perception system of autonomous vehicles.\\nAI Engineer Intern | Yodda Elder Care Technologies Pvt Limited. | Pune, India. July 2023 – December 2023\\n● Developed a OpenCV based fall-detection system with 95% accuracy for elderly people using pose estimation and pose-classification\\nclassification. Integrated features like alarm triggering and snapshot delivery, enhancing the system's effectiveness during emergencies.\\nStudent Researcher | VU Research Centre of Excellence for Health Informatics | Pune, India. June 2022 – August 2022\\n● Developed a CNN model for classifying brain tumors MRI images, achieving 96% accuracy with minimal computational power.\\nPROJECTS\\n1. Multi-Model Classification System for Dyslexia Detection Using Handwritten Digit Data.\\n● Built CNN classifiers to detect dyslexia with 90.52% accuracy using handwritten digit image data with a multi-model approach. This\\napproach helped to boost accuracy. Results are saved for further analysis, enabling robust and reliable detection. This approach supports\\nearly diagnosis, for the betterment of affected people. (TensorFlow / Keras / Machine Learning / Ensemble Learning / Data Preprocessing)\\n2. LLM-Meeting-Minutes-Generation. (Github Link)\\n• Implemented an end-to-end LLM pipeline using Google Gemini for transcription and a Llama model via Hugging Face Router to\\ngenerate clean, shareable meeting minutes automatically. (Python / HuggingFace / Gradio / ML / Genai / LLM)\\n3. LLM-AI-Website-Summarizer. (Github Link)\\n• Built an AI website summarizer that extracts webpage text from a URL and generates concise summaries using an LLM, with support\\nfor both OpenAI and local Ollama models. Packaged as an easy-to-run notebook workflow with simple setup and environment-based\\nkey management.\\nPUBLICATIONS\\n1. IIETA: Efficient Segmentation Approach for the Traceability of Breast Cancer Tissues to Improve Diagnostic Accuracy in Ultrasound Images.\\n● Advanced preprocessing with multiple segmentation models analyzes breast CT images, enhancing quality and tumor delineation. Dice\\nand IoU evaluations show strong accuracy of 96.73%, enabling early diagnosis and informed treatment planning. (link)\\n2. IEEE ICCCIT’ 2025: Collating Random Forest Classifier and Artificial Neural Networks for the Risk Detection of Maternal Health. (Link)\\n● Compared ANN and Random Forests models for maternal health risk classification using clinical features; addressed class imbalance\\nvia class weights/dropout; Random Forest achieved 85.71% accuracy.\\n3. Book chapter (IET/Elsevier, 2024): Role of the Big Data in Healthcare System. (Link)\\n● Healthcare generates massive, diverse, real-time data exceeding traditional systems. Big data enables scalable, cost-efficient integration,\\nstorage, and analysis across records, medications, trials, and claims—improving handling.\\n4. IEEE IC3I ’2022: An Efficient Deep Learning based Approach for the Detection of Brain Tumors (Link)\\n• Developed CNN model for classifying brain tumors MRI images, achieving 96% accuracy with minimal computational power.\"},\n",
       " {'type': 'transcripts',\n",
       "  'source': 'd:\\\\LLM\\\\Projects\\\\LLM-RAG-private-knowldge-worker/data/processed/pdf_markdown\\\\Transcripts\\\\hsc-12th-marksheet-maharashtra-board-2020.md',\n",
       "  'text': '# Higher Secondary Certificate (HSC) — Statement of Marks (February 2020)\\n\\n## Document type\\nHigher Secondary Certificate (HSC) Examination — Statement of Marks (12th Mark Sheet), Maharashtra State Board of Secondary and Higher Secondary Education, Pune.\\n\\n## Candidate details\\n- **Stream:** Science  \\n- **Name:** Uravane Prathamesh Suhas  \\n- **Mother’s name:** Bhagyashree  \\n- **Seat No.:** P087163  \\n- **Centre No.:** 0460  \\n- **Dist. & Hr. Sec. School No.:** 24.05.023  \\n- **Month & Year of Exam:** **February 2020**  \\n- **Sr. No. of Statement:** 217801  \\n\\n## Marks obtained\\n| Subject | Marks (Max) | Marks Obtained |\\n|---|---:|---:|\\n| English | 100 | 71 |\\n| Marathi | 100 | 85 |\\n| Mathematics & Statistics | 100 | 75 |\\n| Physics | 100 | 73 |\\n| Chemistry | 100 | 55 |\\n| Information Technology (Sci) | 100 | 63 |\\n| Environment Education | 50 | 45 |\\n\\n## Result summary\\n- **Total:** **467 / 650**\\n- **Percentage:** **71.85%**\\n- **Result:** **PASS**\\n- **Health & Physical Education (Grade):** **A**\\n'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents=fetch_documents(filenames=filenames)\n",
    "documents[34:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4aaae71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divided into 770 chunks\n",
      "First chunk:\n",
      "\n",
      "page_content='International Association of Cancer Registries (IACR) in types that are difficult to identify, and efforts must be made to\n",
      "2018, this disease was ranked as the 10th most common type identify the exact tumor from these scans. The lack of\n",
      "of disease. Every year more than 28,000 cases of brain tumors qualified neurosurgeons in developing countries is also a\n",
      "are detected in India and this number is increasing day by day. major reason why the sector is trying to replicate this process\n",
      "More than 24,000 people die from this disease annually [2]. In using some advanced technology that is apparently cost-' metadata={'type': 'research_papers', 'source': 'd:\\\\LLM\\\\Projects\\\\LLM-RAG-private-knowldge-worker/data/processed/pdf_markdown\\\\research_papers\\\\An_Efficient_Deep_Learning_based_Approach_for_the_Detection_of_Brain_Tumors.md'}\n"
     ]
    }
   ],
   "source": [
    "chunks=chunking(documents=documents, chunk_size=700, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb7737",
   "metadata": {},
   "source": [
    "### Make a vectore and store it in Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef4b642",
   "metadata": {},
   "source": [
    "#### apply embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b9e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.embedder import embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b8b90a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\LLM\\Projects\\LLM-RAG-private-knowldge-worker\\vectors\n",
      "Vectorstore created with 770 documents\n"
     ]
    }
   ],
   "source": [
    "db_path=Path(str(PROJECT_ROOT)) / \"vectors\"\n",
    "print(db_path)\n",
    "vectore_store=embedder(db_path=db_path, chunks=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7619a288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ids', 'embeddings', 'documents', 'uris', 'included', 'data', 'metadatas'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectore_store._collection.get().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfc0040",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0e906b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": [
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "blue",
           "blue",
           "blue",
           "cyan",
           "cyan",
           "cyan",
           "cyan",
           "cyan",
           "cyan",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green"
          ],
          "opacity": 0.8,
          "size": 5
         },
         "mode": "markers",
         "text": [
          "Type: academic achievements<br>Text: This certificate is presented to Prathamesh Suhas Uravane, Vishwakarma University, Pune, India in\nre...",
          "Type: academic achievements<br>Text: Certificate Of Participation\nThis certificate is awarded to\nPrathamesh Uravane\nfor attending the fol...",
          "Type: academic achievements<br>Text: Ref. #AUGN/IC3I/2022/56241/023\nWe acknowledge the participation of Dr./Mr./Ms. Prathamesh Uravane of...",
          "Type: academic achievements<br>Text: # Maharashtra Olympiad Movement (MOM) — District Topper (2015–2016)\n\n## Awardee\n**Uravane Prathamesh...",
          "Type: academic achievements<br>Text: ## Key details\n- **Program:** Maharashtra Olympiad Movement 2015  \n- **Exam:** Standard 8 Science Ol...",
          "Type: academic achievements<br>Text: # Certificate of Appreciation — “ML Study Jams” (Copy)\n\n## Recipient\n**Prathamesh Uravane**\n\n## Over...",
          "Type: academic achievements<br>Text: # Certificate of Appreciation — “ML Study Jams”\n\n## Recipient\n**Prathamesh Uravane**\n\n## Overview\nTh...",
          "Type: academic achievements<br>Text: # Maharashtra Talent Search Examination (MTSE) — Taluka Prize (2017)\n\n## Awardee\n**Mr. Uravane Prath...",
          "Type: academic achievements<br>Text: ## Key details\n- **Exam:** Maharashtra Talent Search Examination (MTSE)  \n- **Standard:** IX  \n- **S...",
          "Type: academic achievements<br>Text: # Maharashtra Talent Search Examination (MTSE) — Special Prize (2018)\n\n## Awardee\n**Mr. Uravane Prat...",
          "Type: academic achievements<br>Text: ## Key details\n- **Exam:** Maharashtra Talent Search Examination (MTSE)  \n- **Standard:** X  \n- **St...",
          "Type: academic achievements<br>Text: Certificate Of Participation\nThis certificate is awarded to\nPrathamesh Uravane\nfor attending the fol...",
          "Type: academic achievements<br>Text: Certificate Of Participation\nThis certificate is awarded to\nPrathamesh Uravane\nfor attending the fol...",
          "Type: academic achievements<br>Text: VU/S&T/AI/2024-25/32 Date: 24/04/2025\nTo,\nMr. Prathmesh Uravane,\nAlumni from 2020 Batch\nAlumni Repre...",
          "Type: academic achievements<br>Text: # SOF International Mathematics Olympiad — Participation (2014)\n\n## Participant\n**Uravane Prathamesh...",
          "Type: academic achievements<br>Text: ## Visual elements\nIncludes an IMO medal graphic and SOF branding....",
          "Type: academic achievements<br>Text: # SOF International Mathematics Olympiad — Participation (2015)\n\n## Participant\n**Uravane Prathamesh...",
          "Type: academic achievements<br>Text: ## Overview\nA **Science Olympiad Foundation (SOF)** certificate of participation for the **9th SOF I...",
          "Type: academic achievements<br>Text: # SOF National Science Olympiad — Participation (2014)\n\n## Participant\n**Uravane Prathamesh S**  \nPa...",
          "Type: academic achievements<br>Text: ## Visual elements\nIncludes an NSO medal graphic labeled **“Class Topper Rank 1”** and a handwritten...",
          "Type: extra cariculam<br>Text: 1\nVishwakarma University proudly presents this\nCertificate of ACHIEVEMENT\nto\nPrathamesh Suhas Uravan...",
          "Type: extra cariculam<br>Text: # Aarambha 2021 – Certificate of Achievement (Poetry – 1st Position)\n\n## Overview\nA **Certificate of...",
          "Type: extra cariculam<br>Text: 2\nVishwakarma University proudly presents this\nCertificate of ACHIEVEMENT\nto\nPrathamesh Suhas Uravan...",
          "Type: extra cariculam<br>Text: # Sports Championship – Certificate of Honour (Basketball)\n\n## Overview\nA **Certificate of Honour** ...",
          "Type: extra cariculam<br>Text: # Vishwayaan 2023 – Certificate of Appreciation (Chess – Runner Up)\n\n## Overview\nA **Certificate of ...",
          "Type: extra cariculam<br>Text: # Yogathon – Gold Certificate (108 Surya Namaskar Rounds)\n\n## Overview\nA **Gold Certificate** from *...",
          "Type: extra cariculam<br>Text: # Director General’s Youth Parliament Championship – Participation (Solapur Rural, 2017)\n\n## Overvie...",
          "Type: internships<br>Text: # NTU Singapore – Internship / Research Attachment Completion\n\n## Certificate Type\n**Certificate of ...",
          "Type: internships<br>Text: # UMA – Internship / Project Completion Certificate (2024)\n\n## Certificate Type\n**Certificate of Com...",
          "Type: internships<br>Text: ## Signed / Dated\n**Lima – July 3, 2024**  \nSigned by **Dr. Gladys Yvonne Morán Paredes (Chancellor ...",
          "Type: research integrity course certificates<br>Text: # NTU Epigeum Research Integrity – Arts & Humanities Track (2023)\n\n## Certificate Type\n**Course Comp...",
          "Type: research integrity course certificates<br>Text: # NTU Epigeum Research Integrity – Biomedical Sciences Track (2023)\n\n## Certificate Type\n**Course Co...",
          "Type: research integrity course certificates<br>Text: # NTU Epigeum Research Integrity – Engineering & Technology Track (2023)\n\n## Certificate Type\n**Cour...",
          "Type: research integrity course certificates<br>Text: # NTU Epigeum Research Integrity – Natural & Physical Sciences Track (2023)\n\n## Certificate Type\n**C...",
          "Type: research integrity course certificates<br>Text: # NTU Epigeum Research Integrity – Social & Behavioural Sciences Track (2023)\n\n## Certificate Type\n*...",
          "Type: research integrity course certificates<br>Text: ## Date\n**20/12/2023**\n\n## Signed By\n**Associate Professor Roderick Bates**  \nNTU Research Integrity...",
          "Type: research_papers<br>Text: 2022 5th International Conference on Contemporary Computing and Informatics (IC3I)\nAn Efficient Deep...",
          "Type: research_papers<br>Text: 202000611@vupune.ac.in 202001143@vupune.ac.in 202001369@vupune.ac.in\nJanvi Anand Pagariya Mamoon Ras...",
          "Type: research_papers<br>Text: changes in lifestyle such as self-driving cars, Google Assistant,\nThe typical technique used by neur...",
          "Type: research_papers<br>Text: scans, in fact in the Covid era, deep learning evolved majorly to create a complete scan of the insi...",
          "Type: research_papers<br>Text: MRI scans of these millions of people are needed to determine if create a complete image of a patien...",
          "Type: research_papers<br>Text: proposed deep learning model, we have implemented\nany patient's scan. Now the real challenge also be...",
          "Type: research_papers<br>Text: analyses them and later forwards them to a neurologist. He\nthen studies these scans. It takes him at...",
          "Type: research_papers<br>Text: dealt with as soon as possible. The different types of tumors cannot produce more neurologists in a ...",
          "Type: research_papers<br>Text: grow in the nervous system [1]. Medically recognized, there in real-time. This process can be largel...",
          "Type: research_papers<br>Text: International Association of Cancer Registries (IACR) in types that are difficult to identify, and e...",
          "Type: research_papers<br>Text: More than 24,000 people die from this disease annually [2]. In using some advanced technology that i...",
          "Type: research_papers<br>Text: percent of the total number of reported cases of the disease [3]. possible by advances in durable ha...",
          "Type: research_papers<br>Text: 2022 5th International Conference on Contemporary Computing and Informatics (IC3I)\nlibraries that ar...",
          "Type: research_papers<br>Text: models [9, 10].\nis the most important part of any deep learning project. This\nThe outline of the pap...",
          "Type: research_papers<br>Text: proposed for building the deep learning model using and testing set is given in Table I.\nconvolution...",
          "Type: research_papers<br>Text: Glioma 826 100\ncan be solved using the same deep learning, but the approach\nused here transfers lear...",
          "Type: research_papers<br>Text: of using CNN for classification and they have achieved 97.5% RGB channels. The RGB channels are the ...",
          "Type: research_papers<br>Text: in their project [13]. batches of the same but visually altered images are generated\nto meet the add...",
          "Type: research_papers<br>Text: classification methods [14]. The author has suggested using a\nthe same feature set and is mostly use...",
          "Type: research_papers<br>Text: tumor classification can be done by using techniques like\nGLCM, CNN, and DWT, and has got high accur...",
          "Type: research_papers<br>Text: of bone fractures and blood cells [17]. In this paper, the author\nhas heavily discussed the problem ...",
          "Type: research_papers<br>Text: where the first is pre-processing of the image, the second stage\nFig. 1. Different tumor images of e...",
          "Type: research_papers<br>Text: 2022 5th International Conference on Contemporary Computing and Informatics (IC3I)\nhad parameters an...",
          "Type: research_papers<br>Text: information. Later with advancements in technologies with mouths, eyes, black patches, etc. Based on...",
          "Type: research_papers<br>Text: ability to learn from its mistakes. This ability of neural\nany animal from some significant features...",
          "Type: research_papers<br>Text: Intelligence. The role of these technologies has evolved due to\nconvolutional filters are trained to...",
          "Type: research_papers<br>Text: Each image comprises pixels and pixel values range from 0\nto 256. The color scale of the image is de...",
          "Type: research_papers<br>Text: normalization, which is mainly done to reduce computational\neffort. The most important part for late...",
          "Type: research_papers<br>Text: us to prepare Y-train and Y-test data to make predictions and\ntrain neural networks accordingly. We ...",
          "Type: research_papers<br>Text: Here, data augmentation is also performed to create slightly\ndifferent sets of modified image data, ...",
          "Type: research_papers<br>Text: tasks like image classification, because of their ability to\nextract features from any image and dec...",
          "Type: research_papers<br>Text: would take effort as it would simply scan all images, which\n1. Batch Size: It is nothing but a numbe...",
          "Type: research_papers<br>Text: 2022 5th International Conference on Contemporary Computing and Informatics (IC3I)\ndecided, as it af...",
          "Type: research_papers<br>Text: 3. Validation Split: Validation data is a type of unseen data\nTABLE II. ALL METRICS’ PERFORMANCE FOR...",
          "Type: research_papers<br>Text: numbers, we can say that there is no overfitting in our model. Glioma\n0.97 0.98 0.97 97\nWe have spec...",
          "Type: research_papers<br>Text: kind of set, which is a tumor in our case. This is calculated as\nper eqn.1:\n(cid:1)(cid:2)(cid:3)(ci...",
          "Type: research_papers<br>Text: more positive samples are detected. This is calculated as per\neqn.2:\n(cid:1)(cid:2)(cid:3)(cid:4) (c...",
          "Type: research_papers<br>Text: (cid:18)∗(cid:2)(cid:4)(cid:20)(cid:14)(cid:15)(cid:15)∗(cid:21)(cid:2)(cid:4)(cid:20)(cid:9)(cid:8)...",
          "Type: research_papers<br>Text: while evaluating our model’s performance and that is the\nconfusion matrix. In Figure 5. we can under...",
          "Type: research_papers<br>Text: 2022 5th International Conference on Contemporary Computing and Informatics (IC3I)\nIn this matrix, t...",
          "Type: research_papers<br>Text: Convolutional Neural Networks”, Department of Computer Science\nVI. CONCLUSION\nand Engineering, Sathy...",
          "Type: research_papers<br>Text: our model and we hope these deep learning models may help\ndoctors to recover patients as soon as pos...",
          "Type: research_papers<br>Text: [15] Tariq Sadad, Amjad Rehman, Asim Munir, Tanzila Saba, Usman\nlayers as well as filters to make br...",
          "Type: research_papers<br>Text: Classification Methodologies”, International journal of scientific\ntremendous and remarkable benefit...",
          "Type: research_papers<br>Text: Pune for providing us a chance to use their high performance Brain Tumor Detection Using Machine Lea...",
          "Type: research_papers<br>Text: Abdel-Badeeh M. Salem. \"Classification using deep learning neural IEEE Xplore.\nnetworks for brain tu...",
          "Type: research_papers<br>Text: using deep neural network and machine learning algorithm.\" In 2019\n9th international conference on c...",
          "Type: research_papers<br>Text: detection and segmentation in MR images using deep learning.\"\nArabian Journal for Science and Engine...",
          "Type: research_papers<br>Text: Rawat, Kamred Udham Singh, Mamoon Rashid, and Ahmed Saeed\nAlGhamdi. \"Deep learning approach for anal...",
          "Type: research_papers<br>Text: various techniques using deep Learning for brain tumor detection.\" In\n2020 International conference ...",
          "Type: research_papers<br>Text: 2025 International Conference on Computational,Communication and Information Technology (ICCCIT)\nCol...",
          "Type: research_papers<br>Text: Prathamesh Suhas Uravane Tareek Pattewar\nAIDS Department Computer Engineering Department\nVishwakarma...",
          "Type: research_papers<br>Text: mid, or high. The features considered are clinical obstetrician is essential for the smooth delivery...",
          "Type: research_papers<br>Text: regularization. The best test accuracy obtained in this\ngynecologists in India aren't registered wit...",
          "Type: research_papers<br>Text: aren’t executed. Risk factors for any pregnant woman are\nmuch better accuracy of 85.71% compared wit...",
          "Type: research_papers<br>Text: appears to better serve toward high accuracy along with health of the pregnant woman & treating them...",
          "Type: research_papers<br>Text: I. INTRODUCTION may face [2]. In the modern era where technology has\nadvanced and every and all amou...",
          "Type: research_papers<br>Text: prehistoric era to the modern world, though the methods\naccurately. Basically, we need a method to p...",
          "Type: research_papers<br>Text: cases and if they are extracted then we would certainly human efforts, but to enhance the results br...",
          "Type: research_papers<br>Text: face this at some point in our life. Doctors aren’t able to dashboards could be made for those pregn...",
          "Type: research_papers<br>Text: whom the ML or DL model has predicted as high risk, for compare the advantages and disadvantages of ...",
          "Type: research_papers<br>Text: various hospitals and clinics. This data includes blood\nDiastolicBP, BS-bloodo sugar levels, HeartRa...",
          "Type: research_papers<br>Text: patients into three distinct classes: low, medium, and high\nbe very accurate - up to 98% [4]. Other ...",
          "Type: research_papers<br>Text: the dataset in question is related to class imbalance-class\nthe mother's age how many pregnancies sh...",
          "Type: research_papers<br>Text: weights for the Random Forest and used class balancing\nat healthcare trends with the Nationwide Inpa...",
          "Type: research_papers<br>Text: through scaling of features to improve the performance of the\nfield [8]. Also, scientists have taken...",
          "Type: research_papers<br>Text: better on this classification task. The ANN is a particularly\npuzzles [9], [10].\npowerful deep learn...",
          "Type: research_papers<br>Text: so often critically impact outcomes. However, the effect of an\nbrought in AI models you can understa...",
          "Type: research_papers<br>Text: interpretable model in machine learning that constructs an\nafter birth. Studies [16] and [17] looked...",
          "Type: research_papers<br>Text: is able to provide insights into the importance of features;\nbeyond Random Forest adding in mental h...",
          "Type: research_papers<br>Text: providing interpretable results with less risk of overfitting\nforward show how AI and ML are changin...",
          "Type: research_papers<br>Text: learning approaches in maternal health risk classification.\nmaternal health have very serious conseq...",
          "Type: research_papers<br>Text: handle identical data. For instance, although ANN may\nrisk cases at an early stage so interventions ...",
          "Type: research_papers<br>Text: interpretability is of importance. In that sense, this work\nthe risk levels for maternal health. Thi...",
          "Type: research_papers<br>Text: type of model would best classify risk across different this healthcare dataset since different feat...",
          "Type: research_papers<br>Text: Temp, and Heart Rate are of different scales; therefore,\nThe ANN model as shown in table 1 is built ...",
          "Type: research_papers<br>Text: reducing the difference in range among features.\nTABLE I. ANN MODEL SUMMARY With preprocessing compl...",
          "Type: research_papers<br>Text: dense_1 (Dense) (None, 128) 8320 low-risk and mid-risk classes. Class imbalance can lead to the\nmode...",
          "Type: research_papers<br>Text: dropout_2 (Dropout) (None, 64) 0\neach class to ensure that errors in predicting minority classes\n(e....",
          "Type: research_papers<br>Text: Total params: 19,203\nrevealed comparatively higher precision and recall scores for\nTrainable params:...",
          "Type: research_papers<br>Text: introduce non-linearity and correct the vanishing gradient\nstopping on validation loss: it stops the...",
          "Type: research_papers<br>Text: of the neurons are randomly disabled. That is, 30% of the\nthe model stops generalizing better on the...",
          "Type: research_papers<br>Text: them.\nsuccess. During early epochs, accuracy gradually increasing\nfrom about 37% to the end, around ...",
          "Type: research_papers<br>Text: activation function has been utilized. Softmax is a very\nHowever, at last, the model reached a test ...",
          "Type: research_papers<br>Text: sparse_categorical_crossentropy, which gives a better fit for\nB. Random Forest\ninteger-encoded targe...",
          "Type: research_papers<br>Text: on structured data. During training, it builds a number of exhaustive search evaluates various param...",
          "Type: research_papers<br>Text: hence improves generalization to unseen data. This will of trees helps determine the ideal balance b...",
          "Type: research_papers<br>Text: majority classes. This, coupled with the inherent ability of samples required to allow a node to be ...",
          "Type: research_papers<br>Text: Machines or k-Nearest Neighbors, even as its explicit class\nweighting serves to advantage. The use o...",
          "Type: research_papers<br>Text: risk are mapped onto the numbers 0 and 1, mid risk is put final Random Forest model on the whole tra...",
          "Type: research_papers<br>Text: BP, BS, Body Temp, and Heart Rate using Standard Scaler. was significantly higher as compared to the...",
          "Type: research_papers<br>Text: when cross-validating with other algorithms that require careful regularization against overfitting,...",
          "Type: research_papers<br>Text: Target variable class imbalance may further influence the better generalization.\npower of the model ...",
          "Type: research_papers<br>Text: heavily for classes poorly represented with more risk and mid contributed to maternal health risk pr...",
          "Type: research_papers<br>Text: minority classes. Class balancing in Random Forests is\nautomated, hence a greater penalty per split ...",
          "Type: research_papers<br>Text: final model accuracy, where the risk classes achieved the model to have a high recall and precision ...",
          "Type: research_papers<br>Text: samples required for a split (min_samples_split), and using multiple dense layers with dropout for r...",
          "Type: research_papers<br>Text: how ensemble-based approaches like Random Forest can\neven benefit from structured datasets with mode...",
          "Type: research_papers<br>Text: Forest has stable accuracy at cross-validation; therefore, its\ngeneral performance is more consisten...",
          "Type: research_papers<br>Text: class because feature distributions of this class overlap hugely\nFig. 1 ANN Training Accuracy. with ...",
          "Type: research_papers<br>Text: confused with other classes. This ANN model seems more\ninclined to put some cases in the low risk cl...",
          "Type: research_papers<br>Text: [5] Khaled Fawagreh & Mohamed Medhat Gaber.\" Resource-efficient fast\nprediction in healthcare data a...",
          "Type: research_papers<br>Text: (2013), “Maternal and fetal risk factors for stillbirth: population based\nstudy,” BMJ, 346(jan24 3),...",
          "Type: research_papers<br>Text: series (MIMB, volume 458).\n[11] M. M. Hosaain, M. A. Kashem and N. M. Nayan, \"Artificial\nV. CONCLUSI...",
          "Type: research_papers<br>Text: 10.1109/SEEDA-CECNSM63478.2024.00035.\nwas able to learn complex, non-linear patterns, the algorithm\n...",
          "Type: research_papers<br>Text: Random Forest model on the other hand surpassed ANN as\n[13] Subhashini, A., Nataraju, K., Rani, S. S...",
          "Type: research_papers<br>Text: on different subsets of the input data, Random Forest 97-8422-6_41\nprovided reliable accuracy across...",
          "Type: research_papers<br>Text: predictive performance for the clinical decision making J. J., Amdur, R., Rice, M. M., & Rodriguez, ...",
          "Type: research_papers<br>Text: [16] Irfan, N., Zafar, S., & Hussain, I. “Holistic Analysis and Development\ntransparency of the mode...",
          "Type: research_papers<br>Text: Classification Of Maternal Risks In Pregnancy: Analysis Using\nMachine Learning And Artificial Neural...",
          "Type: research_papers<br>Text: [2] Ron Southwick,\"Using AI to predict risks for pregnancy & delivery,\" E., Eriz-Salinas, A., Appel-...",
          "Type: research_papers<br>Text: https://doi.org/10.3389/fendo.2023.1130139, (2023).\n[4] Ali Raza, Hafeez Ur Rehman Siddiqui, Kashif ...",
          "Type: research_papers<br>Text: health risk prediction,\" November 9, 2022. AI-driven technologies in maternal and newborn child heal...",
          "Type: research_papers<br>Text: Traitement du Signal\nVol. 42, No. 5, October, 2025, pp. 2913-2922\nJournal homepage: http://iieta.org...",
          "Type: research_papers<br>Text: Maryland 20742, USA\n2 Ira A. Fulton Schools of Engineering, Arizona State University, Arizona 85281,...",
          "Type: research_papers<br>Text: University, Riyadh 11671, Saudi Arabia\n6 Department of Computer Science, College of Computer Science...",
          "Type: research_papers<br>Text: Revised: 26 August 2025 populations, and requires correct detection through early intervention. This...",
          "Type: research_papers<br>Text: Keywords:\nsegmentation in healthcare for the traceability of every breast tissue to improve diagnost...",
          "Type: research_papers<br>Text: favorable rates. The two state-of-the-art deep learning-based instance segmentation\nframeworks are u...",
          "Type: research_papers<br>Text: patient care.\n1.INTRODUCTION with a sonographer is actively involved in the successful\ncapturing of ...",
          "Type: research_papers<br>Text: with 685,000 deaths from breast cancer alone in the year 2020 forms of radiation and magnetic fields...",
          "Type: research_papers<br>Text: disproportionately skimpy. For example, India is a billion-plus breast cancer, very often represent ...",
          "Type: research_papers<br>Text: Similarly, less than 10,000 radiologists for the whole country number of oncologists and sonographer...",
          "Type: research_papers<br>Text: imaging modalities, particularly ultrasound. It plays a very highly important. However, the imbalanc...",
          "Type: research_papers<br>Text: newer ways of bridging the gap. step-by-step technique used in our novel data preprocessing\nIn this ...",
          "Type: research_papers<br>Text: invasively in real-time. But these images can have a subjective The rest of the paper has been organ...",
          "Type: research_papers<br>Text: work, they were used as a reference or gold standard for the presented in Section 4. Finally, the pa...",
          "Type: research_papers<br>Text: automatically reveal the hidden important information from an images and their involvement with AI, ...",
          "Type: research_papers<br>Text: these characteristics, the model can provide a comprehensive images. The use of an end-to-end integr...",
          "Type: research_papers<br>Text: elevating a higher degree of accurate diagnosis for oncologists models such as VGG16, VGG19, DenseNe...",
          "Type: research_papers<br>Text: the powerful application of different deep learning algorithms, finally, some machine learning-based...",
          "Type: research_papers<br>Text: noise reduction using Gaussian blur, applying CLAHE for guidance without labels, leveraging unlabele...",
          "Type: research_papers<br>Text: each step in this pipeline deals with one of the issues pertaining breast ultrasound image segmentat...",
          "Type: research_papers<br>Text: Diagnosis of breast cancer segmentation is mainly relied on architectures combining network performa...",
          "Type: research_papers<br>Text: radiology experts. To underline these challenges, our study research emphasized more on ultrasonic i...",
          "Type: research_papers<br>Text: inconsistencies and assists oncologists in planning kernels improve feature extraction over log-Gabo...",
          "Type: research_papers<br>Text: results, our approach bridges the gap between computational tumor segmentation to assist doctors and...",
          "Type: research_papers<br>Text: (1) Proposed a segmentation approach using deep learning modal data, and alternatives to machine lea...",
          "Type: research_papers<br>Text: false positives in BUS images, especially for automated fibroglandular tissue, and vessels and provi...",
          "Type: research_papers<br>Text: The authors of this study introduced a geometric model and 3. METHODOLOGY\ncomputational algorithm fo...",
          "Type: research_papers<br>Text: algorithms of deep learning specifically U-Net, MultiResUNet,\nprobability distribution models grey-l...",
          "Type: research_papers<br>Text: and demonstrated on fetal echography and echocardiography\nalso enables the precise localization of t...",
          "Type: research_papers<br>Text: classification from the use of CNN ensemble with VGG19 and\nnormalization is important, producing mor...",
          "Type: research_papers<br>Text: innovation lies in their combination and sequencing with\nmasses themselves that proved crucial for a...",
          "Type: research_papers<br>Text: automatically. A host of techniques involves the use of CNNs,\nthe images and augmentation integrates...",
          "Type: research_papers<br>Text: breast masses and providing support to classify them, focusing\nmore accurate tumor boundary detectio...",
          "Type: research_papers<br>Text: embedded AI system in both the diagnostic and surgical\nthe whole process is carried out is visualize...",
          "Type: research_papers<br>Text: combined in the same directory for three different labels. The\nimaging and diagnostic accuracies. Ma...",
          "Type: research_papers<br>Text: systematically segregating images and corresponding masks\nboth global and local statistical methods,...",
          "Type: research_papers<br>Text: Table 1. Algorithm performance with and without using pipeline\nPipeline Algorithm Accuracy F1-Score ...",
          "Type: research_papers<br>Text: DeeplabV3+Resnet50 0.95892 0.76974 0.68537 0.85848 0.77802\nData+Normalization+Gaussian\nMultiResUnet ...",
          "Type: research_papers<br>Text: the image with a Gaussian kernel, essentially averaging the\npixel values in a localized neighborhood...",
          "Type: research_papers<br>Text: noisy data, Gaussian blur further reduced the impact of outliers\nand extreme intensity variations th...",
          "Type: research_papers<br>Text: size. It also controls the amount of blurring added to the image.\nHere, (5,5) is the size of the nei...",
          "Type: research_papers<br>Text: image analysis relevant to clinical practice.\n3.2 Implementing CLAHE\nThe next process in the pipelin...",
          "Type: research_papers<br>Text: Although normalization aligns pixel values and Gaussian blur\nFigure 1. Overall system representation...",
          "Type: research_papers<br>Text: values with the aim to allow more efficient image analysis.\nOutput: Separated directories for images...",
          "Type: research_papers<br>Text: Construct image_path using path, class_names, and counter:\ncharacteristics detection. CLAHE also cov...",
          "Type: research_papers<br>Text: 4. Read the image from image_path and the mask from\nway of pixel redistribution occurs across the im...",
          "Type: research_papers<br>Text: challenges posed by limited datasets and enhance their model's\nperformance. Data augmentation involv...",
          "Type: research_papers<br>Text: spiculated mass not just at the centroids but also by by our optimized preprocessing pipeline, guara...",
          "Type: research_papers<br>Text: it was trained on features extracted from images that simulated working.\nvarious conditions like rea...",
          "Type: research_papers<br>Text: then constructed a data augmentation training strategy that\nincorporated data augmentation into thei...",
          "Type: research_papers<br>Text: between 0 and 1. Uniformity in pixel values in images was a a wide variety of deep learning algorith...",
          "Type: research_papers<br>Text: extreme intensities could easily skew the model training. The and predicted segmentation masks. The ...",
          "Type: research_papers<br>Text: features in the images more accurately and generally. The scrutinized by the authors, which gives in...",
          "Type: research_papers<br>Text: cancer diagnostic outcomes. great depths of understanding that covers the trend of results\nobtained ...",
          "Type: research_papers<br>Text: Net was used as the baseline model because of its all-round NVIDIA GeForce RTX 3050 GPU (4GB VRAM) a...",
          "Type: research_papers<br>Text: allow the network to extract fine-grained texture patterns, rate of 1e-3, a batch size of 6, and 60 ...",
          "Type: research_papers<br>Text: similar tumor regions while maintaining boundary precision. To overcome on generalization, we integr...",
          "Type: research_papers<br>Text: encoder-decoder architectures used in the networks of these applied to suppress high-frequency noise...",
          "Type: research_papers<br>Text: 4.2 Results without pre-processing score of 0.12, that underscores the inadequacy of the initial\nmod...",
          "Type: research_papers<br>Text: Thus, the algorithm is drawn to the raw image data which performance. The natural reasons can be att...",
          "Type: research_papers<br>Text: and Unet in Figures 4 and 5 respectively, we can say that becomes challenging for them to accurately...",
          "Type: research_papers<br>Text: would be lower Jaccard scores.\nHowever, promisingly, the coming sections hold the\npromise of unveili...",
          "Type: research_papers<br>Text: of confronting this complex medical image segmentation task.\n4.3 Results with pre-processing\nWe succ...",
          "Type: research_papers<br>Text: pipeline tumor segmentations as we progressively add each part of the\npipeline that includes noise r...",
          "Type: research_papers<br>Text: Figure 7. Noise reduction using Gaussian blur on an image\nFigure 6. Training and validation accuracy...",
          "Type: research_papers<br>Text: The pipeline's first preprocessing step is Gaussian blur, which mapped to be between about the same ...",
          "Type: research_papers<br>Text: particularly with breast cancer ultrasounds, which are known and increases the degree to which the m...",
          "Type: research_papers<br>Text: induced inconsistencies. Although this is the first step ahead pipeline systematically handles inher...",
          "Type: research_papers<br>Text: usage of CLAHE and how the application of this technique images toward a standardized dataset. This ...",
          "Type: research_papers<br>Text: better for accuracy in segmentation results. This keeps the performs within the pipeline. Also, we a...",
          "Type: research_papers<br>Text: medical images in producing better reliability and accuracy in\ntheir segmentations.\nThe obtained res...",
          "Type: research_papers<br>Text: algorithms to train these sets altogether. This makes the model\nmore resilient to variations of seve...",
          "Type: research_papers<br>Text: pipeline. Figure 10 shows how normalizing pixel values helps\nFigure 10. Final Segmentation results a...",
          "Type: research_papers<br>Text: Figure 12. Performance of MultiResUnet with the pipeline\nFigure 13. Performance of Unet with the pip...",
          "Type: research_papers<br>Text: Attention U-Net [28] CNN-based Segmentation 0.9500 (Acuuracy) 2024\nTable 1 presents the segmentation...",
          "Type: research_papers<br>Text: decoder structure for ultrasound image segmentation. The noise, poor contrast, and complex textures ...",
          "Type: research_papers<br>Text: extracting multi-scale contextual features by leveraging atrous contrast and tumor boundary visibili...",
          "Type: research_papers<br>Text: Table 2 provides a comparison between existing state-of- Ultrasonics, 65: 51-58.\nthe-art segmentatio...",
          "Type: research_papers<br>Text: 3(1): 100068.\nhttps://doi.org/10.1016/j.wfumbo.2024.100068\n5. CONCLUSION [7] National Breast Cancer ...",
          "Type: research_papers<br>Text: preprocessing techniques with three state-of-the-art deep intelligence in breast ultrasound. World J...",
          "Type: research_papers<br>Text: outperforming several existing methods and demonstrating the of breast cancer from ultrasound images...",
          "Type: research_papers<br>Text: preprocessing. In addition, challenging cases such as small and future direction. Diagnostics, 13(1)...",
          "Type: research_papers<br>Text: deep learning networks which requisite lesser computation and fusion. Sensors, 22(3): 807.\nleveragin...",
          "Type: research_papers<br>Text: computer-assisted breast cancer diagnostic. learning. Informatics in Medicine Unlocked, 41: 101317.\n...",
          "Type: research_papers<br>Text: Abdulrahman University Researchers Supporting Project [14] Abo-El-Rejal, A., Ayman, S., Aymen, F. (2...",
          "Type: research_papers<br>Text: [1] World Health Organization. Breast cancer. for segmentation and classification of breast ultrasou...",
          "Type: research_papers<br>Text: of Clinical Oncology, 13(3): 209-218. IEEE 12th International Conference on Healthcare\nhttps://doi.o...",
          "Type: research_papers<br>Text: 3026.41869 images. IEEE Transactions on Information Technology\n[4] U.S. Food and Drug Administration...",
          "Type: research_papers<br>Text: https://doi.org/10.1007/s00266-024-04074-2 learning model and dataset for segmentation of breast,\n[1...",
          "Type: research_papers<br>Text: Medical Physics, 24(1): e13863. Maximum likelihood segmentation of ultrasound images\nhttps://doi.org...",
          "Type: research_papers<br>Text: segmentation and deep learning techniques. Artificial [25] Tanaka, H., Chiu, S.W., Watanabe, T., Kao...",
          "Type: research_papers<br>Text: image-segmentation-deep-learning-techniques-ranjitha- [26] Pramanik, P., Pramanik, R., Schwenker, F....",
          "Type: research_papers<br>Text: 790.https://doi.org/10.1016/S0167-8655(02)00181-2 AAU-net: An adaptive attention U-net for breast le...",
          "Type: research_papers<br>Text: 200(S1): 113876. based on attention U-Net. In Proceedings of the 2nd\nhttps://doi.org/10.1016/j.ejca....",
          "Type: research_papers<br>Text: 2023 6th International Conference on Contemporary Computing and Informatics (IC3I)\nFall Detection Me...",
          "Type: research_papers<br>Text: Abhiraj Sandeep Gadade Mamoon Rashid\nResearch Center of Excellence Research Center of Excellence\nfor...",
          "Type: research_papers<br>Text: detection systems for elderly people. Caretakers face serious in overall mobility. As the average ag...",
          "Type: research_papers<br>Text: difficulties with effective implementation of these techniques,\nWith an increasing trend of global m...",
          "Type: research_papers<br>Text: and responsiveness of vision-based systems. This study also separation can be particularly distressi...",
          "Type: research_papers<br>Text: Important data on elderly falls is also provided to further\nprompt aid from loved ones can exacerbat...",
          "Type: research_papers<br>Text: and well-being of senior people automatic fall detection, and communication with family\nmembers or h...",
          "Type: research_papers<br>Text: I. INTRODUCTION\nincreasing day by day.\nThe phenomenon of falls among elderly individuals has\nIn rece...",
          "Type: research_papers<br>Text: has garnered significant attention. Understanding the\nsignificant concern, often resulting in seriou...",
          "Type: research_papers<br>Text: unobtrusive and effective fall detection systems. By\nmobility, chronic health conditions, medication...",
          "Type: research_papers<br>Text: 2477\n979-8-3503-0448-0/22/$31.00 ©2023 IEEE\n11879301.3202.71195I3CI/9011.01\n:IOD\n|\nEEEI\n3202©\n00.13$...",
          "Type: research_papers<br>Text: 2023 6th International Conference on Contemporary Computing and Informatics (IC3I)\nA significant inc...",
          "Type: research_papers<br>Text: survey paper aims to comprehensively review and compare categories [2]. This research displays the p...",
          "Type: research_papers<br>Text: today's dynamic and diverse environments, seeking to emphasizes the benefits of developing multimoda...",
          "Type: research_papers<br>Text: analysis of the state-of-the-art techniques, this survey aims to underlying algorithms and the metho...",
          "Type: research_papers<br>Text: aging society. research [4]. The authors of this paper have presented the\nthree stages of a fall, in...",
          "Type: research_papers<br>Text: contributions for the fall detection systems in the systems, as well as showcasing recent works on t...",
          "Type: research_papers<br>Text: all researchers world-wide, i.e., sensor based and which is affordable, inconvenient, but accurate; ...",
          "Type: research_papers<br>Text: the challenges of the well-known research in this Programmable Gate Arrays [FPGAs] and provides an\nd...",
          "Type: research_papers<br>Text: detection method. In order to gather information about the\n• Detailed methodology of the fall detect...",
          "Type: research_papers<br>Text: the fall detection research and have also covered the key approaches have gained popularity in the l...",
          "Type: research_papers<br>Text: three criteria: sensor, performance, and algorithms [1]. The accelerometers, gyroscopes, and pressur...",
          "Type: research_papers<br>Text: 2023 6th International Conference on Contemporary Computing and Informatics (IC3I)\nreadily available...",
          "Type: research_papers<br>Text: volumes of sensor data, enabling the creation of sophisticated the system can accurately recognize f...",
          "Type: research_papers<br>Text: scenarios and individuals. The combination of sensor-based assistance for individuals at risk of fal...",
          "Type: research_papers<br>Text: injuries, and providing timely assistance when needed. initial step in the fall detection process, a...",
          "Type: research_papers<br>Text: various factors, including sensor inaccuracies,\nmovement irregularities, and environmental\ninterfere...",
          "Type: research_papers<br>Text: related movements. Features can include statistical\nparameters (mean, variance, skewness), frequency...",
          "Type: research_papers<br>Text: A. Sensor Based Approach information to the classification stage.\nThe methodology for fall detection...",
          "Type: research_papers<br>Text: magnetometers, are strategically placed on the body or within specific features based on empirical o...",
          "Type: research_papers<br>Text: extraction, and classification stages. Preprocessing involves short time frame, it could indicate a ...",
          "Type: research_papers<br>Text: distinguish between normal activities and fall events. Finally, their adaptability to different scen...",
          "Type: research_papers<br>Text: 2023 6th International Conference on Contemporary Computing and Informatics (IC3I)\nimage acquisition...",
          "Type: research_papers<br>Text: and their relationships. While these systems can provide recorded and pre-processed. Then, using fea...",
          "Type: research_papers<br>Text: machine learning techniques, such as deep neural networks,\nSensors are the heart of this approach. T...",
          "Type: research_papers<br>Text: Sensors Functionality image-based solutions are suited for a variety of settings and\nMeasures accele...",
          "Type: research_papers<br>Text: rotational movements and helps determine\nlooked into how to capture human postures and motions using...",
          "Type: research_papers<br>Text: and recurrent neural networks, among other deep learning\nMeasures changes in atmospheric pressure.\nP...",
          "Type: research_papers<br>Text: Measurement Unit sometimes magnetometer data to provide\n(IMU) comprehensive information about motion...",
          "Type: research_papers<br>Text: (IoT) technology integration. Real-time data gathering, especially the elderly, by facilitating quic...",
          "Type: research_papers<br>Text: platform. As a result, fall incidents can be continuously sensor-based fall detection systems that m...",
          "Type: research_papers<br>Text: daily activity patterns via mobile applications or web placements to provide both effective fall det...",
          "Type: research_papers<br>Text: fall detection systems to analyse photos or video streams and behaviours. To achieve high detection ...",
          "Type: research_papers<br>Text: 2023 6th International Conference on Contemporary Computing and Informatics (IC3I)\nvalues for fall d...",
          "Type: research_papers<br>Text: especially on devices with limited capabilities.\nTABLE II. RELATED WORKS WITH THEIR CHALLENGES\nResea...",
          "Type: research_papers<br>Text: 93% 2023\naccelerometer data from smartphones.\nA fall detection technique utilizing a\ncombination of ...",
          "Type: research_papers<br>Text: Created LSTM network employed as\nChainarong Millimeter -Wave intelligent classifier and millimeter w...",
          "Type: research_papers<br>Text: [16]\ndetection system.\n1. Sensor Modalities Integration 99.56%\nXiaodan Wu a, etc.\nMobile Sensors.\nUs...",
          "Type: research_papers<br>Text: no. 3: 418. https://doi.org/10.3390/app8030418.\nelderly people has resulted in notable breakthroughs...",
          "Type: research_papers<br>Text: [3] V. -R. Xefteris, A. Tsanousa, G. Meditskos, S. Vrochidis and I.\ntechniques address issues such d...",
          "Type: research_papers<br>Text: [4] Muhammad Mubashir, Ling Shao, Luke Seed, “A survey on fall\nocclusions, and privacy issues relate...",
          "Type: research_papers<br>Text: Yazdani, Kumbesan Sandrasegaran, Practical fall detection based on\ndataset variability, resource lim...",
          "Type: research_papers<br>Text: International.Volume 2020 | Article ID 2167160 |\nthese problems. Fall detection systems will effecti...",
          "Type: research_papers<br>Text: Emirates, 2014, pp. 1-4, doi: 10.1109/NTMS.2014.6814018.\n[8] Chen, Gorong & Islam, Mohaiminul. (2019...",
          "Type: research_papers<br>Text: 2023 6th International Conference on Contemporary Computing and Informatics (IC3I)\nInternational Con...",
          "Type: research_papers<br>Text: 2. Vol. 998. Springer Nature, 2023.\n[11] Shukralia, Sakshi, M. P. S. Bhatia, and Pinaki Chakraborty....",
          "Type: research_papers<br>Text: \"Millimeter-Wave Radar-Based Elderly Fall Detection Fed by One-\nDimensional Point Cloud and Doppler,...",
          "Type: research_papers<br>Text: [15] Mekruksavanich, S., Jantawong, P., Hnoohom, N., Jitpattanakul, A.\n(2022). Wearable Fall Detecti...",
          "Type: research_papers<br>Text: human fall detection systems using deep learning: A review, Computers\nin Biology and Medicine, Volum...",
          "Type: research_papers<br>Text: 2/14/26, 11:05 PM Role of big data analytics in healthcare systems | Medical Imaging Informatics\n🔍 🛒...",
          "Type: research_papers<br>Text: Authors: Prathamesh Suhas Uravane, Vedant Vinay Ganthade, Adityaraj Sanjay Belhe, Abhiraj Sandeep\nGa...",
          "Type: research_papers<br>Text: its features and practicality but, data quality, integrating it with other physical, cloud systems, ...",
          "Type: research_papers<br>Text: trials, insurance claims, etc. Just imagine the amount of data produced by every multinational\nhospi...",
          "Type: research_papers<br>Text: 2/14/26, 11:05 PM Role of big data analytics in healthcare systems | Medical Imaging Informatics\nwhi...",
          "Type: research_papers<br>Text: References\n1. Sen, C. K. (2021). Human wound and its burden: updated 2020 compendium of estimates. A...",
          "Type: research_papers<br>Text: reporting in medical research: a cross-disciplinary bibliometric analysis. The Lancet, 393(10171), 5...",
          "Type: research_papers<br>Text: preserving big data scheme for healthcare clouds and applications. IEEE Journal of Biomedical and He...",
          "Type: research_papers<br>Text: 2/14/26, 11:05 PM Role of big data analytics in healthcare systems | Medical Imaging Informatics\n7. ...",
          "Type: research_papers<br>Text: intelligence in healthcare systems: state-of-the-art survey. In 2021 2nd International Conference on...",
          "Type: research_papers<br>Text: analytics and applications. In 2020 4th International Conference on Intelligent Computing and Contro...",
          "Type: research_papers<br>Text: Systems Journal, 2(4), 189–196.\nGoogle Scholar\n13. Rashid, M., Singh, H., Goyal, V., Ahmad, N., and ...",
          "Type: research_papers<br>Text: Revolution: Implementation of Artificial Intelligence for Growing Business Success, pp. 217–229.\nGoo...",
          "Type: research_papers<br>Text: 2/14/26, 11:05 PM Role of big data analytics in healthcare systems | Medical Imaging Informatics\nGoo...",
          "Type: research_papers<br>Text: Data Research, 2(2), 59–64.\nGoogle Scholar\n18. Chen, C., Li, K., Ouyang, A., Zeng, Z., and Li, K. (2...",
          "Type: research_papers<br>Text: Engineering, 5(1), 567–571.\nGoogle Scholar\n20. Harb, H., Mroue, H., Mansour, A., Nasser, A., and Mot...",
          "Type: research_papers<br>Text: hospitals: a scoping review. BMC Health Services Research, 22(1), 134.\nGoogle Scholar\n23. Galetsi, P...",
          "Type: research_papers<br>Text: 2/14/26, 11:05 PM Role of big data analytics in healthcare systems | Medical Imaging Informatics\nGoo...",
          "Type: research_papers<br>Text: data analytics. In 2017 International Conference on Innovations in Information, Embedded and\nCommuni...",
          "Type: research_papers<br>Text: health care systems. In 2019 International conference on automation, computational and technology\nma...",
          "Type: resume<br>Text: Uravane Prathamesh Suhas\nMalewadi-Akluj,Dist-Solapur,Maharashtra,India,413101\nIndia | (+91)976639006...",
          "Type: resume<br>Text: (Class XII) Jadhav-wadi Secondary Education\nSecondary School Sadashivrao Maharashtra State Board\nCer...",
          "Type: resume<br>Text: Experience:\nSr. no Employer Designation Description Duration\nUniversidad Maria AI Engineer Currently...",
          "Type: resume<br>Text: Yodda Elder Care Developed Computer\nVision based Fall detection\nTechnologies Pvt Computer Vision\nsys...",
          "Type: resume<br>Text: Tumors”.\nConference : 5th IEEE International Conference on Contemporary Computing and Informatics (I...",
          "Type: resume<br>Text: SCOPUS Kings Way, Stevenage, SG1 2UA, United Kingdom (published)\n▪ Research Paper: Advanced Preproce...",
          "Type: resume<br>Text: July 24 simulations Virtually. Personalized feedback system is also under implementation to give use...",
          "Type: resume<br>Text: 2.\nBuilt a student’s attentiveness Monitoring system online classes using computer vision\nMay 24 tec...",
          "Type: resume<br>Text: Student Dropout Prediction System\n3.\nImplemented a student dropout prediction system using ensemble ...",
          "Type: resume<br>Text: (UMA,Lima, Technologies: Python / FastAPI / Gradio / Machine Learning / MySQL / Data Preprocessing /...",
          "Type: resume<br>Text: March 24 platform Kaggle. The preprocessing pipeline improves images using various pre-processing\n- ...",
          "Type: resume<br>Text: Technologies: Python / TensorFlow / Keras / OpenCV / U-Net / ResNet / VGG16 / Image\nPreprocessing / ...",
          "Type: resume<br>Text: - used an artificial neural network (ANN) model which resulted in achieving high accuracy in\nMarch 2...",
          "Type: resume<br>Text: 6. Data\nBuilt a dyslexia detection system using handwritten digit data with Multi-model approach, wi...",
          "Type: resume<br>Text: Preprocessing / Pickle\nGAN-Based Realistic Road Scenario Generation for Enhancing Autonomous Vehicle...",
          "Type: resume<br>Text: (ERI@N,NTU, safer and more reliable vehicle perception in dynamic road situations.\nSingapore)\nTechno...",
          "Type: resume<br>Text: Jan 23\n- Implemented logic for emergency scenario detection using advanced computer vision technique...",
          "Type: resume<br>Text: models. Integrated functionalities like alarm triggering and snapshot delivery in milliseconds,\n(Yod...",
          "Type: resume<br>Text: - validation, result processing, login authentication, and special cases like student failures. It\nD...",
          "Type: resume<br>Text: Jun 22 images, achieving 96% accuracy with minimal computational power. The project consisted of\n- i...",
          "Type: resume<br>Text: Academic Courses:\n▪ Research Integrity Course - Certified, Nanyang Technological University, Singapo...",
          "Type: resume<br>Text: ▪ Research paper Presentation- C3I22 IEE conference - 2022\n▪ ‘Machine Learning Study Jams’ host (spo...",
          "Type: resume<br>Text: ▪ Poetry – 1st position - Aarambha 2021 (University’s Cultural Festival) – 2021\n▪ Fashion – 2nd posi...",
          "Type: resume<br>Text: Prathamesh Uravane\nWashington DC, Baltimore Area | +1 (732) 318-9234 | upratham2002@gmail.com\nlinked...",
          "Type: resume<br>Text: ● AI/ML Core Team Member, Google Developer Student Club\nTECHNICAL SKILLS\nMachine Learning: Sci-kit L...",
          "Type: resume<br>Text: ● Developed an AI-powered virtual lab simulator integrated with a student feedback system to give in...",
          "Type: resume<br>Text: ● Implemented GAN model to generate realistic road scenarios to enhance robustness of the perception...",
          "Type: resume<br>Text: Student Researcher Jun 2022 – Aug 2022\nVU Research Centre of Excellence for Health Informatics Pune,...",
          "Type: resume<br>Text: approach helped to boost accuracy. Results are saved for further analysis, enabling robust and relia...",
          "Type: resume<br>Text: generate clean, shareable meeting minutes automatically. (Python / HuggingFace / Gradio / ML / Genai...",
          "Type: resume<br>Text: key management.\nPUBLICATIONS\n1. IIETA: Efficient Segmentation Approach for the Traceability of Breas...",
          "Type: resume<br>Text: ● Compared ANN and Random Forests models for maternal health risk classification using clinical feat...",
          "Type: resume<br>Text: Prathamesh Uravane\nWashington DC, Baltimore Area | +1 (732) 318-9234 | upratham2002@gmail.com\nlinked...",
          "Type: resume<br>Text: ● AI/ML Core Team Member, Google Developer Student Club\nTECHNICAL SKILLS\nMachine Learning: Sci-kit L...",
          "Type: resume<br>Text: ● Developed an AI-powered virtual lab simulator integrated with a student feedback system to give in...",
          "Type: resume<br>Text: ● Implemented GAN model to generate realistic road scenarios to enhance robustness of the perception...",
          "Type: resume<br>Text: Student Researcher | VU Research Centre of Excellence for Health Informatics | Pune, India. June 202...",
          "Type: resume<br>Text: approach helped to boost accuracy. Results are saved for further analysis, enabling robust and relia...",
          "Type: resume<br>Text: generate clean, shareable meeting minutes automatically. (Python / HuggingFace / Gradio / ML / Genai...",
          "Type: resume<br>Text: key management.\nPUBLICATIONS\n1. IIETA: Efficient Segmentation Approach for the Traceability of Breas...",
          "Type: resume<br>Text: ● Compared ANN and Random Forests models for maternal health risk classification using clinical feat...",
          "Type: resume<br>Text: storage, and analysis across records, medications, trials, and claims—improving handling.\n4. IEEE IC...",
          "Type: transcripts<br>Text: # Higher Secondary Certificate (HSC) — Statement of Marks (February 2020)\n\n## Document type\nHigher S...",
          "Type: transcripts<br>Text: ## Marks obtained\n| Subject | Marks (Max) | Marks Obtained |\n|---|---:|---:|\n| English | 100 | 71 |\n...",
          "Type: transcripts<br>Text: # Secondary School Certificate (SSC) — Maharashtra State Board (March 2018)\n\n## Document type\nSecond...",
          "Type: transcripts<br>Text: ## Examination outcome\n- **Exam:** Secondary School Certificate Examination — **March 2018**\n- **Res...",
          "Type: transcripts<br>Text: 2/14/26, 10:23 PM Testudo - Unofficial Transcript\nUNIVERSITY OF MARYLAND\nCOLLEGE PARK\nOffice of the ...",
          "Type: transcripts<br>Text: Fall 2025\nMAJOR: APPLIED MACHINE LEARNING COLLEGE: GRADUATE SCHOOL\nMSML601 PROBABILITY & STATISTICS ...",
          "Type: transcripts<br>Text: /Div Meth /Add Date Date Date\n======== ==== ======= ======= ==== ==== ======== ======== ========\nMSM...",
          "Type: transcripts<br>Text: MSML606 PCS2 3.00 REG D 10/30/25 10/30/25 10/30/25\nMSML604 PCS3 3.00 REG D 10/30/25 10/30/25 10/30/2...",
          "Type: transcripts<br>Text: 2/14/26, 10:23 PM Testudo - Unofficial Transcript\nMSML606 PCS1 3.00 REG D 10/30/25 10/30/25 10/30/25...",
          "Type: transcripts<br>Text: # Vishwakarma University — B.Tech (Artificial Intelligence & Data Science) Transcript\n\n## Document t...",
          "Type: transcripts<br>Text: ## Academic completion note\nThe transcript states the student has appeared for the **Fourth Year B.T...",
          "Type: transcripts<br>Text: ## Final outcome\n- **Final Grade:** **A+**\n- **Document date / reference:** Dated **29/08/2024** (Re...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:58:33.734019Z | Model: gpt-4.1-nano -->\n\n# AI-in-Production-Healthcare...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **FastAPI framework** for building high-performance APIs\n- Simple, minimal setup s...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository is structured around a minimal FastAPI application:\n- ...",
          "Type: repo_summaries<br>Text: The core of the application is the `FastAPI` instance created in `instant.py`, which exposes a GET e...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`instant.py`**: Contains the main FastAPI application instance and a si...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n1. **Clone the repository:**\n```bash\ngit clone https://github.com/upratham/AI-in-Prod...",
          "Type: repo_summaries<br>Text: 4. **Access the API:**\nOpen your browser or use curl to visit:\n```\nhttp://localhost:8000/\n```\nYou sh...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- No explicit testing or CI configurations are present in the repository.\n- To imple...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No specific contribution guidelines are provided.\n- For contributions, fork ...",
          "Type: repo_summaries<br>Text: ---\n\n*This documentation is based on the current repository contents and structure. If additional fe...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:00:46.918835Z | Model: gpt-4.1-nano -->\n\n# Brain-Tumor-Classification\n...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Utilizes CNN architecture for brain tumor classification.\n- Achieved approximately...",
          "Type: repo_summaries<br>Text: ## Architecture / How It Works\nThe core of the project is implemented within a Jupyter Notebook (`Fi...",
          "Type: repo_summaries<br>Text: While specific code details are not provided here, the structure suggests a standard deep learning p...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nTo set up and run the project:\n1. Clone the repository:\n```bash\ngit clone https://git...",
          "Type: repo_summaries<br>Text: ## How to Use\n- **Training**: Run the cells in the notebook to load data, preprocess, augment, build...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or continuous integration (CI) setup is mentioned in the reposit...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nThe repository includes instructions for contributing:\n- Fork the repository.\n...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** For detailed code implementation, model architecture, and training procedures, refer ...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:58:50.943948Z | Model: gpt-4.1-nano -->\n\n# Breast-Cancer-Segmentation\n...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implements multiple segmentation architectures: U-Net, DeepLabV3+, MultiResUNet.\n-...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe project is structured around three main notebooks:\n- `data_prepro...",
          "Type: repo_summaries<br>Text: The notebooks and source files work together to facilitate a modular segmentation pipeline.\n\n## Nota...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### 1) Environment Setup\nCreate and activate a virtual environment:\n```bash\npython -m...",
          "Type: repo_summaries<br>Text: ## How to Use\n### Data Preprocessing\nOpen and run:\n```bash\njupyter notebook data_preprocessing.ipynb...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or CI configurations are mentioned in the provided data. If pres...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo contribution guidelines are provided in the current documentation.\n\n## Limi...",
          "Type: repo_summaries<br>Text: ---\n\n*Note:* If you require further details on specific scripts or configurations, please clarify or...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:03:22.568460Z | Model: gpt-4.1-nano -->\n\n# upratham/chem_sim\n\n## Overv...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Interactive 3D models of chemical apparatus and experiments.\n- Visualizations of f...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository is structured around React components that leverage Th...",
          "Type: repo_summaries<br>Text: Key files and their roles:\n- `src/index.js`: Entry point, sets up routing and renders the main compo...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- `src/Components/`: React components for different experiments and scene m...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n1. Clone the repository:\n```bash\ngit clone https://github.com/upratham/chem_sim.git\nc...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- The repository includes scripts for testing via `react-scripts test`.\n- No explici...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No specific contribution guidelines are provided.\n- Contributions can be mad...",
          "Type: repo_summaries<br>Text: ---\n\n*Note:* Some details are inferred based on the provided code snippets and file structure. For p...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:39.641176Z | Model: gpt-4.1-nano -->\n\n# Clustering-KMeans-AHC\n\n## O...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implementation of K-Means clustering\n- Implementation of Agglomerative Hierarchica...",
          "Type: repo_summaries<br>Text: The notebook likely contains code cells that execute these steps sequentially, demonstrating the clu...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Environment Setup\n1. (Optional) Create a virtual environment:\n```bash\npython -m v...",
          "Type: repo_summaries<br>Text: ## How to Use\n- Follow the notebook cells to understand data loading, preprocessing, clustering, and...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- No explicit testing or continuous integration setup is indicated.\n- The repository...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No specific contribution guidelines are provided.\n- Users are encouraged to ...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** If you require further details about the internal code logic or specific implementati...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:03:12.452128Z | Model: gpt-4.1-nano -->\n\n# compare-knn-dt-randomforest...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Data loading and preprocessing of the balloons dataset\n- Implementation of KNN, De...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe core of this project is encapsulated within a Jupyter Notebook (`...",
          "Type: repo_summaries<br>Text: The project relies on standard scientific and machine learning libraries, including `numpy`, `pandas...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\nEnsure you have Python installed along with the dependencies listed...",
          "Type: repo_summaries<br>Text: ## How to Use\n- Follow the notebook's steps to load data, preprocess, train models, and visualize re...",
          "Type: repo_summaries<br>Text: ## Deployment\nNo deployment instructions are provided. The project is primarily an analytical notebo...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- The project focuses solely on the balloons dataset; generalizati...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:22.476375Z | Model: gpt-4.1-nano -->\n\n# Dataset\n\n## Overview\nThe **...",
          "Type: repo_summaries<br>Text: ## Architecture / How it works\nThe repository's structure is straightforward:\n- The core content is ...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- `.gitignore`: Defines files and directories to exclude from version contr...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nSince the repository contains only dataset files and no explicit setup scripts:\n- Clo...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- No testing frameworks, CI/CD pipelines, or automation workflows are indicated in t...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No contribution guidelines are provided in the current documentation.\n- Cont...",
          "Type: repo_summaries<br>Text: ---\n\n*Note:* If you require more detailed information about the datasets or additional files, please...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:59:22.771602Z | Model: gpt-4.1-nano -->\n\n# Desktop-Chat-App\n\n## Overvi...",
          "Type: repo_summaries<br>Text: This repository is intended for developers interested in customizing or extending a lightweight chat...",
          "Type: repo_summaries<br>Text: ## Architecture / How It Works\nThe repository comprises two main components:\n\n1. **Client Applicatio...",
          "Type: repo_summaries<br>Text: 2. **WebSocket Server:**\n   - Located in the `server` directory.\n   - Uses the `ws` library to handl...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`app/`**: Contains the Electron app code, including UI (`index.html`), ...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Node.js (version >= 12 recommended)\n- For Linux TTS: `espeak` mus...",
          "Type: repo_summaries<br>Text: # For the server\ncd ../server\nnpm install\n```\n\n### Running the Application\n#### Start the WebSocket ...",
          "Type: repo_summaries<br>Text: 2. **Chat:**\n   - Type your message in the input box.\n   - Press **Send** or hit Enter.\n   - Your me...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or CI configurations are present in the provided files. \n\n## Dep...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- **Security & Authentication:** No mention of user authentication...",
          "Type: repo_summaries<br>Text: ---\n\nFor further details, refer to the individual files and scripts within the repository....",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:01:03.872666Z | Model: gpt-4.1-nano -->\n\n# DL-CNN-Transfer-Learning\n\n#...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implements a custom CNN architecture for multi-class flower classification.\n- Util...",
          "Type: repo_summaries<br>Text: - **`src/data_preprocess.py`**: Loads images from the dataset, resizes them to 200×200 pixels, and e...",
          "Type: repo_summaries<br>Text: The dataset is organized in the `data/flowers` directory, with images categorized into subfolders or...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### 1. Environment Setup\nCreate and activate a virtual environment:\n\n```bash\npython -...",
          "Type: repo_summaries<br>Text: ### 4. Train the Model\nRun the training script:\n\n```bash\npython src/train.py\n```\n\nThis will train th...",
          "Type: repo_summaries<br>Text: ```bash\njupyter notebook src/eval.ipynb\n```\n\nUse the notebook to:\n- Load the trained model.\n- Evalua...",
          "Type: repo_summaries<br>Text: ## Deployment\nNo deployment instructions are provided. The trained models can be saved and integrate...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo specific contribution guidelines are included in the provided data.\n\n## Lim...",
          "Type: repo_summaries<br>Text: ---\n\n*For further details, refer to the code files and the Jupyter Notebook in the `src/` directory....",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:59:59.203233Z | Model: gpt-4.1-nano -->\n\n# upratham/DS-Sleep-Disorder-...",
          "Type: repo_summaries<br>Text: ## Key Features\n\n- Data cleaning and preprocessing, including handling missing values and encoding c...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\n\nThe project workflow is encapsulated within a Jupyter Notebook (`Sle...",
          "Type: repo_summaries<br>Text: 1. **Data Loading:** Reads the dataset from `data/ss.csv`.\n2. **Data Cleaning:** Handles missing val...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n\n- `Sleep_Disorder_analysis.ipynb`: Main notebook containing the entire ana...",
          "Type: repo_summaries<br>Text: ```bash\npip install pandas numpy scikit-learn tensorflow keras matplotlib seaborn imbalanced-learn\n`...",
          "Type: repo_summaries<br>Text: 3. Launch Jupyter Notebook:\n\n```bash\njupyter notebook Sleep_Disorder_analysis.ipynb\n```\n\n4. Open the...",
          "Type: repo_summaries<br>Text: *Note:* Since the project is contained within a single notebook, modifications and reruns are straig...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n\nNo contribution guidelines are provided in the repository. For collaborative ...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** If you need further details on specific implementation aspects or additional files, p...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:03:55.145268Z | Model: gpt-4.1-nano -->\n\n# Face-Differentiator\n\n## Ove...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Uses the Keras implementation of FaceNet for face embedding extraction.\n- Compares...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe core functionality is implemented in the `face.py` script, which ...",
          "Type: repo_summaries<br>Text: The `README.md` provides an overview of the approach, emphasizing embedding extraction, distance cal...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Python environment with `keras_facenet` installed.\n- Access to th...",
          "Type: repo_summaries<br>Text: ### Example\n```\nENTER PATH OF 1st IMG: /path/to/reference.jpg\nENTER PATH to the IMG DIRECTORY: /path...",
          "Type: repo_summaries<br>Text: ### Example Output\n```\n[0.1234]\nSAME\n\n[1.5678]\nDIFFERENT\n```\n\n*Note:* The threshold value (`tresh=1....",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No specific contribution guidelines are included.\n- Users can fork the repos...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** If you require further details or clarification, such as the structure of the face em...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:01.856816Z | Model: gpt-4.1-nano -->\n\n# Feature-Selection-and-Dimen...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Loads and preprocesses pollution dataset with label encoding and handling of negat...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository is organized into modular Python scripts within the `s...",
          "Type: repo_summaries<br>Text: The workflow typically involves:\n1. Loading data.\n2. Preprocessing data.\n3. Applying feature enginee...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n1. Clone the repository:\n```bash\ngit clone https://github.com/upratham/Feature-Select...",
          "Type: repo_summaries<br>Text: ## How to Use\n- To perform only feature engineering visualizations:\n```bash\npython feature_engineeri...",
          "Type: repo_summaries<br>Text: ## Deployment\nThere is no deployment process specified. The code is intended for local analysis and ...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo specific contribution guidelines are provided in the documentation. Feel fr...",
          "Type: repo_summaries<br>Text: ---\n\n*Note:* If you have specific questions about certain parts of the code or need further customiz...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:03:28.387526Z | Model: gpt-4.1-nano -->\n\n# gaussian-mle\n\n## Overview\n`...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implementation of MLE for Gaussian distribution parameters (mean and variance)\n- I...",
          "Type: repo_summaries<br>Text: The notebook probably follows these steps:\n- Load data from CSV\n- Define the likelihood function for...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nSince the repository uses a Jupyter Notebook and Python, the typical setup involves:\n...",
          "Type: repo_summaries<br>Text: ## How to use\nOpen the notebook in Jupyter and follow the embedded instructions. The notebook probab...",
          "Type: repo_summaries<br>Text: ## Deployment\nNo deployment instructions are provided or inferred. The repository appears to be educ...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- The repository appears to focus on a single dataset and a specif...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:15.932628Z | Model: gpt-4.1-nano -->\n\n# iris-softmax-vs-svm\n\n## Ove...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implements and trains both Softmax Regression and SVM classifiers.\n- Evaluates mod...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe core workflow is encapsulated within a Jupyter Notebook (`iris_so...",
          "Type: repo_summaries<br>Text: The setup relies on standard Python data science libraries (`pandas`, `scikit-learn`, `matplotlib`) ...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Environment Setup\n```bash\n# Create and activate a virtual environment\npython -m v...",
          "Type: repo_summaries<br>Text: ## How to Use\n- **Data Preparation**: Replace or modify `Data_Iris.csv` if needed. Ensure it contain...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- No explicit testing or CI configurations are present in the repository.\n- The note...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- The current implementation uses default hyperparameters; hyperpa...",
          "Type: repo_summaries<br>Text: ---\n\n**For more details, visit the [GitHub repository](https://github.com/upratham/iris-softmax-vs-s...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:01:23.636613Z | Model: gpt-4.1-nano -->\n\n# Linear-regressing--Ridge-La...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implementation of linear regression models with Ridge and Lasso regularization.\n- ...",
          "Type: repo_summaries<br>Text: The repository is structured around a single notebook, with supporting files such as the dataset and...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nTo run the project:\n1. Clone the repository:\n   ```bash\n   git clone https://github.c...",
          "Type: repo_summaries<br>Text: *Note:* The exact dependencies are not explicitly listed, but typical packages for such analysis inc...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or continuous integration configurations are mentioned or visibl...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo specific contribution guidelines are provided in the repository.\n\n## Limita...",
          "Type: repo_summaries<br>Text: ---\n\n*This documentation is based solely on the provided repository metadata and file excerpts. For ...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:59:47.129200Z | Model: gpt-4.1-nano -->\n\n# LLM-AI-Company-Brochure-Gen...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **Website Content Scraping:** Utilizes `BeautifulSoup` to extract and clean websit...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe project primarily revolves around scraping website content and fe...",
          "Type: repo_summaries<br>Text: The notebooks likely contain the logic to:\n1. Fetch website content using `scraper.py`.\n2. Send the ...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`scraper.py`:** Contains functions for scraping website titles, text, a...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Python 3.11.x\n- Git\n- Internet connection (for Gemini API)\n- Olla...",
          "Type: repo_summaries<br>Text: 3. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n4. Set up environment variable...",
          "Type: repo_summaries<br>Text: ### Running the Notebooks\n- **Using Gemini (Cloud):**\n```bash\njupyter notebook Brochure_Generater_Ge...",
          "Type: repo_summaries<br>Text: ### Generating Brochures\nWithin the notebooks:\n- Input the scraped content.\n- Select the LLM API (Ge...",
          "Type: repo_summaries<br>Text: *(Note: Actual function names depend on notebook implementation)*\n\n## Testing / CI\nNo explicit testi...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo contribution guidelines are included in the provided data.\n\n## Limitations ...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** For detailed usage, refer to the individual notebooks and the `scraper.py` script. If...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:00:07.610298Z | Model: gpt-4.1-nano -->\n\n# LLM-AI-Website-Summarizer\n\n...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Web scraping using `requests` and `BeautifulSoup`.\n- Supports summarization throug...",
          "Type: repo_summaries<br>Text: ## Architecture / How It Works\nThe repository primarily consists of Jupyter notebooks that perform t...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- `summerizer_Gemini.ipynb`: Presumably another summarization notebook, pos...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Python 3.10+ (recommended based on dependencies)\n- Jupyter Notebo...",
          "Type: repo_summaries<br>Text: ### Running the Notebooks\nStart Jupyter:\n\n```bash\njupyter lab\n# or\njupyter notebook\n```\n\nOpen either...",
          "Type: repo_summaries<br>Text: 3. Run the `summerizer_Openai.ipynb` notebook:\n   - It loads the API key via `python-dotenv`.\n   - U...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or CI configurations are mentioned in the provided data. The foc...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo contribution guidelines are provided in the current documentation.\n\n## Limi...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:59:08.335578Z | Model: gpt-4.1-nano -->\n\n# LLM-Code-Explainer\n\n## Over...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **Student-friendly code explanations:** Tailored responses to help learners grasp ...",
          "Type: repo_summaries<br>Text: ## Architecture / How It Works\nThe core of the application is a Python script (`app.py`) that:\n- Loa...",
          "Type: repo_summaries<br>Text: The repository leverages:\n- `app.py` as the main application script.\n- Environment variables for mod...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`app.py`**: Main script that runs the Gradio chat interface and handles...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### 1) Install and Start Ollama\n```bash\nollama serve\n# In another terminal, pull the ...",
          "Type: repo_summaries<br>Text: ### 4) Run the Application\n```bash\npython app.py\n```\n\n## How to Use\n- Access the local Gradio interf...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- No explicit testing or CI configurations are mentioned in the provided files.\n- De...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- **Model dependency:** Relies on Ollama and specific models (`lla...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:00:40.506121Z | Model: gpt-4.1-nano -->\n\n# LLM-Debate-Competition\n\n## ...",
          "Type: repo_summaries<br>Text: This project is suitable for AI researchers, developers, or enthusiasts interested in multi-agent in...",
          "Type: repo_summaries<br>Text: ---\n\n## Key Features\n- Simulates a debate between two LLM-based competitors, each with customizable ...",
          "Type: repo_summaries<br>Text: ---\n\n## Architecture / How it Works\nThe core functionality is implemented within a Jupyter Notebook ...",
          "Type: repo_summaries<br>Text: 1. Initializing two competitor agents with their respective prompts and personas.\n2. Alternating tur...",
          "Type: repo_summaries<br>Text: ---\n\n## Notable Folders/Files\n- **`Debate_Competittion.ipynb`**: The main interactive notebook for r...",
          "Type: repo_summaries<br>Text: ---\n\n## Setup & Run\n### Prerequisites\n- Python 3.11.x installed.\n- Virtual environment tool (recomme...",
          "Type: repo_summaries<br>Text: 3. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n### Configuration\n- **Using Ol...",
          "Type: repo_summaries<br>Text: - **Using OpenAI API:**\n  - Create a `.env` file with your API key:\n    ```bash\n    OPENAI_API_KEY=\"...",
          "Type: repo_summaries<br>Text: ### Customization\n- Modify the **topic** variable to set the debate subject.\n- Adjust the **system p...",
          "Type: repo_summaries<br>Text: ---\n\n## Deployment\nCurrently, the project is designed for local experimentation within a Jupyter Not...",
          "Type: repo_summaries<br>Text: ---\n\n## Limitations / TODOs (Inferred)\n- The project currently relies heavily on manual configuratio...",
          "Type: repo_summaries<br>Text: ---\n\n## Author\nMaintained by **Prathamesh Uravane**  \nEmail: [upratham2002@gmail.com](mailto:upratha...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:58:58.437625Z | Model: gpt-4.1-nano -->\n\n# LLM-Meeting-Minutes-Generat...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Upload and process audio files (mp3, wav, m4a, etc.)\n- Automatic transcription of ...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe application workflow involves:\n1. Uploading an audio file through...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- `app.py`: Entry point of the application, contains the main logic for tra...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Environment Setup\n1. Clone the repository:\n```bash\ngit clone https://github.com/u...",
          "Type: repo_summaries<br>Text: ### Running the Application\n```bash\npython app.py\n```\nThis will start a local server, typically acce...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nThere is no explicit mention of testing frameworks or CI/CD pipelines in the provide...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo specific contribution guidelines are provided in the repository. For contri...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- **Model Customization:** The default model is `meta-llama/Llama-...",
          "Type: repo_summaries<br>Text: - **Localization:** Currently tailored for Denver council meetings; generalization to other meeting ...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** If you need further details on specific components or configurations, please clarify ...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:36:00.497898Z | Model: gpt-4.1-nano -->\n\n# LLM-RAG-private-knowldge-wo...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **Document Ingestion:** Load and process various document formats (TXT, PDF, DOCX)...",
          "Type: repo_summaries<br>Text: - **Retrieval:** Semantic similarity-based document retrieval to find relevant context.\n- **LLM Inte...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe system orchestrates several components:\n- **Data Ingestion:** Loa...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`src/`**: Core source code implementing ingestion, chunking, embeddings...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Installation\n```bash\n# Clone the repository\ngit clone https://github.com/upratham...",
          "Type: repo_summaries<br>Text: ### Running the System\n- To process documents, build index, and query:\n```python\nfrom src.rag_system...",
          "Type: repo_summaries<br>Text: - Or run the main script:\n```bash\npython main.py\n```\n\n## How to Use\n### Basic Workflow\n```python\nfro...",
          "Type: repo_summaries<br>Text: ### Example Queries\n- Ask questions based on ingested documents.\n- Retrieve relevant context snippet...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- Tests are located in `tests/test_rag.py`.\n- Run tests with:\n```bash\npytest tests/\n...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- Create feature branches.\n- Implement components or fixes.\n- Run tests and ad...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- Currently supports in-memory vector store; external vector DB in...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:59:37.851770Z | Model: gpt-4.1-nano -->\n\n# llm_engineering\n\n## Overvie...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Extensive community-contributed projects across multiple domains\n- Examples of web...",
          "Type: repo_summaries<br>Text: ## Architecture / How it works\nThe repository is organized into multiple folders and files, each rep...",
          "Type: repo_summaries<br>Text: The projects leverage APIs (OpenAI, Ollama, etc.), web scraping libraries, and local or cloud-hosted...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n1. **Clone the repository**\n```bash\ngit clone https://github.com/upratham/llm_enginee...",
          "Type: repo_summaries<br>Text: 4. **Configure API keys**\n- Create a `.env` file with your credentials (OpenAI, Ollama, etc.)\n- Exam...",
          "Type: repo_summaries<br>Text: 5. **Run projects/notebooks**\n- Launch notebooks via Jupyter:\n```bash\njupyter notebook\n```\n- Run scr...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- The repository includes test files under `community-contributions/Reputation_Radar...",
          "Type: repo_summaries<br>Text: ## Contribution notes\n- Contributions are welcomed; see individual project folders for contribution ...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- Many projects rely on API keys and external services; usage cost...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:01:10.827314Z | Model: gpt-4.1-nano -->\n\n# ML-Ensemble\n\n## Overview\n**...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implements bootstrap sampling on a dataset\n- Trains multiple neural networks (usin...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository's main logic resides in the `Ensemble.ipynb` notebook,...",
          "Type: repo_summaries<br>Text: The notebook likely uses libraries such as TensorFlow/Keras for neural networks, scikit-learn for da...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nTo run the project:\n1. Ensure you have Python 3 installed.\n2. Install the required de...",
          "Type: repo_summaries<br>Text: ## How to Use\nWithin the notebook:\n- Run all cells to generate bootstrap samples and train neural ne...",
          "Type: repo_summaries<br>Text: ## Deployment\nThere is no indication of deployment procedures or production-ready code. The project ...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- The project focuses on a simple 2D dataset; scaling to more comp...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:01:42.668030Z | Model: gpt-4.1-nano -->\n\n# ML-flow-exp\n\n## Overview\nTh...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Training Random Forest classifiers on the Wine dataset.\n- Experiment tracking with...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository comprises several Python scripts that perform data loa...",
          "Type: repo_summaries<br>Text: The scripts configure MLflow experiments, start runs, and log relevant data for reproducibility and ...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **mlartifacts/**: Stores model artifacts, including trained models, confi...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nWhile explicit setup instructions are not provided, based on the code and artifacts:\n...",
          "Type: repo_summaries<br>Text: 3. **Run scripts:**\n   - To train a model and log an experiment:\n     ```bash\n     python src/file1....",
          "Type: repo_summaries<br>Text: - **Experiment Management:**\n  Use `mlflow.set_experiment()` to specify experiment names. Results ar...",
          "Type: repo_summaries<br>Text: - **Autologging:**\n  Run `autolog.py` to enable automatic logging of models and metrics without manu...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- **Limited Dataset:** Only the Wine dataset is used; support for ...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** If you require detailed setup instructions, environment configuration, or deployment ...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:00:13.941175Z | Model: gpt-4.1-nano -->\n\n# MLOps-CD-Docker\n\n## Overvie...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Dockerfile for containerizing a Python web app\n- Simple Flask application demonstr...",
          "Type: repo_summaries<br>Text: The application runs a web server on port 5000, accessible from outside the container, allowing user...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Docker installed on your machine.\n\n### Building the Docker Image\n...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- No explicit testing or CI configurations are present in the repository.\n- The appl...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No specific contribution guidelines are provided in the repository.\n- Contri...",
          "Type: repo_summaries<br>Text: ---\n\n*This documentation is based on the provided repository data and file excerpts. For further det...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:00:20.555673Z | Model: gpt-4.1-nano -->\n\n# MLOps-CI\n\n## Overview\n**MLO...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Automated testing of Python functions using pytest\n- Integration with GitHub Actio...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository combines a web application and testing scripts:\n- **ap...",
          "Type: repo_summaries<br>Text: The project structure suggests a focus on:\n- Developing a user-friendly web app (`app.py`)\n- Ensurin...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Python 3.x installed\n- Git installed\n\n### Installation\n1. Clone t...",
          "Type: repo_summaries<br>Text: ### Running the Application\nStart the Streamlit app:\n```bash\nstreamlit run app.py\n```\nThis will open...",
          "Type: repo_summaries<br>Text: ### Running Tests\nExecute the tests with pytest:\n```bash\npytest _test.py\n```\nThis will run all defin...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No specific contribution guidelines are provided in the repository.\n- For co...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** If you need further details about the `project flow` or specific deployment instructi...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:01:54.309502Z | Model: gpt-4.1-nano -->\n\n# MLops-Complete-Pipeline\n\nTh...",
          "Type: repo_summaries<br>Text: ---\n\n## 🎯 Overview\n\n**MLops-Complete-Pipeline** provides a comprehensive framework for developing, t...",
          "Type: repo_summaries<br>Text: ---\n\n## 🔑 Key Features\n\n- **End-to-end ML pipeline** from raw data to evaluated model\n- **Data versi...",
          "Type: repo_summaries<br>Text: ---\n\n## 🏗️ Architecture / How It Works\n\nThe pipeline is orchestrated through **`dvc.yaml`**, which d...",
          "Type: repo_summaries<br>Text: - **Configuration:**\n  - Parameters like test size, max features, hyperparameters are managed in `pa...",
          "Type: repo_summaries<br>Text: - **`.dvc/`**: Contains DVC internal data and cache metadata\n- **`dvclive/`**: Stores live metrics, ...",
          "Type: repo_summaries<br>Text: - `model_evaluation.py`: Evaluates and logs model performance\n- **`dvc.yaml`**: Defines pipeline sta...",
          "Type: repo_summaries<br>Text: ---\n\n## 🚀 Setup & Run\n\n### 1. Clone the Repository\n\n```bash\ngit clone https://github.com/upratham/ML...",
          "Type: repo_summaries<br>Text: ### 4. Initialize DVC and Configure Remote Storage\n\n```bash\ndvc init\ngit add .dvc .dvcignore dvc.yam...",
          "Type: repo_summaries<br>Text: Run specific stages (e.g., model training):\n\n```bash\ndvc repro model_building\n```\n\n### 6. Push Data ...",
          "Type: repo_summaries<br>Text: ### Adjust Parameters\n\n- Modify `params.yaml` (e.g., change `max_features` or hyperparameters)\n- Rer...",
          "Type: repo_summaries<br>Text: ---\n\n## 🤝 Contribution Notes\n\nNo specific contribution guidelines are provided. Contributions should...",
          "Type: repo_summaries<br>Text: ---\n\n## ⚠️ Limitations / TODOs (Inferred)\n\n- **Unclear if requirements are fully specified**; consid...",
          "Type: repo_summaries<br>Text: ---\n\n**For more details, visit the [GitHub repository](https://github.com/upratham/MLops-Complete-Pi...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:30.869507Z | Model: gpt-4.1-nano -->\n\n# MLOps-DVC-Data-Versioning\n\n...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Demonstrates data versioning using DVC\n- Provides sample Python code to create and...",
          "Type: repo_summaries<br>Text: The data is stored in an S3 bucket (`S3/files`) with associated MD5 checksum files for integrity ver...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- `.dvc/`: Contains DVC configuration and ignore files, essential for manag...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nWhile explicit setup instructions are not provided, the following can be inferred:\n1....",
          "Type: repo_summaries<br>Text: ```bash\n   python mycode.py\n   ```\n6. Track data with DVC:\n   ```bash\n   dvc add data/sample_data.cs...",
          "Type: repo_summaries<br>Text: ## How to Use\n- To generate and save a new dataset:\n  ```bash\n  python mycode.py\n  ```\n- To track th...",
          "Type: repo_summaries<br>Text: ## Deployment\nThere is no explicit deployment process outlined. The setup appears to be local develo...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo contribution guidelines are provided in the current documentation. For cont...",
          "Type: repo_summaries<br>Text: ---\n\nFor more details, visit the [GitHub repository](https://github.com/upratham/MLOps-DVC-Data-Vers...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:00:30.932432Z | Model: gpt-4.1-nano -->\n\n# MLOps-Insurance-Project\n\n##...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **End-to-end ML pipeline**: Automates data ingestion, validation, transformation, ...",
          "Type: repo_summaries<br>Text: - **Cloud Storage Support**: Includes modules for AWS cloud storage integration.\n- **Reproducibility...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe project is structured into multiple modules that facilitate a mod...",
          "Type: repo_summaries<br>Text: - **Configuration Files**: Located in the `config/` directory, including `model.yaml` and `schema.ya...",
          "Type: repo_summaries<br>Text: - **Entities**: Data structures and model artifacts (`entity/`).\n  - **Configuration**: Cloud and da...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`Dockerfile`**: Defines the container environment for deployment.\n- **`...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nBased on the provided files:\n1. **Clone the repository**:\n   ```bash\n   git clone htt...",
          "Type: repo_summaries<br>Text: ```bash\n     uvicorn app:app --reload\n     ```\n   - Alternatively, build and run the Docker containe...",
          "Type: repo_summaries<br>Text: ## How to Use\n- **API Endpoints**: Once running, access the API (likely via `http://localhost:8000`)...",
          "Type: repo_summaries<br>Text: ## Deployment\n- Deployment is facilitated via Docker (`Dockerfile`) and possibly the `app.py` FastAP...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- **Unclear if there are automated tests**; adding unit/integratio...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** Some details, such as exact API endpoints, specific pipeline steps, or deployment pro...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:01:17.341436Z | Model: gpt-4.1-nano -->\n\n# NN-Backpropagation\n\n## Over...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implementation of a neural network with one hidden layer\n- Manual implementation o...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe core logic resides in the `back_propogation.ipynb` notebook, whic...",
          "Type: repo_summaries<br>Text: The implementation follows a typical neural network training pipeline:\n1. Initialize weights and bia...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- `back_prpogation.ipynb`: The main Jupyter notebook containing all impleme...",
          "Type: repo_summaries<br>Text: ### Installation\nInstall dependencies via pip:\n```bash\npip install numpy matplotlib jupyter\n```\n\n###...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or continuous integration setup is mentioned or present in the r...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo specific contribution guidelines are provided in the repository.\n\n## Limita...",
          "Type: repo_summaries<br>Text: ---\n\n*This documentation is based solely on the provided repository metadata and file excerpts. For ...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:08.294603Z | Model: gpt-4.1-nano -->\n\n# Non-linear-dimensionality-r...",
          "Type: repo_summaries<br>Text: # Non-linear-dimensionality-reduction\n\nRepository for exploring spectral clustering and nonlinear di...",
          "Type: repo_summaries<br>Text: ---\n\n## Key Features\n\n- **Spectral Clustering from Scratch:** Implements spectral clustering algorit...",
          "Type: repo_summaries<br>Text: ---\n\n## Architecture / How it Works\n\nThe core logic resides within a Jupyter Notebook (`HW8.ipynb`),...",
          "Type: repo_summaries<br>Text: ---\n\n## Notable Folders/Files\n\n- `HW8.ipynb`  \n  The main Jupyter Notebook containing all code, visu...",
          "Type: repo_summaries<br>Text: - `README.md`  \n  This documentation file.\n\n---\n\n## Setup & Run\n\n### Requirements\n\nEnsure you have P...",
          "Type: repo_summaries<br>Text: 2. Launch Jupyter Notebook:\n\n```bash\njupyter notebook HW8.ipynb\n```\n\n3. Open `HW8.ipynb` in your bro...",
          "Type: repo_summaries<br>Text: ---\n\n## Testing / CI\n\nNo explicit testing or continuous integration setup is mentioned or present in...",
          "Type: repo_summaries<br>Text: ---\n\n## Contribution Notes\n\nNo contribution guidelines are provided in the repository. Feel free to ...",
          "Type: repo_summaries<br>Text: ---\n\n## License\n\nThis project is licensed under the MIT License. See the `LICENSE` file for details....",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:47.185279Z | Model: gpt-4.1-nano -->\n\n# OOPS-Python-MLOps\n\n## Overv...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Demonstrates core OOP concepts such as classes, objects, constructors, methods, in...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository is structured around several Python files, each illust...",
          "Type: repo_summaries<br>Text: - **`oops_proj.py`**: Contains the main class `chatbook`, demonstrating encapsulation, static method...",
          "Type: repo_summaries<br>Text: - **`adv_inheritance.py`**: Showcases advanced inheritance concepts such as multilevel, hierarchical...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`README.md`**: Provides an overview and documentation for the repositor...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nTo run the code snippets:\n1. Clone the repository:\n```bash\ngit clone https://github.c...",
          "Type: repo_summaries<br>Text: ## How to Use\n- **`oops1.py`**: Run to see basic class instantiation and attribute access.\n- **`oops...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nThere is no explicit mention of testing frameworks or CI/CD pipelines in the reposit...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- The repository primarily contains example code snippets; it lack...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:01:32.520820Z | Model: gpt-4.1-nano -->\n\n# OpenCV-Basics\n\n## Overview\n...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository is structured around Python scripts and Jupyter notebo...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`camera.py`**: Main script for capturing and displaying video streams.\n...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Python 3.x installed\n- OpenCV (`cv2`) library installed (`pip ins...",
          "Type: repo_summaries<br>Text: ### Running the notebook\nOpen `Basics_cv2.ipynb` in Jupyter Notebook:\n```bash\njupyter notebook Basic...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or Continuous Integration (CI) setup is mentioned or evident fro...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- The repository currently offers basic demonstrations; advanced f...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:03:04.638892Z | Model: gpt-4.1-nano -->\n\n# prathamesh-portfolio-static...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **Responsive Design:** Fully responsive layout optimized for desktop and mobile de...",
          "Type: repo_summaries<br>Text: - **About Section:** Skills overview with categorized badges and professional summary.\n- **Projects ...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe project is structured as a React application using TypeScript, st...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- `src/`: Contains all React components, assets, styles, and configuration ...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n1. Clone the repository:\n```bash\ngit clone https://github.com/upratham/prathamesh-por...",
          "Type: repo_summaries<br>Text: ## How to Use\n- **Customizing Content:** Edit the React components (`Hero.tsx`, `About.tsx`, `Projec...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or CI configurations are present in the provided files. Implemen...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- **No License Specified:** Licensing information is absent; consi...",
          "Type: repo_summaries<br>Text: ---\n\n*Note:* If specific details about deployment, contribution, or additional features are required...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:03:47.935512Z | Model: gpt-4.1-nano -->\n\n# Predicting-House-price-in-B...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Data acquisition from real estate listings\n- Data preprocessing to clean and prepa...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe project follows a structured workflow:\n1. **Data Acquisition:** C...",
          "Type: repo_summaries<br>Text: All steps are implemented within a Jupyter Notebook (`code.ipynb`), which guides the user through ea...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nSince the project is implemented in a Jupyter Notebook, follow these steps to run it:...",
          "Type: repo_summaries<br>Text: *Note:* The notebook may require additional Python libraries such as pandas, scikit-learn, etc. Inst...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or Continuous Integration (CI) setup is mentioned or present in ...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo specific contribution guidelines are provided in the repository.\n\n## Limita...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:58:44.007761Z | Model: gpt-4.1-nano -->\n\n# Production Repository\n\n## O...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Step-by-step guides for deploying AI agents on AWS Bedrock\n- Sample Python project...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository combines educational notebooks, code samples, and infr...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`finale/`**: Contains the main Python project (`pyproject.toml`) for de...",
          "Type: repo_summaries<br>Text: - **`terraform/`** (referenced in scripts): Infrastructure-as-code directory for AWS resource manage...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Python 3.12+ (as specified in `pyproject.toml`)\n- AWS CLI configu...",
          "Type: repo_summaries<br>Text: ### Running the Python Projects\n- To run the main agent code:\n```bash\nuv run <script_name.py>\n```\n- ...",
          "Type: repo_summaries<br>Text: ## How to Use\n### Example: Creating and Invoking an Agent\n1. Create a new Python script (e.g., `my_a...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or CI configurations are detailed in the provided data. It is in...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- Contributions involve creating new markdown or notebook files in `community_...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- The repository appears to be a learning and deployment framework...",
          "Type: repo_summaries<br>Text: ---\n\n*Note: If any specific details about configuration files, environment variables, or additional ...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:53.841809Z | Model: gpt-4.1-nano -->\n\n# supervised-ml-feature-exper...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implementation of multiple supervised classification algorithms.\n- Feature selecti...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository is structured around Jupyter Notebooks that contain th...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **.gitattributes & .gitignore**: Standard Git configuration files to mana...",
          "Type: repo_summaries<br>Text: - `heart-disease-classification.csv`: Additional dataset possibly used for specific experiments.\n- *...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n1. **Clone the repository**:\n```bash\ngit clone https://github.com/upratham/supervised...",
          "Type: repo_summaries<br>Text: *Note:* Since the core files are notebooks, execution involves running cells sequentially within Jup...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- No explicit testing or continuous integration setup is indicated in the repository...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No specific contribution guidelines are provided in the repository.\n- Users ...",
          "Type: repo_summaries<br>Text: ---\n\nFor further details, explore the notebooks and datasets directly in the repository: [GitHub Lin...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:03:41.012793Z | Model: gpt-4.1-nano -->\n\n# UMA-V-2 Repository Document...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **Interactive Practical Modules:** Web pages linking to anatomy, biology, and chem...",
          "Type: repo_summaries<br>Text: - **Responsive Design Elements:** Navigation buttons, modals for user interactions, and styled heade...",
          "Type: repo_summaries<br>Text: ---\n\n## Architecture / How it Works\nThe repository combines static HTML, PHP backend scripts, and JS...",
          "Type: repo_summaries<br>Text: - **Frontend:** HTML pages styled with embedded CSS, providing navigation, user profile sections, an...",
          "Type: repo_summaries<br>Text: - **Resources:** Organized into folders such as `Anatomy_pract_templets`, `Biology_Prac_Templates`, ...",
          "Type: repo_summaries<br>Text: ---...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`Anatomy_pract_templets/`**: Contains anatomy practical templates, 3D m...",
          "Type: repo_summaries<br>Text: - **`dbconnect.php`**: Database connection configuration.\n- **`register.php`**: Handles new user reg...",
          "Type: repo_summaries<br>Text: ---\n\n## Setup & Run\nBased on the provided files:\n\n1. **Database Setup:**\n   - Import `stud_name.sql`...",
          "Type: repo_summaries<br>Text: 3. **Configuration:**\n   - Ensure `dbconnect.php` has correct database credentials matching your MyS...",
          "Type: repo_summaries<br>Text: ## How to Use\n- **User Login:**\n  - Access the login page (not explicitly provided but implied).\n  -...",
          "Type: repo_summaries<br>Text: - **Assessment & Data Entry:**\n  - Teachers or authorized users can input student marks via the `ins...",
          "Type: repo_summaries<br>Text: ---\n\n## Testing / CI\n- No explicit testing or CI/CD pipelines are mentioned in the provided files.\n-...",
          "Type: repo_summaries<br>Text: ---\n\n## Contribution Notes\n- No specific contribution guidelines are provided.\n- To contribute:\n  - ...",
          "Type: repo_summaries<br>Text: ---\n\n## Limitations / Inferred TODOs\n- **Security:** Passwords are hashed, but session management an...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** Some details, such as login pages, detailed user flows, or specific scripts for lab i...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:00:56.003390Z | Model: gpt-4.1-nano -->\n\n# UMA_dropout_prediction_for_...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **Multi-model ensemble prediction:** Combines predictions from several pre-trained...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe system primarily consists of:\n- **Pre-trained models:** Stored as...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`app.py`**: Contains the Gradio interface code for interactive predicti...",
          "Type: repo_summaries<br>Text: - **`base_proyecto.xlsx`**: Likely contains raw or processed data used during model training or anal...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Python environment with necessary libraries (`scikit-learn`, `pan...",
          "Type: repo_summaries<br>Text: ## How to Use\n### Web Interface\n- Access the URL provided after running `app.py`.\n- Fill in student ...",
          "Type: repo_summaries<br>Text: ### API Usage\nSend a POST request with JSON data to `http://127.0.0.1:5000/predict`. Example payload...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or CI configurations are present in the repository. Notable note...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- **Model details unspecified:** The exact models and their traini...",
          "Type: repo_summaries<br>Text: ---\n\n*Note:* If you require detailed instructions on data preprocessing, model training, or deployme...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:59:53.128533Z | Model: gpt-4.1-nano -->\n\n# upratham Repository Documen...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **Showcase of Applied ML Projects:** Includes projects on debate simulation, broch...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nWhile specific implementation details are not provided, the structure...",
          "Type: repo_summaries<br>Text: *Note:* Exact architecture diagrams or detailed workflows are not available.\n\n## Notable Folders/Fil...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nBased on the projects and tools mentioned:\n- To run individual projects, you would ty...",
          "Type: repo_summaries<br>Text: ## How to Use\n- Explore the linked projects in the README for practical examples:\n  - Use the **LLM ...",
          "Type: repo_summaries<br>Text: *Note:* Specific usage instructions are not provided in the excerpt, so users should look for projec...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nThere are no explicit contribution guidelines or notes included in the provide...",
          "Type: repo_summaries<br>Text: ---\n\n*This documentation is based solely on the provided metadata, file excerpts, and inferred conte..."
         ],
         "type": "scatter",
         "x": {
          "bdata": "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",
          "dtype": "f4"
         },
         "y": {
          "bdata": "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",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "height": 600,
        "margin": {
         "b": 10,
         "l": 10,
         "r": 20,
         "t": 40
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "2D Chroma Vector Store Visualization"
        },
        "width": 800,
        "xaxis": {
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": [
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "orange",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "blue",
           "blue",
           "blue",
           "cyan",
           "cyan",
           "cyan",
           "cyan",
           "cyan",
           "cyan",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "pink",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "brown",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "purple",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green"
          ],
          "opacity": 0.8,
          "size": 5
         },
         "mode": "markers",
         "text": [
          "Type: academic achievements<br>Text: This certificate is presented to Prathamesh Suhas Uravane, Vishwakarma University, Pune, India in\nre...",
          "Type: academic achievements<br>Text: Certificate Of Participation\nThis certificate is awarded to\nPrathamesh Uravane\nfor attending the fol...",
          "Type: academic achievements<br>Text: Ref. #AUGN/IC3I/2022/56241/023\nWe acknowledge the participation of Dr./Mr./Ms. Prathamesh Uravane of...",
          "Type: academic achievements<br>Text: # Maharashtra Olympiad Movement (MOM) — District Topper (2015–2016)\n\n## Awardee\n**Uravane Prathamesh...",
          "Type: academic achievements<br>Text: ## Key details\n- **Program:** Maharashtra Olympiad Movement 2015  \n- **Exam:** Standard 8 Science Ol...",
          "Type: academic achievements<br>Text: # Certificate of Appreciation — “ML Study Jams” (Copy)\n\n## Recipient\n**Prathamesh Uravane**\n\n## Over...",
          "Type: academic achievements<br>Text: # Certificate of Appreciation — “ML Study Jams”\n\n## Recipient\n**Prathamesh Uravane**\n\n## Overview\nTh...",
          "Type: academic achievements<br>Text: # Maharashtra Talent Search Examination (MTSE) — Taluka Prize (2017)\n\n## Awardee\n**Mr. Uravane Prath...",
          "Type: academic achievements<br>Text: ## Key details\n- **Exam:** Maharashtra Talent Search Examination (MTSE)  \n- **Standard:** IX  \n- **S...",
          "Type: academic achievements<br>Text: # Maharashtra Talent Search Examination (MTSE) — Special Prize (2018)\n\n## Awardee\n**Mr. Uravane Prat...",
          "Type: academic achievements<br>Text: ## Key details\n- **Exam:** Maharashtra Talent Search Examination (MTSE)  \n- **Standard:** X  \n- **St...",
          "Type: academic achievements<br>Text: Certificate Of Participation\nThis certificate is awarded to\nPrathamesh Uravane\nfor attending the fol...",
          "Type: academic achievements<br>Text: Certificate Of Participation\nThis certificate is awarded to\nPrathamesh Uravane\nfor attending the fol...",
          "Type: academic achievements<br>Text: VU/S&T/AI/2024-25/32 Date: 24/04/2025\nTo,\nMr. Prathmesh Uravane,\nAlumni from 2020 Batch\nAlumni Repre...",
          "Type: academic achievements<br>Text: # SOF International Mathematics Olympiad — Participation (2014)\n\n## Participant\n**Uravane Prathamesh...",
          "Type: academic achievements<br>Text: ## Visual elements\nIncludes an IMO medal graphic and SOF branding....",
          "Type: academic achievements<br>Text: # SOF International Mathematics Olympiad — Participation (2015)\n\n## Participant\n**Uravane Prathamesh...",
          "Type: academic achievements<br>Text: ## Overview\nA **Science Olympiad Foundation (SOF)** certificate of participation for the **9th SOF I...",
          "Type: academic achievements<br>Text: # SOF National Science Olympiad — Participation (2014)\n\n## Participant\n**Uravane Prathamesh S**  \nPa...",
          "Type: academic achievements<br>Text: ## Visual elements\nIncludes an NSO medal graphic labeled **“Class Topper Rank 1”** and a handwritten...",
          "Type: extra cariculam<br>Text: 1\nVishwakarma University proudly presents this\nCertificate of ACHIEVEMENT\nto\nPrathamesh Suhas Uravan...",
          "Type: extra cariculam<br>Text: # Aarambha 2021 – Certificate of Achievement (Poetry – 1st Position)\n\n## Overview\nA **Certificate of...",
          "Type: extra cariculam<br>Text: 2\nVishwakarma University proudly presents this\nCertificate of ACHIEVEMENT\nto\nPrathamesh Suhas Uravan...",
          "Type: extra cariculam<br>Text: # Sports Championship – Certificate of Honour (Basketball)\n\n## Overview\nA **Certificate of Honour** ...",
          "Type: extra cariculam<br>Text: # Vishwayaan 2023 – Certificate of Appreciation (Chess – Runner Up)\n\n## Overview\nA **Certificate of ...",
          "Type: extra cariculam<br>Text: # Yogathon – Gold Certificate (108 Surya Namaskar Rounds)\n\n## Overview\nA **Gold Certificate** from *...",
          "Type: extra cariculam<br>Text: # Director General’s Youth Parliament Championship – Participation (Solapur Rural, 2017)\n\n## Overvie...",
          "Type: internships<br>Text: # NTU Singapore – Internship / Research Attachment Completion\n\n## Certificate Type\n**Certificate of ...",
          "Type: internships<br>Text: # UMA – Internship / Project Completion Certificate (2024)\n\n## Certificate Type\n**Certificate of Com...",
          "Type: internships<br>Text: ## Signed / Dated\n**Lima – July 3, 2024**  \nSigned by **Dr. Gladys Yvonne Morán Paredes (Chancellor ...",
          "Type: research integrity course certificates<br>Text: # NTU Epigeum Research Integrity – Arts & Humanities Track (2023)\n\n## Certificate Type\n**Course Comp...",
          "Type: research integrity course certificates<br>Text: # NTU Epigeum Research Integrity – Biomedical Sciences Track (2023)\n\n## Certificate Type\n**Course Co...",
          "Type: research integrity course certificates<br>Text: # NTU Epigeum Research Integrity – Engineering & Technology Track (2023)\n\n## Certificate Type\n**Cour...",
          "Type: research integrity course certificates<br>Text: # NTU Epigeum Research Integrity – Natural & Physical Sciences Track (2023)\n\n## Certificate Type\n**C...",
          "Type: research integrity course certificates<br>Text: # NTU Epigeum Research Integrity – Social & Behavioural Sciences Track (2023)\n\n## Certificate Type\n*...",
          "Type: research integrity course certificates<br>Text: ## Date\n**20/12/2023**\n\n## Signed By\n**Associate Professor Roderick Bates**  \nNTU Research Integrity...",
          "Type: research_papers<br>Text: 2022 5th International Conference on Contemporary Computing and Informatics (IC3I)\nAn Efficient Deep...",
          "Type: research_papers<br>Text: 202000611@vupune.ac.in 202001143@vupune.ac.in 202001369@vupune.ac.in\nJanvi Anand Pagariya Mamoon Ras...",
          "Type: research_papers<br>Text: changes in lifestyle such as self-driving cars, Google Assistant,\nThe typical technique used by neur...",
          "Type: research_papers<br>Text: scans, in fact in the Covid era, deep learning evolved majorly to create a complete scan of the insi...",
          "Type: research_papers<br>Text: MRI scans of these millions of people are needed to determine if create a complete image of a patien...",
          "Type: research_papers<br>Text: proposed deep learning model, we have implemented\nany patient's scan. Now the real challenge also be...",
          "Type: research_papers<br>Text: analyses them and later forwards them to a neurologist. He\nthen studies these scans. It takes him at...",
          "Type: research_papers<br>Text: dealt with as soon as possible. The different types of tumors cannot produce more neurologists in a ...",
          "Type: research_papers<br>Text: grow in the nervous system [1]. Medically recognized, there in real-time. This process can be largel...",
          "Type: research_papers<br>Text: International Association of Cancer Registries (IACR) in types that are difficult to identify, and e...",
          "Type: research_papers<br>Text: More than 24,000 people die from this disease annually [2]. In using some advanced technology that i...",
          "Type: research_papers<br>Text: percent of the total number of reported cases of the disease [3]. possible by advances in durable ha...",
          "Type: research_papers<br>Text: 2022 5th International Conference on Contemporary Computing and Informatics (IC3I)\nlibraries that ar...",
          "Type: research_papers<br>Text: models [9, 10].\nis the most important part of any deep learning project. This\nThe outline of the pap...",
          "Type: research_papers<br>Text: proposed for building the deep learning model using and testing set is given in Table I.\nconvolution...",
          "Type: research_papers<br>Text: Glioma 826 100\ncan be solved using the same deep learning, but the approach\nused here transfers lear...",
          "Type: research_papers<br>Text: of using CNN for classification and they have achieved 97.5% RGB channels. The RGB channels are the ...",
          "Type: research_papers<br>Text: in their project [13]. batches of the same but visually altered images are generated\nto meet the add...",
          "Type: research_papers<br>Text: classification methods [14]. The author has suggested using a\nthe same feature set and is mostly use...",
          "Type: research_papers<br>Text: tumor classification can be done by using techniques like\nGLCM, CNN, and DWT, and has got high accur...",
          "Type: research_papers<br>Text: of bone fractures and blood cells [17]. In this paper, the author\nhas heavily discussed the problem ...",
          "Type: research_papers<br>Text: where the first is pre-processing of the image, the second stage\nFig. 1. Different tumor images of e...",
          "Type: research_papers<br>Text: 2022 5th International Conference on Contemporary Computing and Informatics (IC3I)\nhad parameters an...",
          "Type: research_papers<br>Text: information. Later with advancements in technologies with mouths, eyes, black patches, etc. Based on...",
          "Type: research_papers<br>Text: ability to learn from its mistakes. This ability of neural\nany animal from some significant features...",
          "Type: research_papers<br>Text: Intelligence. The role of these technologies has evolved due to\nconvolutional filters are trained to...",
          "Type: research_papers<br>Text: Each image comprises pixels and pixel values range from 0\nto 256. The color scale of the image is de...",
          "Type: research_papers<br>Text: normalization, which is mainly done to reduce computational\neffort. The most important part for late...",
          "Type: research_papers<br>Text: us to prepare Y-train and Y-test data to make predictions and\ntrain neural networks accordingly. We ...",
          "Type: research_papers<br>Text: Here, data augmentation is also performed to create slightly\ndifferent sets of modified image data, ...",
          "Type: research_papers<br>Text: tasks like image classification, because of their ability to\nextract features from any image and dec...",
          "Type: research_papers<br>Text: would take effort as it would simply scan all images, which\n1. Batch Size: It is nothing but a numbe...",
          "Type: research_papers<br>Text: 2022 5th International Conference on Contemporary Computing and Informatics (IC3I)\ndecided, as it af...",
          "Type: research_papers<br>Text: 3. Validation Split: Validation data is a type of unseen data\nTABLE II. ALL METRICS’ PERFORMANCE FOR...",
          "Type: research_papers<br>Text: numbers, we can say that there is no overfitting in our model. Glioma\n0.97 0.98 0.97 97\nWe have spec...",
          "Type: research_papers<br>Text: kind of set, which is a tumor in our case. This is calculated as\nper eqn.1:\n(cid:1)(cid:2)(cid:3)(ci...",
          "Type: research_papers<br>Text: more positive samples are detected. This is calculated as per\neqn.2:\n(cid:1)(cid:2)(cid:3)(cid:4) (c...",
          "Type: research_papers<br>Text: (cid:18)∗(cid:2)(cid:4)(cid:20)(cid:14)(cid:15)(cid:15)∗(cid:21)(cid:2)(cid:4)(cid:20)(cid:9)(cid:8)...",
          "Type: research_papers<br>Text: while evaluating our model’s performance and that is the\nconfusion matrix. In Figure 5. we can under...",
          "Type: research_papers<br>Text: 2022 5th International Conference on Contemporary Computing and Informatics (IC3I)\nIn this matrix, t...",
          "Type: research_papers<br>Text: Convolutional Neural Networks”, Department of Computer Science\nVI. CONCLUSION\nand Engineering, Sathy...",
          "Type: research_papers<br>Text: our model and we hope these deep learning models may help\ndoctors to recover patients as soon as pos...",
          "Type: research_papers<br>Text: [15] Tariq Sadad, Amjad Rehman, Asim Munir, Tanzila Saba, Usman\nlayers as well as filters to make br...",
          "Type: research_papers<br>Text: Classification Methodologies”, International journal of scientific\ntremendous and remarkable benefit...",
          "Type: research_papers<br>Text: Pune for providing us a chance to use their high performance Brain Tumor Detection Using Machine Lea...",
          "Type: research_papers<br>Text: Abdel-Badeeh M. Salem. \"Classification using deep learning neural IEEE Xplore.\nnetworks for brain tu...",
          "Type: research_papers<br>Text: using deep neural network and machine learning algorithm.\" In 2019\n9th international conference on c...",
          "Type: research_papers<br>Text: detection and segmentation in MR images using deep learning.\"\nArabian Journal for Science and Engine...",
          "Type: research_papers<br>Text: Rawat, Kamred Udham Singh, Mamoon Rashid, and Ahmed Saeed\nAlGhamdi. \"Deep learning approach for anal...",
          "Type: research_papers<br>Text: various techniques using deep Learning for brain tumor detection.\" In\n2020 International conference ...",
          "Type: research_papers<br>Text: 2025 International Conference on Computational,Communication and Information Technology (ICCCIT)\nCol...",
          "Type: research_papers<br>Text: Prathamesh Suhas Uravane Tareek Pattewar\nAIDS Department Computer Engineering Department\nVishwakarma...",
          "Type: research_papers<br>Text: mid, or high. The features considered are clinical obstetrician is essential for the smooth delivery...",
          "Type: research_papers<br>Text: regularization. The best test accuracy obtained in this\ngynecologists in India aren't registered wit...",
          "Type: research_papers<br>Text: aren’t executed. Risk factors for any pregnant woman are\nmuch better accuracy of 85.71% compared wit...",
          "Type: research_papers<br>Text: appears to better serve toward high accuracy along with health of the pregnant woman & treating them...",
          "Type: research_papers<br>Text: I. INTRODUCTION may face [2]. In the modern era where technology has\nadvanced and every and all amou...",
          "Type: research_papers<br>Text: prehistoric era to the modern world, though the methods\naccurately. Basically, we need a method to p...",
          "Type: research_papers<br>Text: cases and if they are extracted then we would certainly human efforts, but to enhance the results br...",
          "Type: research_papers<br>Text: face this at some point in our life. Doctors aren’t able to dashboards could be made for those pregn...",
          "Type: research_papers<br>Text: whom the ML or DL model has predicted as high risk, for compare the advantages and disadvantages of ...",
          "Type: research_papers<br>Text: various hospitals and clinics. This data includes blood\nDiastolicBP, BS-bloodo sugar levels, HeartRa...",
          "Type: research_papers<br>Text: patients into three distinct classes: low, medium, and high\nbe very accurate - up to 98% [4]. Other ...",
          "Type: research_papers<br>Text: the dataset in question is related to class imbalance-class\nthe mother's age how many pregnancies sh...",
          "Type: research_papers<br>Text: weights for the Random Forest and used class balancing\nat healthcare trends with the Nationwide Inpa...",
          "Type: research_papers<br>Text: through scaling of features to improve the performance of the\nfield [8]. Also, scientists have taken...",
          "Type: research_papers<br>Text: better on this classification task. The ANN is a particularly\npuzzles [9], [10].\npowerful deep learn...",
          "Type: research_papers<br>Text: so often critically impact outcomes. However, the effect of an\nbrought in AI models you can understa...",
          "Type: research_papers<br>Text: interpretable model in machine learning that constructs an\nafter birth. Studies [16] and [17] looked...",
          "Type: research_papers<br>Text: is able to provide insights into the importance of features;\nbeyond Random Forest adding in mental h...",
          "Type: research_papers<br>Text: providing interpretable results with less risk of overfitting\nforward show how AI and ML are changin...",
          "Type: research_papers<br>Text: learning approaches in maternal health risk classification.\nmaternal health have very serious conseq...",
          "Type: research_papers<br>Text: handle identical data. For instance, although ANN may\nrisk cases at an early stage so interventions ...",
          "Type: research_papers<br>Text: interpretability is of importance. In that sense, this work\nthe risk levels for maternal health. Thi...",
          "Type: research_papers<br>Text: type of model would best classify risk across different this healthcare dataset since different feat...",
          "Type: research_papers<br>Text: Temp, and Heart Rate are of different scales; therefore,\nThe ANN model as shown in table 1 is built ...",
          "Type: research_papers<br>Text: reducing the difference in range among features.\nTABLE I. ANN MODEL SUMMARY With preprocessing compl...",
          "Type: research_papers<br>Text: dense_1 (Dense) (None, 128) 8320 low-risk and mid-risk classes. Class imbalance can lead to the\nmode...",
          "Type: research_papers<br>Text: dropout_2 (Dropout) (None, 64) 0\neach class to ensure that errors in predicting minority classes\n(e....",
          "Type: research_papers<br>Text: Total params: 19,203\nrevealed comparatively higher precision and recall scores for\nTrainable params:...",
          "Type: research_papers<br>Text: introduce non-linearity and correct the vanishing gradient\nstopping on validation loss: it stops the...",
          "Type: research_papers<br>Text: of the neurons are randomly disabled. That is, 30% of the\nthe model stops generalizing better on the...",
          "Type: research_papers<br>Text: them.\nsuccess. During early epochs, accuracy gradually increasing\nfrom about 37% to the end, around ...",
          "Type: research_papers<br>Text: activation function has been utilized. Softmax is a very\nHowever, at last, the model reached a test ...",
          "Type: research_papers<br>Text: sparse_categorical_crossentropy, which gives a better fit for\nB. Random Forest\ninteger-encoded targe...",
          "Type: research_papers<br>Text: on structured data. During training, it builds a number of exhaustive search evaluates various param...",
          "Type: research_papers<br>Text: hence improves generalization to unseen data. This will of trees helps determine the ideal balance b...",
          "Type: research_papers<br>Text: majority classes. This, coupled with the inherent ability of samples required to allow a node to be ...",
          "Type: research_papers<br>Text: Machines or k-Nearest Neighbors, even as its explicit class\nweighting serves to advantage. The use o...",
          "Type: research_papers<br>Text: risk are mapped onto the numbers 0 and 1, mid risk is put final Random Forest model on the whole tra...",
          "Type: research_papers<br>Text: BP, BS, Body Temp, and Heart Rate using Standard Scaler. was significantly higher as compared to the...",
          "Type: research_papers<br>Text: when cross-validating with other algorithms that require careful regularization against overfitting,...",
          "Type: research_papers<br>Text: Target variable class imbalance may further influence the better generalization.\npower of the model ...",
          "Type: research_papers<br>Text: heavily for classes poorly represented with more risk and mid contributed to maternal health risk pr...",
          "Type: research_papers<br>Text: minority classes. Class balancing in Random Forests is\nautomated, hence a greater penalty per split ...",
          "Type: research_papers<br>Text: final model accuracy, where the risk classes achieved the model to have a high recall and precision ...",
          "Type: research_papers<br>Text: samples required for a split (min_samples_split), and using multiple dense layers with dropout for r...",
          "Type: research_papers<br>Text: how ensemble-based approaches like Random Forest can\neven benefit from structured datasets with mode...",
          "Type: research_papers<br>Text: Forest has stable accuracy at cross-validation; therefore, its\ngeneral performance is more consisten...",
          "Type: research_papers<br>Text: class because feature distributions of this class overlap hugely\nFig. 1 ANN Training Accuracy. with ...",
          "Type: research_papers<br>Text: confused with other classes. This ANN model seems more\ninclined to put some cases in the low risk cl...",
          "Type: research_papers<br>Text: [5] Khaled Fawagreh & Mohamed Medhat Gaber.\" Resource-efficient fast\nprediction in healthcare data a...",
          "Type: research_papers<br>Text: (2013), “Maternal and fetal risk factors for stillbirth: population based\nstudy,” BMJ, 346(jan24 3),...",
          "Type: research_papers<br>Text: series (MIMB, volume 458).\n[11] M. M. Hosaain, M. A. Kashem and N. M. Nayan, \"Artificial\nV. CONCLUSI...",
          "Type: research_papers<br>Text: 10.1109/SEEDA-CECNSM63478.2024.00035.\nwas able to learn complex, non-linear patterns, the algorithm\n...",
          "Type: research_papers<br>Text: Random Forest model on the other hand surpassed ANN as\n[13] Subhashini, A., Nataraju, K., Rani, S. S...",
          "Type: research_papers<br>Text: on different subsets of the input data, Random Forest 97-8422-6_41\nprovided reliable accuracy across...",
          "Type: research_papers<br>Text: predictive performance for the clinical decision making J. J., Amdur, R., Rice, M. M., & Rodriguez, ...",
          "Type: research_papers<br>Text: [16] Irfan, N., Zafar, S., & Hussain, I. “Holistic Analysis and Development\ntransparency of the mode...",
          "Type: research_papers<br>Text: Classification Of Maternal Risks In Pregnancy: Analysis Using\nMachine Learning And Artificial Neural...",
          "Type: research_papers<br>Text: [2] Ron Southwick,\"Using AI to predict risks for pregnancy & delivery,\" E., Eriz-Salinas, A., Appel-...",
          "Type: research_papers<br>Text: https://doi.org/10.3389/fendo.2023.1130139, (2023).\n[4] Ali Raza, Hafeez Ur Rehman Siddiqui, Kashif ...",
          "Type: research_papers<br>Text: health risk prediction,\" November 9, 2022. AI-driven technologies in maternal and newborn child heal...",
          "Type: research_papers<br>Text: Traitement du Signal\nVol. 42, No. 5, October, 2025, pp. 2913-2922\nJournal homepage: http://iieta.org...",
          "Type: research_papers<br>Text: Maryland 20742, USA\n2 Ira A. Fulton Schools of Engineering, Arizona State University, Arizona 85281,...",
          "Type: research_papers<br>Text: University, Riyadh 11671, Saudi Arabia\n6 Department of Computer Science, College of Computer Science...",
          "Type: research_papers<br>Text: Revised: 26 August 2025 populations, and requires correct detection through early intervention. This...",
          "Type: research_papers<br>Text: Keywords:\nsegmentation in healthcare for the traceability of every breast tissue to improve diagnost...",
          "Type: research_papers<br>Text: favorable rates. The two state-of-the-art deep learning-based instance segmentation\nframeworks are u...",
          "Type: research_papers<br>Text: patient care.\n1.INTRODUCTION with a sonographer is actively involved in the successful\ncapturing of ...",
          "Type: research_papers<br>Text: with 685,000 deaths from breast cancer alone in the year 2020 forms of radiation and magnetic fields...",
          "Type: research_papers<br>Text: disproportionately skimpy. For example, India is a billion-plus breast cancer, very often represent ...",
          "Type: research_papers<br>Text: Similarly, less than 10,000 radiologists for the whole country number of oncologists and sonographer...",
          "Type: research_papers<br>Text: imaging modalities, particularly ultrasound. It plays a very highly important. However, the imbalanc...",
          "Type: research_papers<br>Text: newer ways of bridging the gap. step-by-step technique used in our novel data preprocessing\nIn this ...",
          "Type: research_papers<br>Text: invasively in real-time. But these images can have a subjective The rest of the paper has been organ...",
          "Type: research_papers<br>Text: work, they were used as a reference or gold standard for the presented in Section 4. Finally, the pa...",
          "Type: research_papers<br>Text: automatically reveal the hidden important information from an images and their involvement with AI, ...",
          "Type: research_papers<br>Text: these characteristics, the model can provide a comprehensive images. The use of an end-to-end integr...",
          "Type: research_papers<br>Text: elevating a higher degree of accurate diagnosis for oncologists models such as VGG16, VGG19, DenseNe...",
          "Type: research_papers<br>Text: the powerful application of different deep learning algorithms, finally, some machine learning-based...",
          "Type: research_papers<br>Text: noise reduction using Gaussian blur, applying CLAHE for guidance without labels, leveraging unlabele...",
          "Type: research_papers<br>Text: each step in this pipeline deals with one of the issues pertaining breast ultrasound image segmentat...",
          "Type: research_papers<br>Text: Diagnosis of breast cancer segmentation is mainly relied on architectures combining network performa...",
          "Type: research_papers<br>Text: radiology experts. To underline these challenges, our study research emphasized more on ultrasonic i...",
          "Type: research_papers<br>Text: inconsistencies and assists oncologists in planning kernels improve feature extraction over log-Gabo...",
          "Type: research_papers<br>Text: results, our approach bridges the gap between computational tumor segmentation to assist doctors and...",
          "Type: research_papers<br>Text: (1) Proposed a segmentation approach using deep learning modal data, and alternatives to machine lea...",
          "Type: research_papers<br>Text: false positives in BUS images, especially for automated fibroglandular tissue, and vessels and provi...",
          "Type: research_papers<br>Text: The authors of this study introduced a geometric model and 3. METHODOLOGY\ncomputational algorithm fo...",
          "Type: research_papers<br>Text: algorithms of deep learning specifically U-Net, MultiResUNet,\nprobability distribution models grey-l...",
          "Type: research_papers<br>Text: and demonstrated on fetal echography and echocardiography\nalso enables the precise localization of t...",
          "Type: research_papers<br>Text: classification from the use of CNN ensemble with VGG19 and\nnormalization is important, producing mor...",
          "Type: research_papers<br>Text: innovation lies in their combination and sequencing with\nmasses themselves that proved crucial for a...",
          "Type: research_papers<br>Text: automatically. A host of techniques involves the use of CNNs,\nthe images and augmentation integrates...",
          "Type: research_papers<br>Text: breast masses and providing support to classify them, focusing\nmore accurate tumor boundary detectio...",
          "Type: research_papers<br>Text: embedded AI system in both the diagnostic and surgical\nthe whole process is carried out is visualize...",
          "Type: research_papers<br>Text: combined in the same directory for three different labels. The\nimaging and diagnostic accuracies. Ma...",
          "Type: research_papers<br>Text: systematically segregating images and corresponding masks\nboth global and local statistical methods,...",
          "Type: research_papers<br>Text: Table 1. Algorithm performance with and without using pipeline\nPipeline Algorithm Accuracy F1-Score ...",
          "Type: research_papers<br>Text: DeeplabV3+Resnet50 0.95892 0.76974 0.68537 0.85848 0.77802\nData+Normalization+Gaussian\nMultiResUnet ...",
          "Type: research_papers<br>Text: the image with a Gaussian kernel, essentially averaging the\npixel values in a localized neighborhood...",
          "Type: research_papers<br>Text: noisy data, Gaussian blur further reduced the impact of outliers\nand extreme intensity variations th...",
          "Type: research_papers<br>Text: size. It also controls the amount of blurring added to the image.\nHere, (5,5) is the size of the nei...",
          "Type: research_papers<br>Text: image analysis relevant to clinical practice.\n3.2 Implementing CLAHE\nThe next process in the pipelin...",
          "Type: research_papers<br>Text: Although normalization aligns pixel values and Gaussian blur\nFigure 1. Overall system representation...",
          "Type: research_papers<br>Text: values with the aim to allow more efficient image analysis.\nOutput: Separated directories for images...",
          "Type: research_papers<br>Text: Construct image_path using path, class_names, and counter:\ncharacteristics detection. CLAHE also cov...",
          "Type: research_papers<br>Text: 4. Read the image from image_path and the mask from\nway of pixel redistribution occurs across the im...",
          "Type: research_papers<br>Text: challenges posed by limited datasets and enhance their model's\nperformance. Data augmentation involv...",
          "Type: research_papers<br>Text: spiculated mass not just at the centroids but also by by our optimized preprocessing pipeline, guara...",
          "Type: research_papers<br>Text: it was trained on features extracted from images that simulated working.\nvarious conditions like rea...",
          "Type: research_papers<br>Text: then constructed a data augmentation training strategy that\nincorporated data augmentation into thei...",
          "Type: research_papers<br>Text: between 0 and 1. Uniformity in pixel values in images was a a wide variety of deep learning algorith...",
          "Type: research_papers<br>Text: extreme intensities could easily skew the model training. The and predicted segmentation masks. The ...",
          "Type: research_papers<br>Text: features in the images more accurately and generally. The scrutinized by the authors, which gives in...",
          "Type: research_papers<br>Text: cancer diagnostic outcomes. great depths of understanding that covers the trend of results\nobtained ...",
          "Type: research_papers<br>Text: Net was used as the baseline model because of its all-round NVIDIA GeForce RTX 3050 GPU (4GB VRAM) a...",
          "Type: research_papers<br>Text: allow the network to extract fine-grained texture patterns, rate of 1e-3, a batch size of 6, and 60 ...",
          "Type: research_papers<br>Text: similar tumor regions while maintaining boundary precision. To overcome on generalization, we integr...",
          "Type: research_papers<br>Text: encoder-decoder architectures used in the networks of these applied to suppress high-frequency noise...",
          "Type: research_papers<br>Text: 4.2 Results without pre-processing score of 0.12, that underscores the inadequacy of the initial\nmod...",
          "Type: research_papers<br>Text: Thus, the algorithm is drawn to the raw image data which performance. The natural reasons can be att...",
          "Type: research_papers<br>Text: and Unet in Figures 4 and 5 respectively, we can say that becomes challenging for them to accurately...",
          "Type: research_papers<br>Text: would be lower Jaccard scores.\nHowever, promisingly, the coming sections hold the\npromise of unveili...",
          "Type: research_papers<br>Text: of confronting this complex medical image segmentation task.\n4.3 Results with pre-processing\nWe succ...",
          "Type: research_papers<br>Text: pipeline tumor segmentations as we progressively add each part of the\npipeline that includes noise r...",
          "Type: research_papers<br>Text: Figure 7. Noise reduction using Gaussian blur on an image\nFigure 6. Training and validation accuracy...",
          "Type: research_papers<br>Text: The pipeline's first preprocessing step is Gaussian blur, which mapped to be between about the same ...",
          "Type: research_papers<br>Text: particularly with breast cancer ultrasounds, which are known and increases the degree to which the m...",
          "Type: research_papers<br>Text: induced inconsistencies. Although this is the first step ahead pipeline systematically handles inher...",
          "Type: research_papers<br>Text: usage of CLAHE and how the application of this technique images toward a standardized dataset. This ...",
          "Type: research_papers<br>Text: better for accuracy in segmentation results. This keeps the performs within the pipeline. Also, we a...",
          "Type: research_papers<br>Text: medical images in producing better reliability and accuracy in\ntheir segmentations.\nThe obtained res...",
          "Type: research_papers<br>Text: algorithms to train these sets altogether. This makes the model\nmore resilient to variations of seve...",
          "Type: research_papers<br>Text: pipeline. Figure 10 shows how normalizing pixel values helps\nFigure 10. Final Segmentation results a...",
          "Type: research_papers<br>Text: Figure 12. Performance of MultiResUnet with the pipeline\nFigure 13. Performance of Unet with the pip...",
          "Type: research_papers<br>Text: Attention U-Net [28] CNN-based Segmentation 0.9500 (Acuuracy) 2024\nTable 1 presents the segmentation...",
          "Type: research_papers<br>Text: decoder structure for ultrasound image segmentation. The noise, poor contrast, and complex textures ...",
          "Type: research_papers<br>Text: extracting multi-scale contextual features by leveraging atrous contrast and tumor boundary visibili...",
          "Type: research_papers<br>Text: Table 2 provides a comparison between existing state-of- Ultrasonics, 65: 51-58.\nthe-art segmentatio...",
          "Type: research_papers<br>Text: 3(1): 100068.\nhttps://doi.org/10.1016/j.wfumbo.2024.100068\n5. CONCLUSION [7] National Breast Cancer ...",
          "Type: research_papers<br>Text: preprocessing techniques with three state-of-the-art deep intelligence in breast ultrasound. World J...",
          "Type: research_papers<br>Text: outperforming several existing methods and demonstrating the of breast cancer from ultrasound images...",
          "Type: research_papers<br>Text: preprocessing. In addition, challenging cases such as small and future direction. Diagnostics, 13(1)...",
          "Type: research_papers<br>Text: deep learning networks which requisite lesser computation and fusion. Sensors, 22(3): 807.\nleveragin...",
          "Type: research_papers<br>Text: computer-assisted breast cancer diagnostic. learning. Informatics in Medicine Unlocked, 41: 101317.\n...",
          "Type: research_papers<br>Text: Abdulrahman University Researchers Supporting Project [14] Abo-El-Rejal, A., Ayman, S., Aymen, F. (2...",
          "Type: research_papers<br>Text: [1] World Health Organization. Breast cancer. for segmentation and classification of breast ultrasou...",
          "Type: research_papers<br>Text: of Clinical Oncology, 13(3): 209-218. IEEE 12th International Conference on Healthcare\nhttps://doi.o...",
          "Type: research_papers<br>Text: 3026.41869 images. IEEE Transactions on Information Technology\n[4] U.S. Food and Drug Administration...",
          "Type: research_papers<br>Text: https://doi.org/10.1007/s00266-024-04074-2 learning model and dataset for segmentation of breast,\n[1...",
          "Type: research_papers<br>Text: Medical Physics, 24(1): e13863. Maximum likelihood segmentation of ultrasound images\nhttps://doi.org...",
          "Type: research_papers<br>Text: segmentation and deep learning techniques. Artificial [25] Tanaka, H., Chiu, S.W., Watanabe, T., Kao...",
          "Type: research_papers<br>Text: image-segmentation-deep-learning-techniques-ranjitha- [26] Pramanik, P., Pramanik, R., Schwenker, F....",
          "Type: research_papers<br>Text: 790.https://doi.org/10.1016/S0167-8655(02)00181-2 AAU-net: An adaptive attention U-net for breast le...",
          "Type: research_papers<br>Text: 200(S1): 113876. based on attention U-Net. In Proceedings of the 2nd\nhttps://doi.org/10.1016/j.ejca....",
          "Type: research_papers<br>Text: 2023 6th International Conference on Contemporary Computing and Informatics (IC3I)\nFall Detection Me...",
          "Type: research_papers<br>Text: Abhiraj Sandeep Gadade Mamoon Rashid\nResearch Center of Excellence Research Center of Excellence\nfor...",
          "Type: research_papers<br>Text: detection systems for elderly people. Caretakers face serious in overall mobility. As the average ag...",
          "Type: research_papers<br>Text: difficulties with effective implementation of these techniques,\nWith an increasing trend of global m...",
          "Type: research_papers<br>Text: and responsiveness of vision-based systems. This study also separation can be particularly distressi...",
          "Type: research_papers<br>Text: Important data on elderly falls is also provided to further\nprompt aid from loved ones can exacerbat...",
          "Type: research_papers<br>Text: and well-being of senior people automatic fall detection, and communication with family\nmembers or h...",
          "Type: research_papers<br>Text: I. INTRODUCTION\nincreasing day by day.\nThe phenomenon of falls among elderly individuals has\nIn rece...",
          "Type: research_papers<br>Text: has garnered significant attention. Understanding the\nsignificant concern, often resulting in seriou...",
          "Type: research_papers<br>Text: unobtrusive and effective fall detection systems. By\nmobility, chronic health conditions, medication...",
          "Type: research_papers<br>Text: 2477\n979-8-3503-0448-0/22/$31.00 ©2023 IEEE\n11879301.3202.71195I3CI/9011.01\n:IOD\n|\nEEEI\n3202©\n00.13$...",
          "Type: research_papers<br>Text: 2023 6th International Conference on Contemporary Computing and Informatics (IC3I)\nA significant inc...",
          "Type: research_papers<br>Text: survey paper aims to comprehensively review and compare categories [2]. This research displays the p...",
          "Type: research_papers<br>Text: today's dynamic and diverse environments, seeking to emphasizes the benefits of developing multimoda...",
          "Type: research_papers<br>Text: analysis of the state-of-the-art techniques, this survey aims to underlying algorithms and the metho...",
          "Type: research_papers<br>Text: aging society. research [4]. The authors of this paper have presented the\nthree stages of a fall, in...",
          "Type: research_papers<br>Text: contributions for the fall detection systems in the systems, as well as showcasing recent works on t...",
          "Type: research_papers<br>Text: all researchers world-wide, i.e., sensor based and which is affordable, inconvenient, but accurate; ...",
          "Type: research_papers<br>Text: the challenges of the well-known research in this Programmable Gate Arrays [FPGAs] and provides an\nd...",
          "Type: research_papers<br>Text: detection method. In order to gather information about the\n• Detailed methodology of the fall detect...",
          "Type: research_papers<br>Text: the fall detection research and have also covered the key approaches have gained popularity in the l...",
          "Type: research_papers<br>Text: three criteria: sensor, performance, and algorithms [1]. The accelerometers, gyroscopes, and pressur...",
          "Type: research_papers<br>Text: 2023 6th International Conference on Contemporary Computing and Informatics (IC3I)\nreadily available...",
          "Type: research_papers<br>Text: volumes of sensor data, enabling the creation of sophisticated the system can accurately recognize f...",
          "Type: research_papers<br>Text: scenarios and individuals. The combination of sensor-based assistance for individuals at risk of fal...",
          "Type: research_papers<br>Text: injuries, and providing timely assistance when needed. initial step in the fall detection process, a...",
          "Type: research_papers<br>Text: various factors, including sensor inaccuracies,\nmovement irregularities, and environmental\ninterfere...",
          "Type: research_papers<br>Text: related movements. Features can include statistical\nparameters (mean, variance, skewness), frequency...",
          "Type: research_papers<br>Text: A. Sensor Based Approach information to the classification stage.\nThe methodology for fall detection...",
          "Type: research_papers<br>Text: magnetometers, are strategically placed on the body or within specific features based on empirical o...",
          "Type: research_papers<br>Text: extraction, and classification stages. Preprocessing involves short time frame, it could indicate a ...",
          "Type: research_papers<br>Text: distinguish between normal activities and fall events. Finally, their adaptability to different scen...",
          "Type: research_papers<br>Text: 2023 6th International Conference on Contemporary Computing and Informatics (IC3I)\nimage acquisition...",
          "Type: research_papers<br>Text: and their relationships. While these systems can provide recorded and pre-processed. Then, using fea...",
          "Type: research_papers<br>Text: machine learning techniques, such as deep neural networks,\nSensors are the heart of this approach. T...",
          "Type: research_papers<br>Text: Sensors Functionality image-based solutions are suited for a variety of settings and\nMeasures accele...",
          "Type: research_papers<br>Text: rotational movements and helps determine\nlooked into how to capture human postures and motions using...",
          "Type: research_papers<br>Text: and recurrent neural networks, among other deep learning\nMeasures changes in atmospheric pressure.\nP...",
          "Type: research_papers<br>Text: Measurement Unit sometimes magnetometer data to provide\n(IMU) comprehensive information about motion...",
          "Type: research_papers<br>Text: (IoT) technology integration. Real-time data gathering, especially the elderly, by facilitating quic...",
          "Type: research_papers<br>Text: platform. As a result, fall incidents can be continuously sensor-based fall detection systems that m...",
          "Type: research_papers<br>Text: daily activity patterns via mobile applications or web placements to provide both effective fall det...",
          "Type: research_papers<br>Text: fall detection systems to analyse photos or video streams and behaviours. To achieve high detection ...",
          "Type: research_papers<br>Text: 2023 6th International Conference on Contemporary Computing and Informatics (IC3I)\nvalues for fall d...",
          "Type: research_papers<br>Text: especially on devices with limited capabilities.\nTABLE II. RELATED WORKS WITH THEIR CHALLENGES\nResea...",
          "Type: research_papers<br>Text: 93% 2023\naccelerometer data from smartphones.\nA fall detection technique utilizing a\ncombination of ...",
          "Type: research_papers<br>Text: Created LSTM network employed as\nChainarong Millimeter -Wave intelligent classifier and millimeter w...",
          "Type: research_papers<br>Text: [16]\ndetection system.\n1. Sensor Modalities Integration 99.56%\nXiaodan Wu a, etc.\nMobile Sensors.\nUs...",
          "Type: research_papers<br>Text: no. 3: 418. https://doi.org/10.3390/app8030418.\nelderly people has resulted in notable breakthroughs...",
          "Type: research_papers<br>Text: [3] V. -R. Xefteris, A. Tsanousa, G. Meditskos, S. Vrochidis and I.\ntechniques address issues such d...",
          "Type: research_papers<br>Text: [4] Muhammad Mubashir, Ling Shao, Luke Seed, “A survey on fall\nocclusions, and privacy issues relate...",
          "Type: research_papers<br>Text: Yazdani, Kumbesan Sandrasegaran, Practical fall detection based on\ndataset variability, resource lim...",
          "Type: research_papers<br>Text: International.Volume 2020 | Article ID 2167160 |\nthese problems. Fall detection systems will effecti...",
          "Type: research_papers<br>Text: Emirates, 2014, pp. 1-4, doi: 10.1109/NTMS.2014.6814018.\n[8] Chen, Gorong & Islam, Mohaiminul. (2019...",
          "Type: research_papers<br>Text: 2023 6th International Conference on Contemporary Computing and Informatics (IC3I)\nInternational Con...",
          "Type: research_papers<br>Text: 2. Vol. 998. Springer Nature, 2023.\n[11] Shukralia, Sakshi, M. P. S. Bhatia, and Pinaki Chakraborty....",
          "Type: research_papers<br>Text: \"Millimeter-Wave Radar-Based Elderly Fall Detection Fed by One-\nDimensional Point Cloud and Doppler,...",
          "Type: research_papers<br>Text: [15] Mekruksavanich, S., Jantawong, P., Hnoohom, N., Jitpattanakul, A.\n(2022). Wearable Fall Detecti...",
          "Type: research_papers<br>Text: human fall detection systems using deep learning: A review, Computers\nin Biology and Medicine, Volum...",
          "Type: research_papers<br>Text: 2/14/26, 11:05 PM Role of big data analytics in healthcare systems | Medical Imaging Informatics\n🔍 🛒...",
          "Type: research_papers<br>Text: Authors: Prathamesh Suhas Uravane, Vedant Vinay Ganthade, Adityaraj Sanjay Belhe, Abhiraj Sandeep\nGa...",
          "Type: research_papers<br>Text: its features and practicality but, data quality, integrating it with other physical, cloud systems, ...",
          "Type: research_papers<br>Text: trials, insurance claims, etc. Just imagine the amount of data produced by every multinational\nhospi...",
          "Type: research_papers<br>Text: 2/14/26, 11:05 PM Role of big data analytics in healthcare systems | Medical Imaging Informatics\nwhi...",
          "Type: research_papers<br>Text: References\n1. Sen, C. K. (2021). Human wound and its burden: updated 2020 compendium of estimates. A...",
          "Type: research_papers<br>Text: reporting in medical research: a cross-disciplinary bibliometric analysis. The Lancet, 393(10171), 5...",
          "Type: research_papers<br>Text: preserving big data scheme for healthcare clouds and applications. IEEE Journal of Biomedical and He...",
          "Type: research_papers<br>Text: 2/14/26, 11:05 PM Role of big data analytics in healthcare systems | Medical Imaging Informatics\n7. ...",
          "Type: research_papers<br>Text: intelligence in healthcare systems: state-of-the-art survey. In 2021 2nd International Conference on...",
          "Type: research_papers<br>Text: analytics and applications. In 2020 4th International Conference on Intelligent Computing and Contro...",
          "Type: research_papers<br>Text: Systems Journal, 2(4), 189–196.\nGoogle Scholar\n13. Rashid, M., Singh, H., Goyal, V., Ahmad, N., and ...",
          "Type: research_papers<br>Text: Revolution: Implementation of Artificial Intelligence for Growing Business Success, pp. 217–229.\nGoo...",
          "Type: research_papers<br>Text: 2/14/26, 11:05 PM Role of big data analytics in healthcare systems | Medical Imaging Informatics\nGoo...",
          "Type: research_papers<br>Text: Data Research, 2(2), 59–64.\nGoogle Scholar\n18. Chen, C., Li, K., Ouyang, A., Zeng, Z., and Li, K. (2...",
          "Type: research_papers<br>Text: Engineering, 5(1), 567–571.\nGoogle Scholar\n20. Harb, H., Mroue, H., Mansour, A., Nasser, A., and Mot...",
          "Type: research_papers<br>Text: hospitals: a scoping review. BMC Health Services Research, 22(1), 134.\nGoogle Scholar\n23. Galetsi, P...",
          "Type: research_papers<br>Text: 2/14/26, 11:05 PM Role of big data analytics in healthcare systems | Medical Imaging Informatics\nGoo...",
          "Type: research_papers<br>Text: data analytics. In 2017 International Conference on Innovations in Information, Embedded and\nCommuni...",
          "Type: research_papers<br>Text: health care systems. In 2019 International conference on automation, computational and technology\nma...",
          "Type: resume<br>Text: Uravane Prathamesh Suhas\nMalewadi-Akluj,Dist-Solapur,Maharashtra,India,413101\nIndia | (+91)976639006...",
          "Type: resume<br>Text: (Class XII) Jadhav-wadi Secondary Education\nSecondary School Sadashivrao Maharashtra State Board\nCer...",
          "Type: resume<br>Text: Experience:\nSr. no Employer Designation Description Duration\nUniversidad Maria AI Engineer Currently...",
          "Type: resume<br>Text: Yodda Elder Care Developed Computer\nVision based Fall detection\nTechnologies Pvt Computer Vision\nsys...",
          "Type: resume<br>Text: Tumors”.\nConference : 5th IEEE International Conference on Contemporary Computing and Informatics (I...",
          "Type: resume<br>Text: SCOPUS Kings Way, Stevenage, SG1 2UA, United Kingdom (published)\n▪ Research Paper: Advanced Preproce...",
          "Type: resume<br>Text: July 24 simulations Virtually. Personalized feedback system is also under implementation to give use...",
          "Type: resume<br>Text: 2.\nBuilt a student’s attentiveness Monitoring system online classes using computer vision\nMay 24 tec...",
          "Type: resume<br>Text: Student Dropout Prediction System\n3.\nImplemented a student dropout prediction system using ensemble ...",
          "Type: resume<br>Text: (UMA,Lima, Technologies: Python / FastAPI / Gradio / Machine Learning / MySQL / Data Preprocessing /...",
          "Type: resume<br>Text: March 24 platform Kaggle. The preprocessing pipeline improves images using various pre-processing\n- ...",
          "Type: resume<br>Text: Technologies: Python / TensorFlow / Keras / OpenCV / U-Net / ResNet / VGG16 / Image\nPreprocessing / ...",
          "Type: resume<br>Text: - used an artificial neural network (ANN) model which resulted in achieving high accuracy in\nMarch 2...",
          "Type: resume<br>Text: 6. Data\nBuilt a dyslexia detection system using handwritten digit data with Multi-model approach, wi...",
          "Type: resume<br>Text: Preprocessing / Pickle\nGAN-Based Realistic Road Scenario Generation for Enhancing Autonomous Vehicle...",
          "Type: resume<br>Text: (ERI@N,NTU, safer and more reliable vehicle perception in dynamic road situations.\nSingapore)\nTechno...",
          "Type: resume<br>Text: Jan 23\n- Implemented logic for emergency scenario detection using advanced computer vision technique...",
          "Type: resume<br>Text: models. Integrated functionalities like alarm triggering and snapshot delivery in milliseconds,\n(Yod...",
          "Type: resume<br>Text: - validation, result processing, login authentication, and special cases like student failures. It\nD...",
          "Type: resume<br>Text: Jun 22 images, achieving 96% accuracy with minimal computational power. The project consisted of\n- i...",
          "Type: resume<br>Text: Academic Courses:\n▪ Research Integrity Course - Certified, Nanyang Technological University, Singapo...",
          "Type: resume<br>Text: ▪ Research paper Presentation- C3I22 IEE conference - 2022\n▪ ‘Machine Learning Study Jams’ host (spo...",
          "Type: resume<br>Text: ▪ Poetry – 1st position - Aarambha 2021 (University’s Cultural Festival) – 2021\n▪ Fashion – 2nd posi...",
          "Type: resume<br>Text: Prathamesh Uravane\nWashington DC, Baltimore Area | +1 (732) 318-9234 | upratham2002@gmail.com\nlinked...",
          "Type: resume<br>Text: ● AI/ML Core Team Member, Google Developer Student Club\nTECHNICAL SKILLS\nMachine Learning: Sci-kit L...",
          "Type: resume<br>Text: ● Developed an AI-powered virtual lab simulator integrated with a student feedback system to give in...",
          "Type: resume<br>Text: ● Implemented GAN model to generate realistic road scenarios to enhance robustness of the perception...",
          "Type: resume<br>Text: Student Researcher Jun 2022 – Aug 2022\nVU Research Centre of Excellence for Health Informatics Pune,...",
          "Type: resume<br>Text: approach helped to boost accuracy. Results are saved for further analysis, enabling robust and relia...",
          "Type: resume<br>Text: generate clean, shareable meeting minutes automatically. (Python / HuggingFace / Gradio / ML / Genai...",
          "Type: resume<br>Text: key management.\nPUBLICATIONS\n1. IIETA: Efficient Segmentation Approach for the Traceability of Breas...",
          "Type: resume<br>Text: ● Compared ANN and Random Forests models for maternal health risk classification using clinical feat...",
          "Type: resume<br>Text: Prathamesh Uravane\nWashington DC, Baltimore Area | +1 (732) 318-9234 | upratham2002@gmail.com\nlinked...",
          "Type: resume<br>Text: ● AI/ML Core Team Member, Google Developer Student Club\nTECHNICAL SKILLS\nMachine Learning: Sci-kit L...",
          "Type: resume<br>Text: ● Developed an AI-powered virtual lab simulator integrated with a student feedback system to give in...",
          "Type: resume<br>Text: ● Implemented GAN model to generate realistic road scenarios to enhance robustness of the perception...",
          "Type: resume<br>Text: Student Researcher | VU Research Centre of Excellence for Health Informatics | Pune, India. June 202...",
          "Type: resume<br>Text: approach helped to boost accuracy. Results are saved for further analysis, enabling robust and relia...",
          "Type: resume<br>Text: generate clean, shareable meeting minutes automatically. (Python / HuggingFace / Gradio / ML / Genai...",
          "Type: resume<br>Text: key management.\nPUBLICATIONS\n1. IIETA: Efficient Segmentation Approach for the Traceability of Breas...",
          "Type: resume<br>Text: ● Compared ANN and Random Forests models for maternal health risk classification using clinical feat...",
          "Type: resume<br>Text: storage, and analysis across records, medications, trials, and claims—improving handling.\n4. IEEE IC...",
          "Type: transcripts<br>Text: # Higher Secondary Certificate (HSC) — Statement of Marks (February 2020)\n\n## Document type\nHigher S...",
          "Type: transcripts<br>Text: ## Marks obtained\n| Subject | Marks (Max) | Marks Obtained |\n|---|---:|---:|\n| English | 100 | 71 |\n...",
          "Type: transcripts<br>Text: # Secondary School Certificate (SSC) — Maharashtra State Board (March 2018)\n\n## Document type\nSecond...",
          "Type: transcripts<br>Text: ## Examination outcome\n- **Exam:** Secondary School Certificate Examination — **March 2018**\n- **Res...",
          "Type: transcripts<br>Text: 2/14/26, 10:23 PM Testudo - Unofficial Transcript\nUNIVERSITY OF MARYLAND\nCOLLEGE PARK\nOffice of the ...",
          "Type: transcripts<br>Text: Fall 2025\nMAJOR: APPLIED MACHINE LEARNING COLLEGE: GRADUATE SCHOOL\nMSML601 PROBABILITY & STATISTICS ...",
          "Type: transcripts<br>Text: /Div Meth /Add Date Date Date\n======== ==== ======= ======= ==== ==== ======== ======== ========\nMSM...",
          "Type: transcripts<br>Text: MSML606 PCS2 3.00 REG D 10/30/25 10/30/25 10/30/25\nMSML604 PCS3 3.00 REG D 10/30/25 10/30/25 10/30/2...",
          "Type: transcripts<br>Text: 2/14/26, 10:23 PM Testudo - Unofficial Transcript\nMSML606 PCS1 3.00 REG D 10/30/25 10/30/25 10/30/25...",
          "Type: transcripts<br>Text: # Vishwakarma University — B.Tech (Artificial Intelligence & Data Science) Transcript\n\n## Document t...",
          "Type: transcripts<br>Text: ## Academic completion note\nThe transcript states the student has appeared for the **Fourth Year B.T...",
          "Type: transcripts<br>Text: ## Final outcome\n- **Final Grade:** **A+**\n- **Document date / reference:** Dated **29/08/2024** (Re...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:58:33.734019Z | Model: gpt-4.1-nano -->\n\n# AI-in-Production-Healthcare...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **FastAPI framework** for building high-performance APIs\n- Simple, minimal setup s...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository is structured around a minimal FastAPI application:\n- ...",
          "Type: repo_summaries<br>Text: The core of the application is the `FastAPI` instance created in `instant.py`, which exposes a GET e...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`instant.py`**: Contains the main FastAPI application instance and a si...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n1. **Clone the repository:**\n```bash\ngit clone https://github.com/upratham/AI-in-Prod...",
          "Type: repo_summaries<br>Text: 4. **Access the API:**\nOpen your browser or use curl to visit:\n```\nhttp://localhost:8000/\n```\nYou sh...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- No explicit testing or CI configurations are present in the repository.\n- To imple...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No specific contribution guidelines are provided.\n- For contributions, fork ...",
          "Type: repo_summaries<br>Text: ---\n\n*This documentation is based on the current repository contents and structure. If additional fe...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:00:46.918835Z | Model: gpt-4.1-nano -->\n\n# Brain-Tumor-Classification\n...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Utilizes CNN architecture for brain tumor classification.\n- Achieved approximately...",
          "Type: repo_summaries<br>Text: ## Architecture / How It Works\nThe core of the project is implemented within a Jupyter Notebook (`Fi...",
          "Type: repo_summaries<br>Text: While specific code details are not provided here, the structure suggests a standard deep learning p...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nTo set up and run the project:\n1. Clone the repository:\n```bash\ngit clone https://git...",
          "Type: repo_summaries<br>Text: ## How to Use\n- **Training**: Run the cells in the notebook to load data, preprocess, augment, build...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or continuous integration (CI) setup is mentioned in the reposit...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nThe repository includes instructions for contributing:\n- Fork the repository.\n...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** For detailed code implementation, model architecture, and training procedures, refer ...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:58:50.943948Z | Model: gpt-4.1-nano -->\n\n# Breast-Cancer-Segmentation\n...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implements multiple segmentation architectures: U-Net, DeepLabV3+, MultiResUNet.\n-...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe project is structured around three main notebooks:\n- `data_prepro...",
          "Type: repo_summaries<br>Text: The notebooks and source files work together to facilitate a modular segmentation pipeline.\n\n## Nota...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### 1) Environment Setup\nCreate and activate a virtual environment:\n```bash\npython -m...",
          "Type: repo_summaries<br>Text: ## How to Use\n### Data Preprocessing\nOpen and run:\n```bash\njupyter notebook data_preprocessing.ipynb...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or CI configurations are mentioned in the provided data. If pres...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo contribution guidelines are provided in the current documentation.\n\n## Limi...",
          "Type: repo_summaries<br>Text: ---\n\n*Note:* If you require further details on specific scripts or configurations, please clarify or...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:03:22.568460Z | Model: gpt-4.1-nano -->\n\n# upratham/chem_sim\n\n## Overv...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Interactive 3D models of chemical apparatus and experiments.\n- Visualizations of f...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository is structured around React components that leverage Th...",
          "Type: repo_summaries<br>Text: Key files and their roles:\n- `src/index.js`: Entry point, sets up routing and renders the main compo...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- `src/Components/`: React components for different experiments and scene m...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n1. Clone the repository:\n```bash\ngit clone https://github.com/upratham/chem_sim.git\nc...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- The repository includes scripts for testing via `react-scripts test`.\n- No explici...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No specific contribution guidelines are provided.\n- Contributions can be mad...",
          "Type: repo_summaries<br>Text: ---\n\n*Note:* Some details are inferred based on the provided code snippets and file structure. For p...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:39.641176Z | Model: gpt-4.1-nano -->\n\n# Clustering-KMeans-AHC\n\n## O...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implementation of K-Means clustering\n- Implementation of Agglomerative Hierarchica...",
          "Type: repo_summaries<br>Text: The notebook likely contains code cells that execute these steps sequentially, demonstrating the clu...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Environment Setup\n1. (Optional) Create a virtual environment:\n```bash\npython -m v...",
          "Type: repo_summaries<br>Text: ## How to Use\n- Follow the notebook cells to understand data loading, preprocessing, clustering, and...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- No explicit testing or continuous integration setup is indicated.\n- The repository...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No specific contribution guidelines are provided.\n- Users are encouraged to ...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** If you require further details about the internal code logic or specific implementati...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:03:12.452128Z | Model: gpt-4.1-nano -->\n\n# compare-knn-dt-randomforest...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Data loading and preprocessing of the balloons dataset\n- Implementation of KNN, De...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe core of this project is encapsulated within a Jupyter Notebook (`...",
          "Type: repo_summaries<br>Text: The project relies on standard scientific and machine learning libraries, including `numpy`, `pandas...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\nEnsure you have Python installed along with the dependencies listed...",
          "Type: repo_summaries<br>Text: ## How to Use\n- Follow the notebook's steps to load data, preprocess, train models, and visualize re...",
          "Type: repo_summaries<br>Text: ## Deployment\nNo deployment instructions are provided. The project is primarily an analytical notebo...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- The project focuses solely on the balloons dataset; generalizati...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:22.476375Z | Model: gpt-4.1-nano -->\n\n# Dataset\n\n## Overview\nThe **...",
          "Type: repo_summaries<br>Text: ## Architecture / How it works\nThe repository's structure is straightforward:\n- The core content is ...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- `.gitignore`: Defines files and directories to exclude from version contr...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nSince the repository contains only dataset files and no explicit setup scripts:\n- Clo...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- No testing frameworks, CI/CD pipelines, or automation workflows are indicated in t...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No contribution guidelines are provided in the current documentation.\n- Cont...",
          "Type: repo_summaries<br>Text: ---\n\n*Note:* If you require more detailed information about the datasets or additional files, please...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:59:22.771602Z | Model: gpt-4.1-nano -->\n\n# Desktop-Chat-App\n\n## Overvi...",
          "Type: repo_summaries<br>Text: This repository is intended for developers interested in customizing or extending a lightweight chat...",
          "Type: repo_summaries<br>Text: ## Architecture / How It Works\nThe repository comprises two main components:\n\n1. **Client Applicatio...",
          "Type: repo_summaries<br>Text: 2. **WebSocket Server:**\n   - Located in the `server` directory.\n   - Uses the `ws` library to handl...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`app/`**: Contains the Electron app code, including UI (`index.html`), ...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Node.js (version >= 12 recommended)\n- For Linux TTS: `espeak` mus...",
          "Type: repo_summaries<br>Text: # For the server\ncd ../server\nnpm install\n```\n\n### Running the Application\n#### Start the WebSocket ...",
          "Type: repo_summaries<br>Text: 2. **Chat:**\n   - Type your message in the input box.\n   - Press **Send** or hit Enter.\n   - Your me...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or CI configurations are present in the provided files. \n\n## Dep...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- **Security & Authentication:** No mention of user authentication...",
          "Type: repo_summaries<br>Text: ---\n\nFor further details, refer to the individual files and scripts within the repository....",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:01:03.872666Z | Model: gpt-4.1-nano -->\n\n# DL-CNN-Transfer-Learning\n\n#...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implements a custom CNN architecture for multi-class flower classification.\n- Util...",
          "Type: repo_summaries<br>Text: - **`src/data_preprocess.py`**: Loads images from the dataset, resizes them to 200×200 pixels, and e...",
          "Type: repo_summaries<br>Text: The dataset is organized in the `data/flowers` directory, with images categorized into subfolders or...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### 1. Environment Setup\nCreate and activate a virtual environment:\n\n```bash\npython -...",
          "Type: repo_summaries<br>Text: ### 4. Train the Model\nRun the training script:\n\n```bash\npython src/train.py\n```\n\nThis will train th...",
          "Type: repo_summaries<br>Text: ```bash\njupyter notebook src/eval.ipynb\n```\n\nUse the notebook to:\n- Load the trained model.\n- Evalua...",
          "Type: repo_summaries<br>Text: ## Deployment\nNo deployment instructions are provided. The trained models can be saved and integrate...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo specific contribution guidelines are included in the provided data.\n\n## Lim...",
          "Type: repo_summaries<br>Text: ---\n\n*For further details, refer to the code files and the Jupyter Notebook in the `src/` directory....",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:59:59.203233Z | Model: gpt-4.1-nano -->\n\n# upratham/DS-Sleep-Disorder-...",
          "Type: repo_summaries<br>Text: ## Key Features\n\n- Data cleaning and preprocessing, including handling missing values and encoding c...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\n\nThe project workflow is encapsulated within a Jupyter Notebook (`Sle...",
          "Type: repo_summaries<br>Text: 1. **Data Loading:** Reads the dataset from `data/ss.csv`.\n2. **Data Cleaning:** Handles missing val...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n\n- `Sleep_Disorder_analysis.ipynb`: Main notebook containing the entire ana...",
          "Type: repo_summaries<br>Text: ```bash\npip install pandas numpy scikit-learn tensorflow keras matplotlib seaborn imbalanced-learn\n`...",
          "Type: repo_summaries<br>Text: 3. Launch Jupyter Notebook:\n\n```bash\njupyter notebook Sleep_Disorder_analysis.ipynb\n```\n\n4. Open the...",
          "Type: repo_summaries<br>Text: *Note:* Since the project is contained within a single notebook, modifications and reruns are straig...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n\nNo contribution guidelines are provided in the repository. For collaborative ...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** If you need further details on specific implementation aspects or additional files, p...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:03:55.145268Z | Model: gpt-4.1-nano -->\n\n# Face-Differentiator\n\n## Ove...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Uses the Keras implementation of FaceNet for face embedding extraction.\n- Compares...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe core functionality is implemented in the `face.py` script, which ...",
          "Type: repo_summaries<br>Text: The `README.md` provides an overview of the approach, emphasizing embedding extraction, distance cal...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Python environment with `keras_facenet` installed.\n- Access to th...",
          "Type: repo_summaries<br>Text: ### Example\n```\nENTER PATH OF 1st IMG: /path/to/reference.jpg\nENTER PATH to the IMG DIRECTORY: /path...",
          "Type: repo_summaries<br>Text: ### Example Output\n```\n[0.1234]\nSAME\n\n[1.5678]\nDIFFERENT\n```\n\n*Note:* The threshold value (`tresh=1....",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No specific contribution guidelines are included.\n- Users can fork the repos...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** If you require further details or clarification, such as the structure of the face em...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:01.856816Z | Model: gpt-4.1-nano -->\n\n# Feature-Selection-and-Dimen...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Loads and preprocesses pollution dataset with label encoding and handling of negat...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository is organized into modular Python scripts within the `s...",
          "Type: repo_summaries<br>Text: The workflow typically involves:\n1. Loading data.\n2. Preprocessing data.\n3. Applying feature enginee...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n1. Clone the repository:\n```bash\ngit clone https://github.com/upratham/Feature-Select...",
          "Type: repo_summaries<br>Text: ## How to Use\n- To perform only feature engineering visualizations:\n```bash\npython feature_engineeri...",
          "Type: repo_summaries<br>Text: ## Deployment\nThere is no deployment process specified. The code is intended for local analysis and ...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo specific contribution guidelines are provided in the documentation. Feel fr...",
          "Type: repo_summaries<br>Text: ---\n\n*Note:* If you have specific questions about certain parts of the code or need further customiz...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:03:28.387526Z | Model: gpt-4.1-nano -->\n\n# gaussian-mle\n\n## Overview\n`...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implementation of MLE for Gaussian distribution parameters (mean and variance)\n- I...",
          "Type: repo_summaries<br>Text: The notebook probably follows these steps:\n- Load data from CSV\n- Define the likelihood function for...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nSince the repository uses a Jupyter Notebook and Python, the typical setup involves:\n...",
          "Type: repo_summaries<br>Text: ## How to use\nOpen the notebook in Jupyter and follow the embedded instructions. The notebook probab...",
          "Type: repo_summaries<br>Text: ## Deployment\nNo deployment instructions are provided or inferred. The repository appears to be educ...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- The repository appears to focus on a single dataset and a specif...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:15.932628Z | Model: gpt-4.1-nano -->\n\n# iris-softmax-vs-svm\n\n## Ove...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implements and trains both Softmax Regression and SVM classifiers.\n- Evaluates mod...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe core workflow is encapsulated within a Jupyter Notebook (`iris_so...",
          "Type: repo_summaries<br>Text: The setup relies on standard Python data science libraries (`pandas`, `scikit-learn`, `matplotlib`) ...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Environment Setup\n```bash\n# Create and activate a virtual environment\npython -m v...",
          "Type: repo_summaries<br>Text: ## How to Use\n- **Data Preparation**: Replace or modify `Data_Iris.csv` if needed. Ensure it contain...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- No explicit testing or CI configurations are present in the repository.\n- The note...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- The current implementation uses default hyperparameters; hyperpa...",
          "Type: repo_summaries<br>Text: ---\n\n**For more details, visit the [GitHub repository](https://github.com/upratham/iris-softmax-vs-s...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:01:23.636613Z | Model: gpt-4.1-nano -->\n\n# Linear-regressing--Ridge-La...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implementation of linear regression models with Ridge and Lasso regularization.\n- ...",
          "Type: repo_summaries<br>Text: The repository is structured around a single notebook, with supporting files such as the dataset and...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nTo run the project:\n1. Clone the repository:\n   ```bash\n   git clone https://github.c...",
          "Type: repo_summaries<br>Text: *Note:* The exact dependencies are not explicitly listed, but typical packages for such analysis inc...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or continuous integration configurations are mentioned or visibl...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo specific contribution guidelines are provided in the repository.\n\n## Limita...",
          "Type: repo_summaries<br>Text: ---\n\n*This documentation is based solely on the provided repository metadata and file excerpts. For ...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:59:47.129200Z | Model: gpt-4.1-nano -->\n\n# LLM-AI-Company-Brochure-Gen...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **Website Content Scraping:** Utilizes `BeautifulSoup` to extract and clean websit...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe project primarily revolves around scraping website content and fe...",
          "Type: repo_summaries<br>Text: The notebooks likely contain the logic to:\n1. Fetch website content using `scraper.py`.\n2. Send the ...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`scraper.py`:** Contains functions for scraping website titles, text, a...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Python 3.11.x\n- Git\n- Internet connection (for Gemini API)\n- Olla...",
          "Type: repo_summaries<br>Text: 3. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n4. Set up environment variable...",
          "Type: repo_summaries<br>Text: ### Running the Notebooks\n- **Using Gemini (Cloud):**\n```bash\njupyter notebook Brochure_Generater_Ge...",
          "Type: repo_summaries<br>Text: ### Generating Brochures\nWithin the notebooks:\n- Input the scraped content.\n- Select the LLM API (Ge...",
          "Type: repo_summaries<br>Text: *(Note: Actual function names depend on notebook implementation)*\n\n## Testing / CI\nNo explicit testi...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo contribution guidelines are included in the provided data.\n\n## Limitations ...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** For detailed usage, refer to the individual notebooks and the `scraper.py` script. If...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:00:07.610298Z | Model: gpt-4.1-nano -->\n\n# LLM-AI-Website-Summarizer\n\n...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Web scraping using `requests` and `BeautifulSoup`.\n- Supports summarization throug...",
          "Type: repo_summaries<br>Text: ## Architecture / How It Works\nThe repository primarily consists of Jupyter notebooks that perform t...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- `summerizer_Gemini.ipynb`: Presumably another summarization notebook, pos...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Python 3.10+ (recommended based on dependencies)\n- Jupyter Notebo...",
          "Type: repo_summaries<br>Text: ### Running the Notebooks\nStart Jupyter:\n\n```bash\njupyter lab\n# or\njupyter notebook\n```\n\nOpen either...",
          "Type: repo_summaries<br>Text: 3. Run the `summerizer_Openai.ipynb` notebook:\n   - It loads the API key via `python-dotenv`.\n   - U...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or CI configurations are mentioned in the provided data. The foc...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo contribution guidelines are provided in the current documentation.\n\n## Limi...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:59:08.335578Z | Model: gpt-4.1-nano -->\n\n# LLM-Code-Explainer\n\n## Over...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **Student-friendly code explanations:** Tailored responses to help learners grasp ...",
          "Type: repo_summaries<br>Text: ## Architecture / How It Works\nThe core of the application is a Python script (`app.py`) that:\n- Loa...",
          "Type: repo_summaries<br>Text: The repository leverages:\n- `app.py` as the main application script.\n- Environment variables for mod...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`app.py`**: Main script that runs the Gradio chat interface and handles...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### 1) Install and Start Ollama\n```bash\nollama serve\n# In another terminal, pull the ...",
          "Type: repo_summaries<br>Text: ### 4) Run the Application\n```bash\npython app.py\n```\n\n## How to Use\n- Access the local Gradio interf...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- No explicit testing or CI configurations are mentioned in the provided files.\n- De...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- **Model dependency:** Relies on Ollama and specific models (`lla...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:00:40.506121Z | Model: gpt-4.1-nano -->\n\n# LLM-Debate-Competition\n\n## ...",
          "Type: repo_summaries<br>Text: This project is suitable for AI researchers, developers, or enthusiasts interested in multi-agent in...",
          "Type: repo_summaries<br>Text: ---\n\n## Key Features\n- Simulates a debate between two LLM-based competitors, each with customizable ...",
          "Type: repo_summaries<br>Text: ---\n\n## Architecture / How it Works\nThe core functionality is implemented within a Jupyter Notebook ...",
          "Type: repo_summaries<br>Text: 1. Initializing two competitor agents with their respective prompts and personas.\n2. Alternating tur...",
          "Type: repo_summaries<br>Text: ---\n\n## Notable Folders/Files\n- **`Debate_Competittion.ipynb`**: The main interactive notebook for r...",
          "Type: repo_summaries<br>Text: ---\n\n## Setup & Run\n### Prerequisites\n- Python 3.11.x installed.\n- Virtual environment tool (recomme...",
          "Type: repo_summaries<br>Text: 3. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n### Configuration\n- **Using Ol...",
          "Type: repo_summaries<br>Text: - **Using OpenAI API:**\n  - Create a `.env` file with your API key:\n    ```bash\n    OPENAI_API_KEY=\"...",
          "Type: repo_summaries<br>Text: ### Customization\n- Modify the **topic** variable to set the debate subject.\n- Adjust the **system p...",
          "Type: repo_summaries<br>Text: ---\n\n## Deployment\nCurrently, the project is designed for local experimentation within a Jupyter Not...",
          "Type: repo_summaries<br>Text: ---\n\n## Limitations / TODOs (Inferred)\n- The project currently relies heavily on manual configuratio...",
          "Type: repo_summaries<br>Text: ---\n\n## Author\nMaintained by **Prathamesh Uravane**  \nEmail: [upratham2002@gmail.com](mailto:upratha...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:58:58.437625Z | Model: gpt-4.1-nano -->\n\n# LLM-Meeting-Minutes-Generat...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Upload and process audio files (mp3, wav, m4a, etc.)\n- Automatic transcription of ...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe application workflow involves:\n1. Uploading an audio file through...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- `app.py`: Entry point of the application, contains the main logic for tra...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Environment Setup\n1. Clone the repository:\n```bash\ngit clone https://github.com/u...",
          "Type: repo_summaries<br>Text: ### Running the Application\n```bash\npython app.py\n```\nThis will start a local server, typically acce...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nThere is no explicit mention of testing frameworks or CI/CD pipelines in the provide...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo specific contribution guidelines are provided in the repository. For contri...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- **Model Customization:** The default model is `meta-llama/Llama-...",
          "Type: repo_summaries<br>Text: - **Localization:** Currently tailored for Denver council meetings; generalization to other meeting ...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** If you need further details on specific components or configurations, please clarify ...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:36:00.497898Z | Model: gpt-4.1-nano -->\n\n# LLM-RAG-private-knowldge-wo...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **Document Ingestion:** Load and process various document formats (TXT, PDF, DOCX)...",
          "Type: repo_summaries<br>Text: - **Retrieval:** Semantic similarity-based document retrieval to find relevant context.\n- **LLM Inte...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe system orchestrates several components:\n- **Data Ingestion:** Loa...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`src/`**: Core source code implementing ingestion, chunking, embeddings...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Installation\n```bash\n# Clone the repository\ngit clone https://github.com/upratham...",
          "Type: repo_summaries<br>Text: ### Running the System\n- To process documents, build index, and query:\n```python\nfrom src.rag_system...",
          "Type: repo_summaries<br>Text: - Or run the main script:\n```bash\npython main.py\n```\n\n## How to Use\n### Basic Workflow\n```python\nfro...",
          "Type: repo_summaries<br>Text: ### Example Queries\n- Ask questions based on ingested documents.\n- Retrieve relevant context snippet...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- Tests are located in `tests/test_rag.py`.\n- Run tests with:\n```bash\npytest tests/\n...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- Create feature branches.\n- Implement components or fixes.\n- Run tests and ad...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- Currently supports in-memory vector store; external vector DB in...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:59:37.851770Z | Model: gpt-4.1-nano -->\n\n# llm_engineering\n\n## Overvie...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Extensive community-contributed projects across multiple domains\n- Examples of web...",
          "Type: repo_summaries<br>Text: ## Architecture / How it works\nThe repository is organized into multiple folders and files, each rep...",
          "Type: repo_summaries<br>Text: The projects leverage APIs (OpenAI, Ollama, etc.), web scraping libraries, and local or cloud-hosted...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n1. **Clone the repository**\n```bash\ngit clone https://github.com/upratham/llm_enginee...",
          "Type: repo_summaries<br>Text: 4. **Configure API keys**\n- Create a `.env` file with your credentials (OpenAI, Ollama, etc.)\n- Exam...",
          "Type: repo_summaries<br>Text: 5. **Run projects/notebooks**\n- Launch notebooks via Jupyter:\n```bash\njupyter notebook\n```\n- Run scr...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- The repository includes test files under `community-contributions/Reputation_Radar...",
          "Type: repo_summaries<br>Text: ## Contribution notes\n- Contributions are welcomed; see individual project folders for contribution ...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- Many projects rely on API keys and external services; usage cost...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:01:10.827314Z | Model: gpt-4.1-nano -->\n\n# ML-Ensemble\n\n## Overview\n**...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implements bootstrap sampling on a dataset\n- Trains multiple neural networks (usin...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository's main logic resides in the `Ensemble.ipynb` notebook,...",
          "Type: repo_summaries<br>Text: The notebook likely uses libraries such as TensorFlow/Keras for neural networks, scikit-learn for da...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nTo run the project:\n1. Ensure you have Python 3 installed.\n2. Install the required de...",
          "Type: repo_summaries<br>Text: ## How to Use\nWithin the notebook:\n- Run all cells to generate bootstrap samples and train neural ne...",
          "Type: repo_summaries<br>Text: ## Deployment\nThere is no indication of deployment procedures or production-ready code. The project ...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- The project focuses on a simple 2D dataset; scaling to more comp...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:01:42.668030Z | Model: gpt-4.1-nano -->\n\n# ML-flow-exp\n\n## Overview\nTh...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Training Random Forest classifiers on the Wine dataset.\n- Experiment tracking with...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository comprises several Python scripts that perform data loa...",
          "Type: repo_summaries<br>Text: The scripts configure MLflow experiments, start runs, and log relevant data for reproducibility and ...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **mlartifacts/**: Stores model artifacts, including trained models, confi...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nWhile explicit setup instructions are not provided, based on the code and artifacts:\n...",
          "Type: repo_summaries<br>Text: 3. **Run scripts:**\n   - To train a model and log an experiment:\n     ```bash\n     python src/file1....",
          "Type: repo_summaries<br>Text: - **Experiment Management:**\n  Use `mlflow.set_experiment()` to specify experiment names. Results ar...",
          "Type: repo_summaries<br>Text: - **Autologging:**\n  Run `autolog.py` to enable automatic logging of models and metrics without manu...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- **Limited Dataset:** Only the Wine dataset is used; support for ...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** If you require detailed setup instructions, environment configuration, or deployment ...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:00:13.941175Z | Model: gpt-4.1-nano -->\n\n# MLOps-CD-Docker\n\n## Overvie...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Dockerfile for containerizing a Python web app\n- Simple Flask application demonstr...",
          "Type: repo_summaries<br>Text: The application runs a web server on port 5000, accessible from outside the container, allowing user...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Docker installed on your machine.\n\n### Building the Docker Image\n...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- No explicit testing or CI configurations are present in the repository.\n- The appl...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No specific contribution guidelines are provided in the repository.\n- Contri...",
          "Type: repo_summaries<br>Text: ---\n\n*This documentation is based on the provided repository data and file excerpts. For further det...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:00:20.555673Z | Model: gpt-4.1-nano -->\n\n# MLOps-CI\n\n## Overview\n**MLO...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Automated testing of Python functions using pytest\n- Integration with GitHub Actio...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository combines a web application and testing scripts:\n- **ap...",
          "Type: repo_summaries<br>Text: The project structure suggests a focus on:\n- Developing a user-friendly web app (`app.py`)\n- Ensurin...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Python 3.x installed\n- Git installed\n\n### Installation\n1. Clone t...",
          "Type: repo_summaries<br>Text: ### Running the Application\nStart the Streamlit app:\n```bash\nstreamlit run app.py\n```\nThis will open...",
          "Type: repo_summaries<br>Text: ### Running Tests\nExecute the tests with pytest:\n```bash\npytest _test.py\n```\nThis will run all defin...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No specific contribution guidelines are provided in the repository.\n- For co...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** If you need further details about the `project flow` or specific deployment instructi...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:01:54.309502Z | Model: gpt-4.1-nano -->\n\n# MLops-Complete-Pipeline\n\nTh...",
          "Type: repo_summaries<br>Text: ---\n\n## 🎯 Overview\n\n**MLops-Complete-Pipeline** provides a comprehensive framework for developing, t...",
          "Type: repo_summaries<br>Text: ---\n\n## 🔑 Key Features\n\n- **End-to-end ML pipeline** from raw data to evaluated model\n- **Data versi...",
          "Type: repo_summaries<br>Text: ---\n\n## 🏗️ Architecture / How It Works\n\nThe pipeline is orchestrated through **`dvc.yaml`**, which d...",
          "Type: repo_summaries<br>Text: - **Configuration:**\n  - Parameters like test size, max features, hyperparameters are managed in `pa...",
          "Type: repo_summaries<br>Text: - **`.dvc/`**: Contains DVC internal data and cache metadata\n- **`dvclive/`**: Stores live metrics, ...",
          "Type: repo_summaries<br>Text: - `model_evaluation.py`: Evaluates and logs model performance\n- **`dvc.yaml`**: Defines pipeline sta...",
          "Type: repo_summaries<br>Text: ---\n\n## 🚀 Setup & Run\n\n### 1. Clone the Repository\n\n```bash\ngit clone https://github.com/upratham/ML...",
          "Type: repo_summaries<br>Text: ### 4. Initialize DVC and Configure Remote Storage\n\n```bash\ndvc init\ngit add .dvc .dvcignore dvc.yam...",
          "Type: repo_summaries<br>Text: Run specific stages (e.g., model training):\n\n```bash\ndvc repro model_building\n```\n\n### 6. Push Data ...",
          "Type: repo_summaries<br>Text: ### Adjust Parameters\n\n- Modify `params.yaml` (e.g., change `max_features` or hyperparameters)\n- Rer...",
          "Type: repo_summaries<br>Text: ---\n\n## 🤝 Contribution Notes\n\nNo specific contribution guidelines are provided. Contributions should...",
          "Type: repo_summaries<br>Text: ---\n\n## ⚠️ Limitations / TODOs (Inferred)\n\n- **Unclear if requirements are fully specified**; consid...",
          "Type: repo_summaries<br>Text: ---\n\n**For more details, visit the [GitHub repository](https://github.com/upratham/MLops-Complete-Pi...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:30.869507Z | Model: gpt-4.1-nano -->\n\n# MLOps-DVC-Data-Versioning\n\n...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Demonstrates data versioning using DVC\n- Provides sample Python code to create and...",
          "Type: repo_summaries<br>Text: The data is stored in an S3 bucket (`S3/files`) with associated MD5 checksum files for integrity ver...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- `.dvc/`: Contains DVC configuration and ignore files, essential for manag...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nWhile explicit setup instructions are not provided, the following can be inferred:\n1....",
          "Type: repo_summaries<br>Text: ```bash\n   python mycode.py\n   ```\n6. Track data with DVC:\n   ```bash\n   dvc add data/sample_data.cs...",
          "Type: repo_summaries<br>Text: ## How to Use\n- To generate and save a new dataset:\n  ```bash\n  python mycode.py\n  ```\n- To track th...",
          "Type: repo_summaries<br>Text: ## Deployment\nThere is no explicit deployment process outlined. The setup appears to be local develo...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo contribution guidelines are provided in the current documentation. For cont...",
          "Type: repo_summaries<br>Text: ---\n\nFor more details, visit the [GitHub repository](https://github.com/upratham/MLOps-DVC-Data-Vers...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:00:30.932432Z | Model: gpt-4.1-nano -->\n\n# MLOps-Insurance-Project\n\n##...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **End-to-end ML pipeline**: Automates data ingestion, validation, transformation, ...",
          "Type: repo_summaries<br>Text: - **Cloud Storage Support**: Includes modules for AWS cloud storage integration.\n- **Reproducibility...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe project is structured into multiple modules that facilitate a mod...",
          "Type: repo_summaries<br>Text: - **Configuration Files**: Located in the `config/` directory, including `model.yaml` and `schema.ya...",
          "Type: repo_summaries<br>Text: - **Entities**: Data structures and model artifacts (`entity/`).\n  - **Configuration**: Cloud and da...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`Dockerfile`**: Defines the container environment for deployment.\n- **`...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nBased on the provided files:\n1. **Clone the repository**:\n   ```bash\n   git clone htt...",
          "Type: repo_summaries<br>Text: ```bash\n     uvicorn app:app --reload\n     ```\n   - Alternatively, build and run the Docker containe...",
          "Type: repo_summaries<br>Text: ## How to Use\n- **API Endpoints**: Once running, access the API (likely via `http://localhost:8000`)...",
          "Type: repo_summaries<br>Text: ## Deployment\n- Deployment is facilitated via Docker (`Dockerfile`) and possibly the `app.py` FastAP...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- **Unclear if there are automated tests**; adding unit/integratio...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** Some details, such as exact API endpoints, specific pipeline steps, or deployment pro...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:01:17.341436Z | Model: gpt-4.1-nano -->\n\n# NN-Backpropagation\n\n## Over...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implementation of a neural network with one hidden layer\n- Manual implementation o...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe core logic resides in the `back_propogation.ipynb` notebook, whic...",
          "Type: repo_summaries<br>Text: The implementation follows a typical neural network training pipeline:\n1. Initialize weights and bia...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- `back_prpogation.ipynb`: The main Jupyter notebook containing all impleme...",
          "Type: repo_summaries<br>Text: ### Installation\nInstall dependencies via pip:\n```bash\npip install numpy matplotlib jupyter\n```\n\n###...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or continuous integration setup is mentioned or present in the r...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo specific contribution guidelines are provided in the repository.\n\n## Limita...",
          "Type: repo_summaries<br>Text: ---\n\n*This documentation is based solely on the provided repository metadata and file excerpts. For ...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:08.294603Z | Model: gpt-4.1-nano -->\n\n# Non-linear-dimensionality-r...",
          "Type: repo_summaries<br>Text: # Non-linear-dimensionality-reduction\n\nRepository for exploring spectral clustering and nonlinear di...",
          "Type: repo_summaries<br>Text: ---\n\n## Key Features\n\n- **Spectral Clustering from Scratch:** Implements spectral clustering algorit...",
          "Type: repo_summaries<br>Text: ---\n\n## Architecture / How it Works\n\nThe core logic resides within a Jupyter Notebook (`HW8.ipynb`),...",
          "Type: repo_summaries<br>Text: ---\n\n## Notable Folders/Files\n\n- `HW8.ipynb`  \n  The main Jupyter Notebook containing all code, visu...",
          "Type: repo_summaries<br>Text: - `README.md`  \n  This documentation file.\n\n---\n\n## Setup & Run\n\n### Requirements\n\nEnsure you have P...",
          "Type: repo_summaries<br>Text: 2. Launch Jupyter Notebook:\n\n```bash\njupyter notebook HW8.ipynb\n```\n\n3. Open `HW8.ipynb` in your bro...",
          "Type: repo_summaries<br>Text: ---\n\n## Testing / CI\n\nNo explicit testing or continuous integration setup is mentioned or present in...",
          "Type: repo_summaries<br>Text: ---\n\n## Contribution Notes\n\nNo contribution guidelines are provided in the repository. Feel free to ...",
          "Type: repo_summaries<br>Text: ---\n\n## License\n\nThis project is licensed under the MIT License. See the `LICENSE` file for details....",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:47.185279Z | Model: gpt-4.1-nano -->\n\n# OOPS-Python-MLOps\n\n## Overv...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Demonstrates core OOP concepts such as classes, objects, constructors, methods, in...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository is structured around several Python files, each illust...",
          "Type: repo_summaries<br>Text: - **`oops_proj.py`**: Contains the main class `chatbook`, demonstrating encapsulation, static method...",
          "Type: repo_summaries<br>Text: - **`adv_inheritance.py`**: Showcases advanced inheritance concepts such as multilevel, hierarchical...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`README.md`**: Provides an overview and documentation for the repositor...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nTo run the code snippets:\n1. Clone the repository:\n```bash\ngit clone https://github.c...",
          "Type: repo_summaries<br>Text: ## How to Use\n- **`oops1.py`**: Run to see basic class instantiation and attribute access.\n- **`oops...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nThere is no explicit mention of testing frameworks or CI/CD pipelines in the reposit...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- The repository primarily contains example code snippets; it lack...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:01:32.520820Z | Model: gpt-4.1-nano -->\n\n# OpenCV-Basics\n\n## Overview\n...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository is structured around Python scripts and Jupyter notebo...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`camera.py`**: Main script for capturing and displaying video streams.\n...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Python 3.x installed\n- OpenCV (`cv2`) library installed (`pip ins...",
          "Type: repo_summaries<br>Text: ### Running the notebook\nOpen `Basics_cv2.ipynb` in Jupyter Notebook:\n```bash\njupyter notebook Basic...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or Continuous Integration (CI) setup is mentioned or evident fro...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- The repository currently offers basic demonstrations; advanced f...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:03:04.638892Z | Model: gpt-4.1-nano -->\n\n# prathamesh-portfolio-static...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **Responsive Design:** Fully responsive layout optimized for desktop and mobile de...",
          "Type: repo_summaries<br>Text: - **About Section:** Skills overview with categorized badges and professional summary.\n- **Projects ...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe project is structured as a React application using TypeScript, st...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- `src/`: Contains all React components, assets, styles, and configuration ...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n1. Clone the repository:\n```bash\ngit clone https://github.com/upratham/prathamesh-por...",
          "Type: repo_summaries<br>Text: ## How to Use\n- **Customizing Content:** Edit the React components (`Hero.tsx`, `About.tsx`, `Projec...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or CI configurations are present in the provided files. Implemen...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- **No License Specified:** Licensing information is absent; consi...",
          "Type: repo_summaries<br>Text: ---\n\n*Note:* If specific details about deployment, contribution, or additional features are required...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:03:47.935512Z | Model: gpt-4.1-nano -->\n\n# Predicting-House-price-in-B...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Data acquisition from real estate listings\n- Data preprocessing to clean and prepa...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe project follows a structured workflow:\n1. **Data Acquisition:** C...",
          "Type: repo_summaries<br>Text: All steps are implemented within a Jupyter Notebook (`code.ipynb`), which guides the user through ea...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nSince the project is implemented in a Jupyter Notebook, follow these steps to run it:...",
          "Type: repo_summaries<br>Text: *Note:* The notebook may require additional Python libraries such as pandas, scikit-learn, etc. Inst...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or Continuous Integration (CI) setup is mentioned or present in ...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nNo specific contribution guidelines are provided in the repository.\n\n## Limita...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:58:44.007761Z | Model: gpt-4.1-nano -->\n\n# Production Repository\n\n## O...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Step-by-step guides for deploying AI agents on AWS Bedrock\n- Sample Python project...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository combines educational notebooks, code samples, and infr...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`finale/`**: Contains the main Python project (`pyproject.toml`) for de...",
          "Type: repo_summaries<br>Text: - **`terraform/`** (referenced in scripts): Infrastructure-as-code directory for AWS resource manage...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Python 3.12+ (as specified in `pyproject.toml`)\n- AWS CLI configu...",
          "Type: repo_summaries<br>Text: ### Running the Python Projects\n- To run the main agent code:\n```bash\nuv run <script_name.py>\n```\n- ...",
          "Type: repo_summaries<br>Text: ## How to Use\n### Example: Creating and Invoking an Agent\n1. Create a new Python script (e.g., `my_a...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or CI configurations are detailed in the provided data. It is in...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- Contributions involve creating new markdown or notebook files in `community_...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- The repository appears to be a learning and deployment framework...",
          "Type: repo_summaries<br>Text: ---\n\n*Note: If any specific details about configuration files, environment variables, or additional ...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:02:53.841809Z | Model: gpt-4.1-nano -->\n\n# supervised-ml-feature-exper...",
          "Type: repo_summaries<br>Text: ## Key Features\n- Implementation of multiple supervised classification algorithms.\n- Feature selecti...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe repository is structured around Jupyter Notebooks that contain th...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **.gitattributes & .gitignore**: Standard Git configuration files to mana...",
          "Type: repo_summaries<br>Text: - `heart-disease-classification.csv`: Additional dataset possibly used for specific experiments.\n- *...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n1. **Clone the repository**:\n```bash\ngit clone https://github.com/upratham/supervised...",
          "Type: repo_summaries<br>Text: *Note:* Since the core files are notebooks, execution involves running cells sequentially within Jup...",
          "Type: repo_summaries<br>Text: ## Testing / CI\n- No explicit testing or continuous integration setup is indicated in the repository...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\n- No specific contribution guidelines are provided in the repository.\n- Users ...",
          "Type: repo_summaries<br>Text: ---\n\nFor further details, explore the notebooks and datasets directly in the repository: [GitHub Lin...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:03:41.012793Z | Model: gpt-4.1-nano -->\n\n# UMA-V-2 Repository Document...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **Interactive Practical Modules:** Web pages linking to anatomy, biology, and chem...",
          "Type: repo_summaries<br>Text: - **Responsive Design Elements:** Navigation buttons, modals for user interactions, and styled heade...",
          "Type: repo_summaries<br>Text: ---\n\n## Architecture / How it Works\nThe repository combines static HTML, PHP backend scripts, and JS...",
          "Type: repo_summaries<br>Text: - **Frontend:** HTML pages styled with embedded CSS, providing navigation, user profile sections, an...",
          "Type: repo_summaries<br>Text: - **Resources:** Organized into folders such as `Anatomy_pract_templets`, `Biology_Prac_Templates`, ...",
          "Type: repo_summaries<br>Text: ---...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`Anatomy_pract_templets/`**: Contains anatomy practical templates, 3D m...",
          "Type: repo_summaries<br>Text: - **`dbconnect.php`**: Database connection configuration.\n- **`register.php`**: Handles new user reg...",
          "Type: repo_summaries<br>Text: ---\n\n## Setup & Run\nBased on the provided files:\n\n1. **Database Setup:**\n   - Import `stud_name.sql`...",
          "Type: repo_summaries<br>Text: 3. **Configuration:**\n   - Ensure `dbconnect.php` has correct database credentials matching your MyS...",
          "Type: repo_summaries<br>Text: ## How to Use\n- **User Login:**\n  - Access the login page (not explicitly provided but implied).\n  -...",
          "Type: repo_summaries<br>Text: - **Assessment & Data Entry:**\n  - Teachers or authorized users can input student marks via the `ins...",
          "Type: repo_summaries<br>Text: ---\n\n## Testing / CI\n- No explicit testing or CI/CD pipelines are mentioned in the provided files.\n-...",
          "Type: repo_summaries<br>Text: ---\n\n## Contribution Notes\n- No specific contribution guidelines are provided.\n- To contribute:\n  - ...",
          "Type: repo_summaries<br>Text: ---\n\n## Limitations / Inferred TODOs\n- **Security:** Passwords are hashed, but session management an...",
          "Type: repo_summaries<br>Text: ---\n\n**Note:** Some details, such as login pages, detailed user flows, or specific scripts for lab i...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T03:00:56.003390Z | Model: gpt-4.1-nano -->\n\n# UMA_dropout_prediction_for_...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **Multi-model ensemble prediction:** Combines predictions from several pre-trained...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nThe system primarily consists of:\n- **Pre-trained models:** Stored as...",
          "Type: repo_summaries<br>Text: ## Notable Folders/Files\n- **`app.py`**: Contains the Gradio interface code for interactive predicti...",
          "Type: repo_summaries<br>Text: - **`base_proyecto.xlsx`**: Likely contains raw or processed data used during model training or anal...",
          "Type: repo_summaries<br>Text: ## Setup & Run\n### Prerequisites\n- Python environment with necessary libraries (`scikit-learn`, `pan...",
          "Type: repo_summaries<br>Text: ## How to Use\n### Web Interface\n- Access the URL provided after running `app.py`.\n- Fill in student ...",
          "Type: repo_summaries<br>Text: ### API Usage\nSend a POST request with JSON data to `http://127.0.0.1:5000/predict`. Example payload...",
          "Type: repo_summaries<br>Text: ## Testing / CI\nNo explicit testing or CI configurations are present in the repository. Notable note...",
          "Type: repo_summaries<br>Text: ## Limitations / TODOs (Inferred)\n- **Model details unspecified:** The exact models and their traini...",
          "Type: repo_summaries<br>Text: ---\n\n*Note:* If you require detailed instructions on data preprocessing, model training, or deployme...",
          "Type: repo_summaries<br>Text: <!-- Generated: 2026-02-15T02:59:53.128533Z | Model: gpt-4.1-nano -->\n\n# upratham Repository Documen...",
          "Type: repo_summaries<br>Text: ## Key Features\n- **Showcase of Applied ML Projects:** Includes projects on debate simulation, broch...",
          "Type: repo_summaries<br>Text: ## Architecture / How it Works\nWhile specific implementation details are not provided, the structure...",
          "Type: repo_summaries<br>Text: *Note:* Exact architecture diagrams or detailed workflows are not available.\n\n## Notable Folders/Fil...",
          "Type: repo_summaries<br>Text: ## Setup & Run\nBased on the projects and tools mentioned:\n- To run individual projects, you would ty...",
          "Type: repo_summaries<br>Text: ## How to Use\n- Explore the linked projects in the README for practical examples:\n  - Use the **LLM ...",
          "Type: repo_summaries<br>Text: *Note:* Specific usage instructions are not provided in the excerpt, so users should look for projec...",
          "Type: repo_summaries<br>Text: ## Contribution Notes\nThere are no explicit contribution guidelines or notes included in the provide...",
          "Type: repo_summaries<br>Text: ---\n\n*This documentation is based solely on the provided metadata, file excerpts, and inferred conte..."
         ],
         "type": "scatter3d",
         "x": {
          "bdata": "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",
          "dtype": "f4"
         },
         "y": {
          "bdata": "w1oxwcgoGsGE8pDAQse5v9icLb9v3FnAd5dtwHPLpT9wDWdABr11PoBCTkDpqQ3ByCgawf2p6z0KhMPAF5cJwGbFv8CLDXDA+GmkwMfYPr/ZxV3AxFA9wF/ROMCA1jbAuiX+v3OnwsDb372/sTBxQE/kjj/sHM++Z/sQQYvZ6EAT6NZA6h/nQOOmGEH1KCZBrg6bwAiEwsDubjzAYSELwDIrZ7+BHIu9aRRQP7K0GkCjuahAYU/dQGRz2kBp5UrBDt+jvzy5yD/49TJAn51XQH3jeUAHEaZAmmOtQJt1+UD5uxNB7oh4QCgnwcGjs7vBVSG2wXlgq8G1jaHBJdp6waTsbMF8GILBmfGMwaIojsGKsdhBQlvDQWrEsEG+VqFB1kaoQZ2uvUH7ptFBUzskwKG+ir70+nO/0yqkP0godjyESwG/OqtlP2TLrL+Y3fC/DmtxwI3pO8DU/TrB+7pPwWQkr8HaiJjB2CiWwQantsGILszBUCPRwfvazcH+fXPBnd6+wQ/EtcHm4q/B6Cu5wX5HqMGhVorBj/ycwfm+ssEZ0aHB9uOswSUNvcFMgMnBlPOtwQSUmMGDMaTB3VeRwUyIuEHdHMBBqZjQQWo25UFaS/NB6krqQemS3kGgVoLBQ4BewaFskMF0WKPBSNuUwWMJfMGy54/BMy6AwZojd8FfQbbByz2jwaDJk8HY35bBLzw9wcWqT8EmPFbBcD1rwQ0iUsFzDovBE7B1wdB8dcGD7mzBF5WAwbXGhcGnz6XB5CWVwW3Di8EHDaHBMuGYwdMmkMHqQMhA7EsXwMwBm752AzFBjMRHQZVNgEGMoYJBG8xkQW6AU0E/qWxBkg+IQSDai0EeTv9AxbbeQHMRfEEhNnJBJj17QfOVvkFgRcVBNPRxQc26cEHnjoJBiSqUQQOKI0FK1PJAWnVtQYL0YEFfV3VBpvuZQcrxpkHvoaxBV/WIQWj1cUG3nT5B7NNfQTYVnEHvcpVBuT+NQWnEwkGMfdRBeI7UQaHx2EGjKdtBDtbrQekV+UEI2dlBrUzCQSKGnUFmOqFBpxGYQWT+kUHG8bpBlJ6UQSQvcUFaOGhBLnigQVI4v0E0J75BhJ6GQeu3ekFsu4tBBnyVQReGlEF6X6NBdaylQSuMqUHJxKhBcYm6QdqnykHxU81BDNG5QX/Vr0E+WbNByTROQa0VVkEkQaVBbrinQTihPkE2mmVB4C5lQW4nOUHX22NBM7EPQbZ0g0D6VfU/P/wWQH8KjUBl2ABBkWj1QGA11EDr5eBAt5gCQVVV2UBhwLJAuTy9wM81xcCNT18/9VtLQHp4zD6jAbI/4SkuP7dSKjsDefa/q1guwegwb8E6jcLALWb9wGE2xMAI2inA3ooEwBddvMACz/vAexWNwCJW3L8zujfAW5RJwWLp0MAehlHAKGChv5ZciT/eY/A/vzRHQBPFtL4RJVc/V/wsv6bvlMEPxoLAIEWJwGxovcDuvhjBuJoLwcnH2MB7PoTAEL1swPey/L+uis/AYGo1wTmP2MDPw/DAwFydvqbHfD+SySLAqCotwdPt+8B2ddjAAs3RwKpzDcEjvCPB87zOwP0Im8B7EQfAExbkv05AQcDzZDPBDhUPwS6MvsGNCK7BJ4tvwRxhjcGmp5PBt7mRwc+DZMFK3WjBfGpJwVKaIsF8GpHBZllJwfB6VsFn1XLBTS+MwVZZM8HxZEbBjfZ/wQnSpMB9u5TAfWUtwSCR4cCH+N3AhHAhwdpvvsAMVYrAL32KQFIZWEFeyVZBD366wDV64MBCt/rAuEgswVJqHsFS6wTB5TDYv2nC/r+6h1PA4tm3QCROMUC619g+ZdmPwM8CFcEHbwfBzYcVwUbkoMADk+XAe+n7wDUJj0CtevDA4kaGwPe/B8Gn1BrBXXz/wKrccMADk+XAusYKwZ3vrkDJGBfB352gwIeIwsAxgkLA2y1qwPY4H8CNehy/iwodQOZAGkE2Wd1AjUDKQNR8VT9RWClAIB7lP91tQ0EjqudASX1AwfvYa8GEQyvBzyN7QVJAhkFhI2tB+xp+wD/TkMDN8OJA/pHtwI4l4cD+KhDBIt9vQT/ZRD/07LtAdieUwBXuOMHk4AtB/gelwMLFoD1KVmA/kH3kQMF+YEBUoLBAZyEDwfPLc0CczrdBqCXQwC2XVMHmySPBYq8UwT/KqUFI6SVBQhx7wAqow7/V3ULA8LRKwBMFUr+IJiFBWR4PQBnuD0Dib6XAw/myPx8iZkEfeojADCI+wPqGc78ndlZBBkFFQFUqikA3LO/AP4tyQeSV8MDtp4k/MHJ1QZZiC0GD1TDBbsQNQNy4jMFRvIDBy/FqwYEXi8Gy3PbAgE+pwQiyocESZXfBOjI7QRk0T8E9xj8+k4WJwfEVdMHAk6G+Q8jXQB5VAkH4hBhAhEpRP0wtA0HYYxDBLQ+mPtKhA0Eda7vAjer/wIFiksD0xcVAhiEFQWkT8EAhEpg/G5UOwfDHpEBMA5XAt5FjwBqH4r8Wpg499cGhP14besG/ajXBlfozwanF9UDl5tg//QDmv8AiYsCpjN+/Tx1UQbsWIkG1X95AX/sHwfmLZEDt2QtBamgJQQlCy0DaGjVB1kLVQG1rjUAoZsXAtVq9QLaCRcDUG1/Ar/f7vnMJCUEgXgJA4u+hP/8vp8A+egtB6rHvQAChscC0y5LAvXdeQZ3uYkC/LM9A42L2wNv3J8BT/orA1RQwwI0qqsCM6OHAjZF7wMMLS0FccjVBlP1VwGLgq8DhCkpAMTxowY0Y079WzqrA0ohLQLzXucA4ZB3Am+vsQFxRu0AE7clAfEKoQByqjsCuUrvAq0H0wIu0HMHRFwPB4UpSQUePYEFuQ+vAYpoEQCQBBcEF0aM/uOLCPy5AZUA+M63AlbdhQLXc/EAzBSdBHvwtQWP/10D+FdhAINMIQBgPwUC3+sxA4vSCwJi8XsFdSkLBjkzHwEJVbUE/R1bBTLQOQHzWHb+HfC3BsMFHwS4vokCedna+fXugP7E1q75slUdAlLE7wJHGWkGnPddArxzgQCuk7UBRlgZBfDJQv2jbQsGG+9W/HNsVP9FfCsEf7JNAFQlFQcQwF0FSFipBaRYlQbRh6T+1cBvBhhqpQDvI68DxWRTAOPQZvl+5H0HAiXVA+eU9QHMJDsFB6zbAqy4+wDwui8COVAdAP+OaP7L2RkGFu8Q/Ia7CP1sVLkC1b0DBP9vKQKWZmUFxSC7BOXc5wZHkmkHKu/9A8RgVwIeGDsBlOaNBAqBfQZ9wgkEExn5BjvJ+QeAbg0EOj2pBZ4ehwDOVxUCoRpFBABmeQT9wi0BI1BdAHJvQQElnpkDjNXdAZAFVQTdDI0HjCxNBAp3+QOEgfcCH/QPBvW+YQd/VekFQx9hAzyvwQNxziEBcx09B5IU8QYmDG0GE0eVAKVJzwO8GiEH8Gq5B/5CIQMRo5D8m1CLBKSFAwGQgtMAh7K3Ay12RQWdOo0EMtrC+pSiuQIJktsBo4gJBJkhUQR+Rp8BLwtHA/DElwbCsb0Cg0ZhA1kgMQXLFFcEV45TAi9uLQJaMEEBcVc++X4x8wGy4DkB+5lJB3WptQINrzz+f9j/B8YFZQWCsiUFCfSG/1DY6wXIbSr4yUb8/Jn/JPUTyjEF8CihAgkDVQCz5CcELylrBzng2wUtmLMFeeotB0dxNwSgTFUHj0DfBKu8VwUpbHcFuZTXB8BZnwS14P8EhopVBtmpuwZO1cEHF2vrAQcwIQZ9iKkGOpcfAYz/owOIxeMDH64VBxm1CP6FI7kDjmN/AT40mQUV18UB4eA/BFVGzwCwEosBny51BErusQU4nsUGwBD5BkZk1P44vzcAsTFxAKZEKQPj+DcAxFMPA8Z+aP6RdEz99TkpBxqEaP/WMckBL/YbAKVo4QVCjsb9Bb2fAi9XpwIFQK8HfK0zAc96LwCSd37+Ms17AJTgCv4urtEEDffy/HpCnv+mYaj+Rw9lA0XWTv3BZHMFiXNZAYccOQOqBkkAcVZ1Ay7GkwCJurcDZhfpAO4p4QH9qDUGztJBAdbAKweq9g0B1FO7AroshwcDdAMFU43o/bAd6Qc+J57wc7wFBabriwNj9XcA=",
          "dtype": "f4"
         },
         "z": {
          "bdata": "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",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "height": 700,
        "margin": {
         "b": 10,
         "l": 10,
         "r": 10,
         "t": 40
        },
        "scene": {
         "xaxis": {
          "title": {
           "text": "x"
          }
         },
         "yaxis": {
          "title": {
           "text": "y"
          }
         },
         "zaxis": {
          "title": {
           "text": "z"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D Chroma Vector Store Visualization"
        },
        "width": 900
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.visualize_vector_db import visualize_2d, visualize_3d\n",
    "\n",
    "# 2D visualization\n",
    "fig_2d = visualize_2d(vectore_store)\n",
    "fig_2d.show()\n",
    "\n",
    "# 3D visualization\n",
    "fig_3d = visualize_3d(vectore_store)\n",
    "fig_3d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99cf2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a43594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-rag-private-knowledge-worker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
